# Kafka çŸ¥å¤šå°‘ v1.0

> åŸºäº Apache Kafka 3.9.x | æœ€åæ›´æ–°æ—¶é—´ï¼š2025-01-01

---

## ğŸ“– å‰è¨€

### æŠ€æœ¯èƒŒæ™¯ä¸å­¦ä¹ ä»·å€¼

Apache Kafka æ˜¯å½“ä»Šæœ€æµè¡Œçš„åˆ†å¸ƒå¼äº‹ä»¶æµå¹³å°ï¼ˆDistributed Event Streaming Platformï¼‰ï¼Œæœ€åˆç”± LinkedIn äº 2010 å¹´å¼€å‘ï¼Œ2011 å¹´å¼€æºå¹¶æèµ ç»™ Apache åŸºé‡‘ä¼šï¼Œ2012 å¹´æˆä¸ºé¡¶çº§é¡¹ç›®ã€‚æˆªè‡³ç›®å‰ï¼Œå…¨çƒè¶…è¿‡ 80% çš„è´¢å¯Œ 100 å¼ºä¼ä¸šåœ¨ä½¿ç”¨ Kafkaã€‚

ğŸ¯ å­¦ä¹  Kafka çš„æ ¸å¿ƒä»·å€¼ï¼š
- **è¡Œä¸šæ ‡å‡†**ï¼šäº‹ä»¶é©±åŠ¨æ¶æ„ï¼ˆEDAï¼‰å’Œå®æ—¶æ•°æ®ç®¡é“çš„äº‹å®æ ‡å‡†
- **æŠ€æœ¯æ·±åº¦**ï¼šæ¶µç›–åˆ†å¸ƒå¼ç³»ç»Ÿã€å­˜å‚¨å¼•æ“ã€ç½‘ç»œç¼–ç¨‹ã€å…±è¯†åè®®ç­‰æ ¸å¿ƒæŠ€æœ¯
- **ç”Ÿæ€å®Œå–„**ï¼šKafka Connectï¼ˆæ•°æ®é›†æˆï¼‰ã€Kafka Streamsï¼ˆæµå¤„ç†ï¼‰ã€Schema Registryï¼ˆæ•°æ®æ²»ç†ï¼‰å½¢æˆå®Œæ•´ç”Ÿæ€
- **èŒä¸šå¿…å¤‡**ï¼šåç«¯å¼€å‘ã€å¤§æ•°æ®å·¥ç¨‹å¸ˆã€æ¶æ„å¸ˆå²—ä½çš„æ ¸å¿ƒæŠ€èƒ½

### é€‚ç”¨è¯»è€…

| è¯»è€…ç±»å‹ | å»ºè®®é˜…è¯»ç« èŠ‚ |
|---------|------------|
| åˆå­¦è€… | å‰è¨€ â†’ ç¬¬ä¸€ç«  â†’ ç¬¬ä¸ƒç« ï¼ˆå®éªŒç¯å¢ƒï¼‰ |
| åç«¯å¼€å‘å·¥ç¨‹å¸ˆ | ç¬¬ä¸€ç«  â†’ ç¬¬äºŒç«  â†’ ç¬¬äº”ç«  â†’ ç¬¬å…­ç«  |
| å¤§æ•°æ®/æµå¤„ç†å·¥ç¨‹å¸ˆ | ç¬¬äºŒç«  â†’ ç¬¬ä¸‰ç«  â†’ ç¬¬äº”ç«  |
| æ¶æ„å¸ˆ | ç¬¬äºŒç«  â†’ ç¬¬å››ç«  â†’ ç¬¬äº”ç«  |
| é¢è¯•å¤‡æˆ˜ | ç¬¬ä¸ƒç«  â†’ ç¬¬äºŒç«  â†’ ç¬¬äº”ç«  |

### ç‰ˆæœ¬è¯´æ˜

æœ¬æ–‡æ¡£åŸºäº **Apache Kafka 3.9.x**ã€‚è¯¥ç‰ˆæœ¬çš„é‡å¤§å˜åŒ–åŒ…æ‹¬ï¼š
- **KRaft æ¨¡å¼æˆä¸ºé»˜è®¤**ï¼šZooKeeper æ¨¡å¼å·²æ ‡è®°ä¸º deprecatedï¼ŒKRaftï¼ˆKafka Raftï¼‰æˆä¸ºç”Ÿäº§æ¨èçš„å…ƒæ•°æ®ç®¡ç†æ–¹å¼
- **æ–°ç‰ˆ Consumer Group åè®®**ï¼šKIP-848 å¼•å…¥çš„æ–° Consumer Rebalance åè®®æŒç»­æ¼”è¿›
- **åˆ†å±‚å­˜å‚¨ï¼ˆTiered Storageï¼‰**ï¼šKIP-405 å¼•å…¥çš„åˆ†å±‚å­˜å‚¨ç‰¹æ€§æŒç»­å®Œå–„
- **æ”¹è¿›çš„å®‰å…¨ä¸é…é¢ç®¡ç†**

> è§ Apache Kafka å®˜æ–¹æ–‡æ¡£ï¼š[Apache Kafka Documentation](https://kafka.apache.org/documentation/)

---

## ç¬¬ä¸€ç« ï¼šåŸºç¡€ç†è®ºä¸æ¶æ„æ¼”è¿›

### 1.1 æŠ€æœ¯è¯ç”ŸèƒŒæ™¯ä¸æ ¸å¿ƒé—®é¢˜

**æ—¶ä»£èƒŒæ™¯**ï¼š2010 å¹´å‰åï¼ŒLinkedIn é¢ä¸´ä¸¥å³»çš„æ•°æ®ç®¡é“æŒ‘æˆ˜ã€‚å…¬å¸å†…éƒ¨æœ‰æ•°åä¸ªæ•°æ®ç³»ç»Ÿï¼ˆæ•°æ®åº“ã€æœç´¢å¼•æ“ã€ç¼“å­˜ã€æ•°æ®ä»“åº“ã€ç›‘æ§ç³»ç»Ÿï¼‰ï¼Œå®ƒä»¬ä¹‹é—´éœ€è¦å®æ—¶äº¤æ¢æ•°æ®ã€‚ä¼ ç»Ÿçš„ç‚¹å¯¹ç‚¹é›†æˆæ–¹å¼å¯¼è‡´äº† O(NÂ²) çš„è¿æ¥å¤æ‚åº¦ï¼Œç³»ç»Ÿé—´è€¦åˆä¸¥é‡ï¼Œæ•°æ®ä¸€è‡´æ€§éš¾ä»¥ä¿è¯ã€‚

**Kafka è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜**ï¼š
1. **æ•°æ®ç®¡é“ç»Ÿä¸€**ï¼šæä¾›ä¸€ä¸ªç»Ÿä¸€çš„ã€é«˜ååçš„æ•°æ®ä¼ è¾“å±‚ï¼Œè§£è€¦æ•°æ®ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…
2. **å®æ—¶æ€§**ï¼šä»æ‰¹å¤„ç†èµ°å‘å®æ—¶æµå¤„ç†ï¼Œæ•°æ®äº§ç”Ÿåæ¯«ç§’çº§å¯æ¶ˆè´¹
3. **é«˜åå**ï¼šæ”¯æ’‘ LinkedIn æ¯å¤©æ•°ä¸‡äº¿æ¡æ¶ˆæ¯çš„å¤„ç†éœ€æ±‚
4. **æŒä¹…åŒ–ä¸å›æº¯**ï¼šæ¶ˆæ¯æŒä¹…åŒ–åˆ°ç£ç›˜ï¼Œæ”¯æŒæ¶ˆè´¹è€…æŒ‰éœ€å›æº¯å†å²æ•°æ®
5. **æ°´å¹³æ‰©å±•**ï¼šé€šè¿‡åˆ†åŒºï¼ˆPartitionï¼‰æœºåˆ¶å®ç°çº¿æ€§æ‰©å±•

**åˆ›å§‹å›¢é˜Ÿ**ï¼šJay Krepsã€Neha Narkhede å’Œ Jun Rao åœ¨ LinkedIn å¼€å‘äº† Kafkaã€‚åå­—æ¥æºäºä½œå®¶ Franz Kafkaï¼Œå› ä¸º"Kafka æ˜¯ä¸€ä¸ªä¸ºå†™ä½œè€Œä¼˜åŒ–çš„ç³»ç»Ÿ"ï¼ˆJay Kreps è¯­ï¼‰ã€‚

ğŸ’¡ **è¿›é˜¶æ€è€ƒ**ï¼šKafka çš„è®¾è®¡å“²å­¦æ˜¯"åˆ†å¸ƒå¼æäº¤æ—¥å¿—ï¼ˆDistributed Commit Logï¼‰"ã€‚å®ƒä¸æ˜¯ä¼ ç»Ÿæ„ä¹‰ä¸Šçš„æ¶ˆæ¯é˜Ÿåˆ—ï¼Œè€Œæ˜¯ä¸€ä¸ªæœ‰åºçš„ã€å¯æŒä¹…åŒ–çš„ã€å¯å›æº¯çš„æ—¥å¿—ç³»ç»Ÿã€‚è¿™ä¸ªæ ¸å¿ƒæŠ½è±¡å†³å®šäº† Kafka çš„æ‰€æœ‰è®¾è®¡å†³ç­–ã€‚

### 1.2 æ¶æ„æ¼”è¿›å†ç¨‹

| ç‰ˆæœ¬ | å¹´ä»½ | é‡Œç¨‹ç¢‘ |
|------|------|--------|
| 0.7 | 2011 | å¼€æºå‘å¸ƒï¼ŒåŸºæœ¬çš„ Pub/Sub åŠŸèƒ½ |
| 0.8 | 2013 | **å¼•å…¥å‰¯æœ¬æœºåˆ¶ï¼ˆReplicationï¼‰**ï¼Œæ•°æ®å¯é æ€§å¤§å¹…æå‡ |
| 0.9 | 2015 | æ–°ç‰ˆ Consumer APIï¼ˆåŸºäº Consumer Group åè®®ï¼‰ã€å®‰å…¨ç‰¹æ€§ï¼ˆSSL/SASLï¼‰ |
| 0.10 | 2016 | **Kafka Streams** æµå¤„ç†åº“ã€æ¶ˆæ¯æ—¶é—´æˆ³ã€Rack-Aware å‰¯æœ¬åˆ†é… |
| 0.11 | 2017 | **å¹‚ç­‰ Producer + äº‹åŠ¡ï¼ˆExactly-Once Semanticsï¼‰**ã€æ¶ˆæ¯å¤´ï¼ˆHeadersï¼‰ |
| 1.0 | 2017 | æ­£å¼ 1.0 ç‰ˆæœ¬ï¼ŒAPI ç¨³å®šæ€§æ‰¿è¯º |
| 2.0 | 2018 | å®‰å…¨å¢å¼ºã€KIP-290 å‰ç¼€ ACL |
| 2.4 | 2020 | **KRaft æ—©æœŸé¢„è§ˆ**ï¼ˆKIP-500ï¼šå» ZooKeeperï¼‰ |
| 3.0 | 2021 | KRaft è¿›å…¥ Early Accessï¼ŒProducer é»˜è®¤å¼€å¯å¹‚ç­‰ |
| 3.3 | 2022 | **KRaft æ ‡è®°ä¸ºç”Ÿäº§å°±ç»ª** |
| 3.5 | 2023 | ZooKeeper æ¨¡å¼æ ‡è®°ä¸º deprecated |
| **3.9** | **2024** | **KRaft ä¸ºé»˜è®¤æ¨¡å¼ï¼ŒZK è¿ç§»å·¥å…·æˆç†Ÿï¼Œæ–° Consumer åè®®æ¼”è¿›** |

**æ¼”è¿›åŸå› åˆ†æ**ï¼š

ğŸ¯ **ä»æ— å‰¯æœ¬åˆ°å‰¯æœ¬æœºåˆ¶ï¼ˆ0.8ï¼‰**ï¼šæ—©æœŸ Kafka æ²¡æœ‰å‰¯æœ¬ï¼ŒBroker å®•æœºå³ä¸¢æ•°æ®ã€‚0.8 å¼•å…¥ ISRï¼ˆIn-Sync Replicasï¼‰å‰¯æœ¬æœºåˆ¶ï¼Œæ˜¯ Kafka ä»"é«˜ååæ—¥å¿—"èµ°å‘"å¯é æ¶ˆæ¯ç³»ç»Ÿ"çš„å…³é”®ä¸€æ­¥ã€‚

ğŸ¯ **Exactly-Once è¯­ä¹‰ï¼ˆ0.11ï¼‰**ï¼šåœ¨æ­¤ä¹‹å‰ï¼ŒKafka åªèƒ½ä¿è¯ At-Least-Onceï¼ˆè‡³å°‘ä¸€æ¬¡ï¼‰ï¼Œä¸šåŠ¡éœ€è¦è‡ªè¡Œå»é‡ã€‚0.11 é€šè¿‡å¹‚ç­‰ Producerï¼ˆPID + Sequence Numberï¼‰å’Œäº‹åŠ¡ï¼ˆTransaction Coordinatorï¼‰å®ç°äº†ç«¯åˆ°ç«¯çš„ Exactly-Onceã€‚è§ KIP-98ã€‚

ğŸ¯ **KRaft å» ZooKeeperï¼ˆ2.4 â†’ 3.9ï¼‰**ï¼šZooKeeper æ˜¯ Kafka æœ€å¤§çš„è¿ç»´ç—›ç‚¹â€”â€”éœ€è¦ç‹¬ç«‹éƒ¨ç½²å’Œç»´æŠ¤ä¸€å¥— ZK é›†ç¾¤ï¼Œä¸” ZK çš„ Watch æœºåˆ¶åœ¨å¤§è§„æ¨¡é›†ç¾¤ä¸‹æˆä¸ºæ€§èƒ½ç“¶é¢ˆï¼ˆå…ƒæ•°æ®æ›´æ–°å»¶è¿Ÿï¼‰ã€‚KRaft ä½¿ç”¨ Raft åè®®åœ¨ Kafka å†…éƒ¨å®ç°å…ƒæ•°æ®ç®¡ç†ï¼Œæ¶ˆé™¤äº†å¤–éƒ¨ä¾èµ–ã€‚è§ KIP-500ã€‚

âš ï¸ **æ˜“é”™ç‚¹**ï¼šKafka 3.9.x ä¸­ ZooKeeper æ¨¡å¼ä»ç„¶å¯ç”¨ä½†å·² deprecatedã€‚æ–°éƒ¨ç½²åº”ç›´æ¥ä½¿ç”¨ KRaft æ¨¡å¼ã€‚ä» ZK è¿ç§»åˆ° KRaft å¯ä½¿ç”¨ `kafka-metadata.sh` å·¥å…·ã€‚

### 1.3 æ ¸å¿ƒæ¦‚å¿µæœ¯è¯­è¡¨

| è‹±æ–‡æœ¯è¯­ | ä¸­æ–‡ | é€šä¿—è§£é‡Š |
|---------|------|---------|
| Broker | ä»£ç†èŠ‚ç‚¹ | Kafka é›†ç¾¤ä¸­çš„ä¸€ä¸ªæœåŠ¡å™¨å®ä¾‹ï¼Œè´Ÿè´£å­˜å‚¨å’Œè½¬å‘æ¶ˆæ¯ |
| Topic | ä¸»é¢˜ | æ¶ˆæ¯çš„é€»è¾‘åˆ†ç±»ï¼Œç±»ä¼¼æ•°æ®åº“ä¸­çš„"è¡¨" |
| Partition | åˆ†åŒº | Topic çš„ç‰©ç†åˆ†ç‰‡ï¼Œæ˜¯å¹¶è¡Œåº¦å’Œæœ‰åºæ€§çš„åŸºæœ¬å•ä½ |
| Replica | å‰¯æœ¬ | åˆ†åŒºçš„æ•°æ®æ‹·è´ï¼Œåˆ†ä¸º Leader å’Œ Follower |
| Leader | é¢†å¯¼è€…å‰¯æœ¬ | è´Ÿè´£å¤„ç†è¯¥åˆ†åŒºæ‰€æœ‰è¯»å†™è¯·æ±‚çš„å‰¯æœ¬ |
| Follower | è¿½éšè€…å‰¯æœ¬ | ä» Leader æ‹‰å–æ•°æ®ä¿æŒåŒæ­¥ï¼Œä¸ç›´æ¥æœåŠ¡å®¢æˆ·ç«¯ï¼ˆ3.x å‰ï¼‰ |
| ISR | åŒæ­¥å‰¯æœ¬é›† | In-Sync Replicasï¼Œä¸ Leader ä¿æŒåŒæ­¥çš„å‰¯æœ¬é›†åˆ |
| Producer | ç”Ÿäº§è€… | å‘ Topic å‘é€æ¶ˆæ¯çš„å®¢æˆ·ç«¯ |
| Consumer | æ¶ˆè´¹è€… | ä» Topic è¯»å–æ¶ˆæ¯çš„å®¢æˆ·ç«¯ |
| Consumer Group | æ¶ˆè´¹è€…ç»„ | ä¸€ç»„ Consumer å…±åŒæ¶ˆè´¹ä¸€ä¸ª Topicï¼Œæ¯ä¸ªåˆ†åŒºåªè¢«ç»„å†…ä¸€ä¸ª Consumer æ¶ˆè´¹ |
| Offset | åç§»é‡ | æ¶ˆæ¯åœ¨åˆ†åŒºä¸­çš„å”¯ä¸€åºå·ï¼Œä» 0 å¼€å§‹é€’å¢ |
| Segment | æ®µæ–‡ä»¶ | åˆ†åŒºæ—¥å¿—åœ¨ç£ç›˜ä¸Šçš„ç‰©ç†æ–‡ä»¶å•å…ƒï¼ˆ.log + .index + .timeindexï¼‰ |
| Controller | æ§åˆ¶å™¨ | è´Ÿè´£é›†ç¾¤å…ƒæ•°æ®ç®¡ç†çš„ç‰¹æ®Š Brokerï¼ˆKRaft æ¨¡å¼ä¸‹ä¸º Raft Leaderï¼‰ |
| KRaft | Kafka Raft | Kafka å†…ç½®çš„åŸºäº Raft åè®®çš„å…ƒæ•°æ®ç®¡ç†æ¨¡å¼ï¼Œæ›¿ä»£ ZooKeeper |
| Log Compaction | æ—¥å¿—å‹ç¼© | ä¿ç•™æ¯ä¸ª Key çš„æœ€æ–°å€¼ï¼Œåˆ é™¤æ—§å€¼ï¼Œç”¨äº Changelog åœºæ™¯ |
| Exactly-Once | ç²¾ç¡®ä¸€æ¬¡ | æ¶ˆæ¯ä¸ä¸¢ä¸é‡çš„è¯­ä¹‰ä¿è¯ |
| Idempotent Producer | å¹‚ç­‰ç”Ÿäº§è€… | é€šè¿‡ PID + Sequence Number ä¿è¯å•åˆ†åŒºå†…æ¶ˆæ¯ä¸é‡å¤ |
| Transaction | äº‹åŠ¡ | è·¨åˆ†åŒºçš„åŸå­å†™å…¥ä¿è¯ |
| Consumer Lag | æ¶ˆè´¹å»¶è¿Ÿ | Consumer å½“å‰ Offset ä¸åˆ†åŒºæœ€æ–° Offset çš„å·®å€¼ |
| Rebalance | é‡å¹³è¡¡ | Consumer Group å†…åˆ†åŒºé‡æ–°åˆ†é…çš„è¿‡ç¨‹ |

### 1.4 é€‚ç”¨åœºæ™¯ vs ä¸é€‚ç”¨åœºæ™¯

| åœºæ™¯ | æ˜¯å¦é€‚ç”¨ | è¯´æ˜ |
|------|---------|------|
| å®æ—¶æ•°æ®ç®¡é“ï¼ˆæ•°æ®åº“ â†’ æ•°æ®ä»“åº“ï¼‰ | âœ… | Kafka Connect + CDC æ˜¯æ ‡å‡†æ–¹æ¡ˆ |
| äº‹ä»¶é©±åŠ¨æ¶æ„ï¼ˆå¾®æœåŠ¡é—´å¼‚æ­¥é€šä¿¡ï¼‰ | âœ… | è§£è€¦æœåŠ¡ã€å‰Šå³°å¡«è°·ã€äº‹ä»¶æº¯æº |
| æ—¥å¿—æ”¶é›†ä¸èšåˆ | âœ… | æ›¿ä»£ Flume/Logstash ä½œä¸ºæ—¥å¿—ä¼ è¾“å±‚ |
| å®æ—¶æµå¤„ç† | âœ… | Kafka Streams / Flink / Spark Streaming çš„æ•°æ®æº |
| æŒ‡æ ‡ç›‘æ§æ•°æ®ä¼ è¾“ | âœ… | é«˜ååã€æŒä¹…åŒ–ã€æ”¯æŒå¤šæ¶ˆè´¹è€… |
| æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆä»»åŠ¡åˆ†å‘ï¼‰ | âœ… | Consumer Group å¤©ç„¶æ”¯æŒè´Ÿè½½å‡è¡¡ |
| äº‹ä»¶æº¯æºï¼ˆEvent Sourcingï¼‰ | âœ… | ä¸å¯å˜æ—¥å¿— + Log Compaction å®Œç¾åŒ¹é… |
| ä½å»¶è¿Ÿè¯·æ±‚-å“åº”ï¼ˆRPCï¼‰ | âŒ | Kafka æ˜¯å¼‚æ­¥æ¨¡å‹ï¼Œä¸é€‚åˆåŒæ­¥ RPCï¼Œåº”é€‰ç”¨ gRPC/Dubbo |
| å°æ¶ˆæ¯é‡ã€ç®€å•é˜Ÿåˆ— | âŒ | è¿ç»´æˆæœ¬é«˜ï¼Œå°è§„æ¨¡åœºæ™¯ RabbitMQ/Redis æ›´è½»é‡ |
| ä¸¥æ ¼çš„æ¶ˆæ¯é¡ºåºï¼ˆå…¨å±€æœ‰åºï¼‰ | âŒ | Kafka åªä¿è¯åˆ†åŒºå†…æœ‰åºï¼Œå…¨å±€æœ‰åºéœ€å•åˆ†åŒºï¼ˆç‰ºç‰²ååï¼‰ |
| å¤æ‚è·¯ç”±è§„åˆ™ | âŒ | ä¸æ”¯æŒ RabbitMQ é‚£æ ·çš„ Exchange/Binding è·¯ç”±ï¼Œåº”é€‰ç”¨ RabbitMQ |
| æ¶ˆæ¯ä¼˜å…ˆçº§é˜Ÿåˆ— | âŒ | Kafka ä¸æ”¯æŒæ¶ˆæ¯ä¼˜å…ˆçº§ï¼Œåº”é€‰ç”¨ RabbitMQ/RocketMQ |
| å»¶è¿Ÿæ¶ˆæ¯/å®šæ—¶æ¶ˆæ¯ | âŒ | åŸç”Ÿä¸æ”¯æŒï¼Œéœ€å€ŸåŠ©å¤–éƒ¨æ–¹æ¡ˆã€‚RocketMQ åŸç”Ÿæ”¯æŒ |

### 1.5 åŒç±»æŠ€æœ¯å¯¹æ¯”

#### Kafka vs RocketMQ vs Pulsar vs RabbitMQ

| ç»´åº¦ | Kafka 3.9 | RocketMQ 5.x | Pulsar 3.x | RabbitMQ 3.13 |
|------|-----------|-------------|------------|---------------|
| **è®¾è®¡å“²å­¦** | åˆ†å¸ƒå¼æäº¤æ—¥å¿—ï¼Œååä¼˜å…ˆ | é‡‘èçº§æ¶ˆæ¯é˜Ÿåˆ—ï¼ŒåŠŸèƒ½ä¸°å¯Œ | å­˜ç®—åˆ†ç¦»ï¼Œäº‘åŸç”Ÿ | AMQP æ ‡å‡†ï¼Œçµæ´»è·¯ç”± |
| **å¼€å‘è¯­è¨€** | Java/Scala | Java | Java | Erlang |
| **å­˜å‚¨æ¶æ„** | åˆ†åŒºæ—¥å¿—ï¼ˆBroker æœ¬åœ°ç£ç›˜ï¼‰ | CommitLog + ConsumeQueue | BookKeeperï¼ˆå­˜ç®—åˆ†ç¦»ï¼‰ | å†…å­˜ + ç£ç›˜ï¼ˆMnesia/Khepriï¼‰ |
| **å…ƒæ•°æ®ç®¡ç†** | KRaftï¼ˆå†…ç½® Raftï¼‰ | NameServerï¼ˆæ— çŠ¶æ€ï¼‰ | ZooKeeper | Mnesia/Khepri å†…ç½® |
| **æ¶ˆæ¯æ¨¡å‹** | Pub/Subï¼ˆPull æ¨¡å¼ï¼‰ | Pub/Subï¼ˆPush + Pullï¼‰ | Pub/Subï¼ˆPush + Pullï¼‰ | Queue + Exchangeï¼ˆPushï¼‰ |
| **æ¶ˆæ¯é¡ºåº** | åˆ†åŒºå†…æœ‰åº | é˜Ÿåˆ—å†…æœ‰åº | åˆ†åŒºå†…æœ‰åº | é˜Ÿåˆ—å†…æœ‰åº |
| **å»¶è¿Ÿæ¶ˆæ¯** | âŒ ä¸æ”¯æŒ | âœ… åŸç”Ÿæ”¯æŒï¼ˆä»»æ„å»¶è¿Ÿï¼‰ | âœ… æ”¯æŒ | âœ… æ’ä»¶æ”¯æŒ |
| **äº‹åŠ¡æ¶ˆæ¯** | âœ… è·¨åˆ†åŒºäº‹åŠ¡ | âœ… åŠæ¶ˆæ¯äº‹åŠ¡ | âœ… æ”¯æŒ | âœ… æ”¯æŒ |
| **Exactly-Once** | âœ… å¹‚ç­‰ + äº‹åŠ¡ | âœ… äº‹åŠ¡æ¶ˆæ¯ | âœ… å»é‡ + äº‹åŠ¡ | âŒ At-Least-Once |
| **æ¶ˆæ¯å›æº¯** | âœ… æŒ‰ Offset/æ—¶é—´æˆ³ | âœ… æŒ‰æ—¶é—´æˆ³ | âœ… æŒ‰ MessageID/æ—¶é—´ | âŒ æ¶ˆè´¹å³åˆ é™¤ |
| **ååé‡** | æé«˜ï¼ˆç™¾ä¸‡çº§ TPSï¼‰ | é«˜ï¼ˆåä¸‡çº§ TPSï¼‰ | é«˜ï¼ˆåä¸‡çº§ TPSï¼‰ | ä¸­ï¼ˆä¸‡çº§ TPSï¼‰ |
| **ç«¯åˆ°ç«¯å»¶è¿Ÿ** | æ¯«ç§’çº§ï¼ˆ2-10msï¼‰ | æ¯«ç§’çº§ï¼ˆ1-5msï¼‰ | æ¯«ç§’çº§ï¼ˆ5-10msï¼‰ | å¾®ç§’çº§ï¼ˆ< 1msï¼‰ |
| **è¿ç»´å¤æ‚åº¦** | ä¸­ï¼ˆKRaft åé™ä½ï¼‰ | ä½ | é«˜ï¼ˆä¾èµ– BookKeeper + ZKï¼‰ | ä½ |
| **ç”Ÿæ€ç³»ç»Ÿ** | æä¸°å¯Œï¼ˆConnectã€Streamsã€Schema Registryï¼‰ | ä¸°å¯Œï¼ˆå›½å†…ç”Ÿæ€å¼ºï¼‰ | ä¸°å¯Œï¼ˆFunctionsã€IOï¼‰ | ä¸°å¯Œï¼ˆæ’ä»¶ä½“ç³»ï¼‰ |
| **ç¤¾åŒºæ´»è·ƒåº¦** | æé«˜ï¼ˆApache é¡¶çº§é¡¹ç›®ï¼‰ | é«˜ï¼ˆApache + é˜¿é‡Œå·´å·´ï¼‰ | é«˜ï¼ˆApache + StreamNativeï¼‰ | é«˜ï¼ˆVMware/Broadcomï¼‰ |
| **è®¸å¯è¯** | Apache 2.0 | Apache 2.0 | Apache 2.0 | MPL 2.0 |

**å¦‚ä½•é€‰æ‹©**ï¼š

ğŸ¯ **é€‰ Kafka**ï¼šéœ€è¦æé«˜ååçš„å®æ—¶æ•°æ®ç®¡é“ã€äº‹ä»¶é©±åŠ¨æ¶æ„ã€æ—¥å¿—èšåˆã€æµå¤„ç†åœºæ™¯ã€‚å›¢é˜Ÿæœ‰ä¸€å®šè¿ç»´èƒ½åŠ›ã€‚

ğŸ¯ **é€‰ RocketMQ**ï¼šå›½å†…ä¸šåŠ¡åœºæ™¯ã€éœ€è¦å»¶è¿Ÿæ¶ˆæ¯/å®šæ—¶æ¶ˆæ¯ã€é‡‘èçº§å¯é æ€§ã€å¯¹è¿ç»´å¤æ‚åº¦æ•æ„Ÿã€‚

ğŸ¯ **é€‰ Pulsar**ï¼šéœ€è¦å­˜ç®—åˆ†ç¦»æ¶æ„ã€å¤šç§Ÿæˆ·éš”ç¦»ã€è·¨åœ°åŸŸå¤åˆ¶åŸç”Ÿæ”¯æŒã€äº‘åŸç”Ÿéƒ¨ç½²ã€‚

ğŸ¯ **é€‰ RabbitMQ**ï¼šæ¶ˆæ¯é‡ä¸å¤§ä½†éœ€è¦çµæ´»è·¯ç”±è§„åˆ™ã€ä½å»¶è¿Ÿã€ç®€å•éƒ¨ç½²ã€AMQP åè®®å…¼å®¹ã€‚

âš ï¸ **æ˜“é”™ç‚¹**ï¼šKafka çš„"é«˜åå"å»ºç«‹åœ¨æ‰¹é‡å‘é€å’Œé¡ºåº I/O çš„åŸºç¡€ä¸Šã€‚å¦‚æœä¸šåŠ¡åœºæ™¯æ˜¯å¤§é‡å°æ¶ˆæ¯ä¸”è¦æ±‚æä½å»¶è¿Ÿï¼ˆ< 1msï¼‰ï¼ŒRabbitMQ å¯èƒ½æ˜¯æ›´å¥½çš„é€‰æ‹©ã€‚

---

## ç¬¬äºŒç« ï¼šå®ç°åŸç†è§£æ

### 2.1 æ ¸å¿ƒç»„ä»¶æ¶æ„å›¾

Kafka 3.9.xï¼ˆKRaft æ¨¡å¼ï¼‰çš„æ ¸å¿ƒæ¶æ„ç”± Producerã€Brokerï¼ˆå« Controllerï¼‰ã€Consumer ä¸‰å¤§è§’è‰²ç»„æˆã€‚

```mermaid
graph TB
    subgraph ç”Ÿäº§è€…
        P1[Producer 1]
        P2[Producer 2]
    end

    subgraph "Kafka é›†ç¾¤ï¼ˆKRaft æ¨¡å¼ï¼‰"
        subgraph "Broker 1ï¼ˆController Leaderï¼‰"
            C1[KRaft Controller]
            B1P0[Topic-A Partition 0<br/>Leader]
            B1P1[Topic-B Partition 1<br/>Follower]
        end
        subgraph "Broker 2ï¼ˆController Followerï¼‰"
            C2[KRaft Controller]
            B2P0[Topic-A Partition 0<br/>Follower]
            B2P1[Topic-B Partition 0<br/>Leader]
        end
        subgraph "Broker 3ï¼ˆController Followerï¼‰"
            C3[KRaft Controller]
            B3P0[Topic-A Partition 1<br/>Leader]
            B3P1[Topic-B Partition 1<br/>Leader]
        end
        C1 <-->|Raft å…±è¯†| C2
        C1 <-->|Raft å…±è¯†| C3
    end

    subgraph "æ¶ˆè´¹è€…ç»„ A"
        CA1[Consumer 1]
        CA2[Consumer 2]
    end

    P1 & P2 --> B1P0 & B2P1 & B3P0 & B3P1
    B1P0 --> CA1
    B2P1 & B3P0 --> CA2
```

ğŸ¯ **æ ¸å¿ƒè¦ç‚¹**ï¼š
- **KRaft æ¨¡å¼**ä¸‹ï¼ŒController è§’è‰²å†…åµŒåœ¨ Broker ä¸­ï¼ˆä¹Ÿå¯ç‹¬ç«‹éƒ¨ç½²ï¼‰ï¼Œé€šè¿‡ Raft åè®®é€‰ä¸¾ Active Controllerï¼Œç®¡ç†é›†ç¾¤å…ƒæ•°æ®ï¼ˆTopicã€åˆ†åŒºåˆ†é…ã€ISR ç­‰ï¼‰
- æ¯ä¸ª Partition æœ‰ä¸€ä¸ª Leader å‰¯æœ¬å’Œå¤šä¸ª Follower å‰¯æœ¬ï¼Œæ‰€æœ‰è¯»å†™è¯·æ±‚éƒ½ç”± Leader å¤„ç†
- Consumer Group å†…çš„ Consumer é€šè¿‡ Group Coordinator åè°ƒåˆ†åŒºåˆ†é…

> è§ Kafka å®˜æ–¹æ–‡æ¡£ï¼š[KRaft Architecture](https://kafka.apache.org/documentation/#kraft)

### 2.2 æ¶ˆæ¯ç”Ÿäº§æµç¨‹

#### 2.2.1 æ­£å¸¸å‘é€æµç¨‹

```mermaid
sequenceDiagram
    participant App as åº”ç”¨ç¨‹åº
    participant Producer as KafkaProducer
    participant Interceptor as æ‹¦æˆªå™¨é“¾
    participant Serializer as åºåˆ—åŒ–å™¨
    participant Partitioner as åˆ†åŒºå™¨
    participant RecordAccum as RecordAccumulator
    participant Sender as Sender çº¿ç¨‹
    participant Broker as Broker Leader

    App->>Producer: 1. send(ProducerRecord)
    Producer->>Interceptor: 2. onSend() æ‹¦æˆªå¤„ç†
    Interceptor->>Serializer: 3. åºåˆ—åŒ– Key + Value
    Serializer->>Partitioner: 4. è®¡ç®—ç›®æ ‡åˆ†åŒº
    Note over Partitioner: æœ‰ Key â†’ murmur2(key) % numPartitions<br/>æ—  Key â†’ Sticky Partitionerï¼ˆæ‰¹é‡ç²˜æ€§ï¼‰
    Partitioner->>RecordAccum: 5. è¿½åŠ åˆ°å¯¹åº”åˆ†åŒºçš„ ProducerBatch
    RecordAccum-->>App: 6. è¿”å› Futureï¼ˆå¼‚æ­¥ï¼‰

    Note over RecordAccum,Sender: --- Sender çº¿ç¨‹ï¼ˆç‹¬ç«‹çº¿ç¨‹ï¼‰ ---
    Sender->>RecordAccum: 7. æŒ‰ Broker èšåˆ batchï¼ˆdrainï¼‰
    Sender->>Broker: 8. å‘é€ ProduceRequestï¼ˆæ‰¹é‡ï¼‰
    Broker->>Broker: 9. å†™å…¥ Leader Log + ç­‰å¾… ISR åŒæ­¥ï¼ˆå–å†³äº acksï¼‰
    Broker-->>Sender: 10. ProduceResponseï¼ˆoffset + é”™è¯¯ç ï¼‰
    Sender-->>App: 11. è§¦å‘ Callback å›è°ƒ
```

**å…³é”®è®¾è®¡è§£æ**ï¼š

**æ‰¹é‡å‘é€ï¼ˆBatchingï¼‰**ï¼šProducer ä¸ä¼šæ¯æ¡æ¶ˆæ¯éƒ½å‘ä¸€æ¬¡ç½‘ç»œè¯·æ±‚ã€‚`RecordAccumulator` å°†æ¶ˆæ¯æŒ‰åˆ†åŒºèšåˆåˆ° `ProducerBatch` ä¸­ï¼Œç”± `Sender` çº¿ç¨‹æ‰¹é‡å‘é€ã€‚ä¸¤ä¸ªå‚æ•°æ§åˆ¶æ‰¹é‡è¡Œä¸ºï¼š
- `batch.size`ï¼ˆé»˜è®¤ 16KBï¼‰ï¼šå•ä¸ª batch çš„å¤§å°ä¸Šé™
- `linger.ms`ï¼ˆé»˜è®¤ 0msï¼‰ï¼šbatch æœªæ»¡æ—¶çš„ç­‰å¾…æ—¶é—´

```java
// Producer é…ç½®ç¤ºä¾‹
Properties props = new Properties();
props.put("bootstrap.servers", "broker1:9092,broker2:9092");
props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
props.put("acks", "all");              // ç­‰å¾…æ‰€æœ‰ ISR ç¡®è®¤
props.put("batch.size", 32768);        // 32KB batch
props.put("linger.ms", 5);            // ç­‰å¾… 5ms å‡‘æ‰¹
props.put("compression.type", "lz4"); // LZ4 å‹ç¼©
props.put("enable.idempotence", true); // å¼€å¯å¹‚ç­‰ï¼ˆ3.0+ é»˜è®¤å¼€å¯ï¼‰

KafkaProducer<String, String> producer = new KafkaProducer<>(props);
producer.send(new ProducerRecord<>("my-topic", "key", "value"), (metadata, exception) -> {
    if (exception == null) {
        System.out.printf("Sent to partition %d, offset %d%n",
            metadata.partition(), metadata.offset());
    } else {
        exception.printStackTrace();
    }
});
```

#### 2.2.2 é‡è¯•ä¸å¹‚ç­‰æœºåˆ¶

```mermaid
sequenceDiagram
    participant Producer as Producer
    participant Broker as Broker Leader

    Producer->>Broker: ProduceRequest (PID=1, Seq=0, batch=[msg1,msg2])
    Broker->>Broker: å†™å…¥ Log, è®°å½• PID=1 æœ€æ–° Seq=1
    Broker-->>Producer: æˆåŠŸ (offset=100)

    Producer->>Broker: ProduceRequest (PID=1, Seq=2, batch=[msg3])
    Note over Broker: ç½‘ç»œè¶…æ—¶ï¼ŒProducer æœªæ”¶åˆ°å“åº”

    Producer->>Broker: é‡è¯•: ProduceRequest (PID=1, Seq=2, batch=[msg3])
    Broker->>Broker: æ£€æŸ¥ PID=1 çš„ Seq: æœŸæœ› 2, æ”¶åˆ° 2 â†’ æ­£å¸¸å†™å…¥
    Broker-->>Producer: æˆåŠŸ (offset=102)

    Producer->>Broker: å†æ¬¡é‡è¯•ï¼ˆç½‘ç»œæŠ–åŠ¨ï¼‰: ProduceRequest (PID=1, Seq=2, batch=[msg3])
    Broker->>Broker: æ£€æŸ¥ PID=1 çš„ Seq: æœŸæœ› 3, æ”¶åˆ° 2 â†’ é‡å¤! è¿”å›æˆåŠŸä½†ä¸å†™å…¥
    Broker-->>Producer: æˆåŠŸ (offset=102, å¹‚ç­‰å»é‡)
```

ğŸ¯ **å¹‚ç­‰ Producer åŸç†**ï¼š
- æ¯ä¸ª Producer å®ä¾‹å¯åŠ¨æ—¶è·å¾—ä¸€ä¸ªå”¯ä¸€çš„ `Producer ID (PID)`
- æ¯æ¡æ¶ˆæ¯æºå¸¦ `<PID, Partition, SequenceNumber>`
- Broker ç«¯ä¸ºæ¯ä¸ª `<PID, Partition>` ç»´æŠ¤æœ€æ–°çš„ Sequence Number
- å¦‚æœæ”¶åˆ°çš„ Seq â‰¤ å·²è®°å½•çš„ Seqï¼Œåˆ¤å®šä¸ºé‡å¤æ¶ˆæ¯ï¼Œè¿”å›æˆåŠŸä½†ä¸é‡å¤å†™å…¥
- å¦‚æœæ”¶åˆ°çš„ Seq > å·²è®°å½•çš„ Seq + 1ï¼Œè¯´æ˜æœ‰æ¶ˆæ¯ä¸¢å¤±ï¼Œè¿”å› `OutOfOrderSequenceException`

âš ï¸ **æ˜“é”™ç‚¹**ï¼šå¹‚ç­‰ Producer åªä¿è¯å•åˆ†åŒºå†…çš„å»é‡ã€‚è·¨åˆ†åŒºçš„ Exactly-Once éœ€è¦ä½¿ç”¨äº‹åŠ¡ï¼ˆTransactional Producerï¼‰ã€‚

### 2.3 æ¶ˆæ¯æ¶ˆè´¹æµç¨‹

#### 2.3.1 Consumer Group ä¸ Rebalance

```mermaid
sequenceDiagram
    participant C1 as Consumer 1
    participant C2 as Consumer 2
    participant GC as Group Coordinator<br/>(Broker)

    Note over C1,GC: --- åŠ å…¥é˜¶æ®µ ---
    C1->>GC: JoinGroup (group=g1, protocols=[range,roundrobin])
    C2->>GC: JoinGroup (group=g1, protocols=[range,roundrobin])
    GC->>GC: é€‰ä¸¾ C1 ä¸º Group Leader
    GC-->>C1: JoinGroupResponse (leader=C1, members=[C1,C2])
    GC-->>C2: JoinGroupResponse (leader=C1, members=[])

    Note over C1,GC: --- åŒæ­¥é˜¶æ®µ ---
    C1->>C1: Leader æ‰§è¡Œåˆ†åŒºåˆ†é…ç®—æ³•
    C1->>GC: SyncGroup (assignments: C1â†’[P0,P1], C2â†’[P2,P3])
    C2->>GC: SyncGroup (ç©º)
    GC-->>C1: SyncGroupResponse (assignment: [P0,P1])
    GC-->>C2: SyncGroupResponse (assignment: [P2,P3])

    Note over C1,GC: --- æ¶ˆè´¹é˜¶æ®µ ---
    C1->>GC: Heartbeat (æ¯ heartbeat.interval.ms)
    C2->>GC: Heartbeat
    C1->>GC: Fetch (partitions=[P0,P1], offsets=[100,200])
    GC-->>C1: FetchResponse (records...)
```

**Rebalance è§¦å‘æ¡ä»¶**ï¼š
1. Consumer åŠ å…¥æˆ–ç¦»å¼€ Group
2. Consumer å¿ƒè·³è¶…æ—¶ï¼ˆ`session.timeout.ms`ï¼Œé»˜è®¤ 45sï¼‰
3. Consumer å¤„ç†æ¶ˆæ¯è¶…æ—¶ï¼ˆ`max.poll.interval.ms`ï¼Œé»˜è®¤ 5 åˆ†é’Ÿï¼‰
4. Topic åˆ†åŒºæ•°å˜åŒ–
5. è®¢é˜…çš„ Topic åˆ—è¡¨å˜åŒ–ï¼ˆæ­£åˆ™åŒ¹é…æ—¶æ–° Topic å‡ºç°ï¼‰

**Offset ç®¡ç†**ï¼š

```java
// è‡ªåŠ¨æäº¤ï¼ˆé»˜è®¤ï¼‰
props.put("enable.auto.commit", true);
props.put("auto.commit.interval.ms", 5000); // æ¯ 5 ç§’è‡ªåŠ¨æäº¤

// æ‰‹åŠ¨æäº¤ï¼ˆæ¨èç”Ÿäº§ä½¿ç”¨ï¼‰
props.put("enable.auto.commit", false);

KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
consumer.subscribe(Arrays.asList("my-topic"));

while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    for (ConsumerRecord<String, String> record : records) {
        // å¤„ç†æ¶ˆæ¯
        processRecord(record);
    }
    consumer.commitSync(); // åŒæ­¥æäº¤ offset
}
```

âš ï¸ **æ˜“é”™ç‚¹**ï¼šè‡ªåŠ¨æäº¤ Offset å¯èƒ½å¯¼è‡´æ¶ˆæ¯ä¸¢å¤±ï¼ˆæäº¤äº†ä½†å¤„ç†å¤±è´¥ï¼‰æˆ–é‡å¤æ¶ˆè´¹ï¼ˆå¤„ç†äº†ä½†æœªæäº¤ï¼‰ã€‚ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨æ‰‹åŠ¨æäº¤ï¼Œå¹¶åœ¨æ¶ˆæ¯å¤„ç†æˆåŠŸåå†æäº¤ã€‚

### 2.4 å‰¯æœ¬åŒæ­¥ä¸ ISR æœºåˆ¶

#### 2.4.1 æ­£å¸¸å‰¯æœ¬åŒæ­¥æµç¨‹

```mermaid
sequenceDiagram
    participant Producer as Producer
    participant Leader as Leader (Broker 1)
    participant F1 as Follower 1 (Broker 2)
    participant F2 as Follower 2 (Broker 3)

    Producer->>Leader: ProduceRequest (acks=all)
    Leader->>Leader: å†™å…¥æœ¬åœ° Log (offset=100)

    par å¹¶è¡Œæ‹‰å–
        F1->>Leader: FetchRequest (offset=100)
        F2->>Leader: FetchRequest (offset=100)
    end

    Leader-->>F1: FetchResponse (records at offset=100)
    Leader-->>F2: FetchResponse (records at offset=100)
    F1->>F1: å†™å…¥æœ¬åœ° Log
    F2->>F2: å†™å…¥æœ¬åœ° Log

    Note over Leader: ISR=[Leader,F1,F2] å…¨éƒ¨åŒæ­¥å®Œæˆ
    Leader->>Leader: æ¨è¿› High Watermark (HW=101)
    Leader-->>Producer: ProduceResponse (æˆåŠŸ, offset=100)
```

**å…³é”®æ¦‚å¿µ**ï¼š

```
åˆ†åŒºæ—¥å¿—çš„æ°´ä½çº¿ï¼š

LEO (Log End Offset)     = æ¯ä¸ªå‰¯æœ¬æœ€æ–°å†™å…¥çš„ä¸‹ä¸€ä¸ª offset
HW  (High Watermark)     = æ‰€æœ‰ ISR å‰¯æœ¬ä¸­æœ€å°çš„ LEO
                           æ¶ˆè´¹è€…åªèƒ½è¯»åˆ° HW ä¹‹å‰çš„æ¶ˆæ¯

Leader:    [msg0][msg1][msg2][msg3][msg4]  LEO=5
Follower1: [msg0][msg1][msg2][msg3]        LEO=4
Follower2: [msg0][msg1][msg2]              LEO=3
                                    HW=3 â†‘
                                    (æ¶ˆè´¹è€…åªèƒ½è¯»åˆ° offset 0,1,2)
```

#### 2.4.2 Leader æ•…éšœåˆ‡æ¢

```mermaid
stateDiagram-v2
    [*] --> æ­£å¸¸è¿è¡Œ: ISR=[B1(Leader),B2,B3]
    æ­£å¸¸è¿è¡Œ --> Leaderå®•æœº: Broker 1 æ•…éšœ
    Leaderå®•æœº --> Controlleræ£€æµ‹: Controller é€šè¿‡å¿ƒè·³æ£€æµ‹
    Controlleræ£€æµ‹ --> é€‰ä¸¾æ–°Leader: ä» ISR ä¸­é€‰æ‹©æ–° Leader
    é€‰ä¸¾æ–°Leader --> B2æˆä¸ºLeader: B2 çš„ LEO æœ€å¤§
    B2æˆä¸ºLeader --> æ›´æ–°å…ƒæ•°æ®: Controller å¹¿æ’­ LeaderAndISR è¯·æ±‚
    æ›´æ–°å…ƒæ•°æ® --> æ­£å¸¸è¿è¡Œ: ISR=[B2(Leader),B3]

    Leaderå®•æœº --> ISRä¸ºç©º: æ‰€æœ‰ ISR å‰¯æœ¬éƒ½å®•æœº
    ISRä¸ºç©º --> ç­‰å¾…æ¢å¤: unclean.leader.election.enable=false
    ISRä¸ºç©º --> éISRé€‰ä¸¾: unclean.leader.election.enable=true
    éISRé€‰ä¸¾ --> å¯èƒ½ä¸¢æ•°æ®: é ISR å‰¯æœ¬æ•°æ®å¯èƒ½è½å
    ç­‰å¾…æ¢å¤ --> æ­£å¸¸è¿è¡Œ: ISR å‰¯æœ¬æ¢å¤
```

âš ï¸ **æ˜“é”™ç‚¹**ï¼š`unclean.leader.election.enable` é»˜è®¤ä¸º `false`ï¼ˆKafka 2.0+ï¼‰ã€‚è®¾ä¸º `true` å¯ä»¥åœ¨æ‰€æœ‰ ISR å‰¯æœ¬å®•æœºæ—¶ä»é ISR å‰¯æœ¬é€‰ä¸¾ Leaderï¼Œæé«˜å¯ç”¨æ€§ä½†å¯èƒ½ä¸¢æ•°æ®ã€‚é‡‘èåœºæ™¯åŠ¡å¿…ä¿æŒ `false`ã€‚

### 2.5 å…³é”®ç®—æ³•/åè®®è¯¦è§£

#### 2.5.1 KRaftï¼ˆKafka Raftï¼‰åè®®

KRaft æ˜¯ Kafka åŸºäº Raft è®ºæ–‡å®ç°çš„å…±è¯†åè®®ï¼Œç”¨äºç®¡ç†é›†ç¾¤å…ƒæ•°æ®ã€‚

**ä¸æ ‡å‡† Raft çš„å·®å¼‚**ï¼š
- ä½¿ç”¨ **Pull æ¨¡å¼**ï¼ˆFollower ä¸»åŠ¨æ‹‰å–ï¼‰è€Œéæ ‡å‡† Raft çš„ Push æ¨¡å¼ï¼ˆLeader æ¨é€ï¼‰ï¼Œä¸ Kafka çš„ Fetch æœºåˆ¶ä¿æŒä¸€è‡´
- å…ƒæ•°æ®å­˜å‚¨åœ¨å†…éƒ¨ Topic `__cluster_metadata` ä¸­ï¼Œå¤ç”¨ Kafka çš„æ—¥å¿—å­˜å‚¨æœºåˆ¶
- æ”¯æŒ **Snapshot** æœºåˆ¶ï¼Œå®šæœŸå¯¹å…ƒæ•°æ®çŠ¶æ€åšå¿«ç…§ï¼Œé¿å…æ—¥å¿—æ— é™å¢é•¿

```properties
# KRaft æ¨¡å¼ Broker é…ç½®ï¼ˆserver.propertiesï¼‰
process.roles=broker,controller    # åŒæ—¶æ‹…ä»» broker å’Œ controller
node.id=1
controller.quorum.voters=1@broker1:9093,2@broker2:9093,3@broker3:9093
controller.listener.names=CONTROLLER
listeners=PLAINTEXT://:9092,CONTROLLER://:9093
log.dirs=/var/kafka-logs
```

#### 2.5.2 åˆ†åŒºåˆ†é…ç­–ç•¥

| ç­–ç•¥ | ç±»å | åŸç† | é€‚ç”¨åœºæ™¯ |
|------|------|------|---------|
| Range | `RangeAssignor` | æŒ‰ Topic ç»´åº¦ï¼Œå°†åˆ†åŒºæŒ‰èŒƒå›´åˆ†é…ç»™ Consumer | é»˜è®¤ç­–ç•¥ï¼Œç®€å•ä½†å¯èƒ½ä¸å‡åŒ€ |
| RoundRobin | `RoundRobinAssignor` | å°†æ‰€æœ‰ Topic çš„åˆ†åŒºè½®è¯¢åˆ†é… | æ‰€æœ‰ Consumer è®¢é˜…ç›¸åŒ Topic æ—¶å‡åŒ€ |
| Sticky | `StickyAssignor` | åœ¨å‡åŒ€çš„åŸºç¡€ä¸Šï¼ŒRebalance æ—¶å°½é‡ä¿æŒåŸæœ‰åˆ†é… | å‡å°‘ Rebalance å¼€é”€ |
| CooperativeSticky | `CooperativeStickyAssignor` | Sticky + åä½œå¼ Rebalanceï¼ˆå¢é‡å¼ï¼Œä¸åœæ­¢æ‰€æœ‰æ¶ˆè´¹ï¼‰ | **3.x æ¨è**ï¼Œå‡å°‘ Rebalance å½±å“ |

#### 2.5.3 Log Compactionï¼ˆæ—¥å¿—å‹ç¼©ï¼‰

```
æ™®é€šæ—¥å¿—ï¼ˆdelete ç­–ç•¥ï¼‰ï¼š
[K1:V1][K2:V2][K1:V3][K3:V4][K2:V5] â†’ è¶…è¿‡ retention åå…¨éƒ¨åˆ é™¤

å‹ç¼©æ—¥å¿—ï¼ˆcompact ç­–ç•¥ï¼‰ï¼š
[K1:V1][K2:V2][K1:V3][K3:V4][K2:V5]
                â†“ Log Compaction
[K1:V3][K3:V4][K2:V5]  â† æ¯ä¸ª Key åªä¿ç•™æœ€æ–°å€¼

ç”¨é€”ï¼šKafka Streams çš„ Changelog Topicã€Connect çš„ Offset Topicï¼ˆ__consumer_offsetsï¼‰
```

### 2.6 æ•°æ®æ¨¡å‹ä¸å­˜å‚¨ç»“æ„

#### 2.6.1 ç£ç›˜å¸ƒå±€

```
/var/kafka-logs/                          # log.dirs é…ç½®çš„ç›®å½•
â”œâ”€â”€ __cluster_metadata-0/                 # KRaft å…ƒæ•°æ®åˆ†åŒº
â”œâ”€â”€ __consumer_offsets-0/                 # Consumer Offset å†…éƒ¨ Topic
â”œâ”€â”€ my-topic-0/                           # Topic=my-topic, Partition=0
â”‚   â”œâ”€â”€ 00000000000000000000.log          # ç¬¬ä¸€ä¸ª Segment çš„æ•°æ®æ–‡ä»¶ï¼ˆèµ·å§‹ offset=0ï¼‰
â”‚   â”œâ”€â”€ 00000000000000000000.index        # ç¨€ç–åç§»é‡ç´¢å¼•
â”‚   â”œâ”€â”€ 00000000000000000000.timeindex    # ç¨€ç–æ—¶é—´æˆ³ç´¢å¼•
â”‚   â”œâ”€â”€ 00000000000000065536.log          # ç¬¬äºŒä¸ª Segmentï¼ˆèµ·å§‹ offset=65536ï¼‰
â”‚   â”œâ”€â”€ 00000000000000065536.index
â”‚   â”œâ”€â”€ 00000000000000065536.timeindex
â”‚   â”œâ”€â”€ leader-epoch-checkpoint            # Leader Epoch æ£€æŸ¥ç‚¹
â”‚   â””â”€â”€ partition.metadata                 # åˆ†åŒºå…ƒæ•°æ®
â”œâ”€â”€ my-topic-1/                           # Partition=1
â””â”€â”€ ...
```

#### 2.6.2 æ¶ˆæ¯æ ¼å¼ï¼ˆRecordBatchï¼‰

```
RecordBatch ç»“æ„ï¼ˆV2 æ ¼å¼ï¼ŒKafka 0.11+ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RecordBatch Header                                â”‚
â”‚  - baseOffset (8 bytes)        èµ·å§‹ offset        â”‚
â”‚  - batchLength (4 bytes)       batch æ€»é•¿åº¦       â”‚
â”‚  - partitionLeaderEpoch (4B)   Leader Epoch       â”‚
â”‚  - magic (1 byte)              ç‰ˆæœ¬å· = 2         â”‚
â”‚  - crc (4 bytes)               CRC32 æ ¡éªŒ         â”‚
â”‚  - attributes (2 bytes)        å‹ç¼©/äº‹åŠ¡/æ—¶é—´æˆ³ç±»å‹â”‚
â”‚  - lastOffsetDelta (4 bytes)   æœ€åä¸€æ¡çš„ offset å¢é‡â”‚
â”‚  - baseTimestamp (8 bytes)     åŸºå‡†æ—¶é—´æˆ³          â”‚
â”‚  - maxTimestamp (8 bytes)      æœ€å¤§æ—¶é—´æˆ³          â”‚
â”‚  - producerId (8 bytes)        PIDï¼ˆå¹‚ç­‰/äº‹åŠ¡ï¼‰    â”‚
â”‚  - producerEpoch (2 bytes)     Producer Epoch     â”‚
â”‚  - baseSequence (4 bytes)      èµ·å§‹åºåˆ—å·          â”‚
â”‚  - numRecords (4 bytes)        è®°å½•æ•°              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Record 1                                          â”‚
â”‚  - length (varint)             è®°å½•é•¿åº¦            â”‚
â”‚  - attributes (1 byte)                            â”‚
â”‚  - timestampDelta (varint)     æ—¶é—´æˆ³å¢é‡          â”‚
â”‚  - offsetDelta (varint)        offset å¢é‡         â”‚
â”‚  - keyLength (varint) + key                       â”‚
â”‚  - valueLength (varint) + value                   â”‚
â”‚  - numHeaders (varint) + headers[]                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Record 2 ...                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

ğŸ’¡ **è¿›é˜¶æ€è€ƒ**ï¼šKafka ä½¿ç”¨ varint ç¼–ç å’Œå¢é‡å­˜å‚¨ï¼ˆdelta encodingï¼‰æ¥å‹ç¼©æ¶ˆæ¯å…ƒæ•°æ®ã€‚åŒä¸€ä¸ª batch å†…çš„ offset å’Œ timestamp åªå­˜å‚¨ä¸ base çš„å·®å€¼ï¼Œå¤§å¹…å‡å°‘å­˜å‚¨å¼€é”€ã€‚

### 2.7 é€šä¿¡åè®®

Kafka ä½¿ç”¨è‡ªå®šä¹‰çš„äºŒè¿›åˆ¶åè®®ï¼ŒåŸºäº TCPã€‚æ‰€æœ‰è¯·æ±‚/å“åº”éµå¾ªç»Ÿä¸€æ ¼å¼ï¼š

```
è¯·æ±‚æ ¼å¼ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Size (4 bytes)    æ•´ä¸ªè¯·æ±‚çš„é•¿åº¦     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Request Header                      â”‚
â”‚  - api_key (2 bytes)   API ç±»å‹     â”‚
â”‚  - api_version (2 bytes) ç‰ˆæœ¬å·     â”‚
â”‚  - correlation_id (4 bytes) è¯·æ±‚ ID â”‚
â”‚  - client_id (string)  å®¢æˆ·ç«¯æ ‡è¯†   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Request Bodyï¼ˆå–å†³äº api_keyï¼‰       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å¸¸ç”¨ API Keyï¼š
  0  = Produce          å‘é€æ¶ˆæ¯
  1  = Fetch            æ‹‰å–æ¶ˆæ¯
  3  = Metadata         è·å–é›†ç¾¤å…ƒæ•°æ®
  10 = FindCoordinator  æŸ¥æ‰¾ Group Coordinator
  11 = JoinGroup        åŠ å…¥æ¶ˆè´¹è€…ç»„
  14 = SyncGroup        åŒæ­¥åˆ†åŒºåˆ†é…
  22 = InitProducerId   åˆå§‹åŒ–å¹‚ç­‰ Producer
```

> è§ Kafka å®˜æ–¹æ–‡æ¡£ï¼š[Kafka Protocol Guide](https://kafka.apache.org/protocol)

---

## ç¬¬ä¸‰ç« ï¼šæºç çº§å®ç°ç»†èŠ‚

> æœ¬ç« åŸºäº Apache Kafka 3.9.x æºç ï¼ˆ[GitHub: apache/kafka](https://github.com/apache/kafka)ï¼‰ã€‚Kafka ä½¿ç”¨ Java å’Œ Scala ç¼–å†™ï¼Œæ„å»ºç³»ç»Ÿä¸º Gradleã€‚

### 3.1 ä»£ç ç»„ç»‡ç»“æ„

```
kafka/
â”œâ”€â”€ core/                          # Broker ç«¯æ ¸å¿ƒä»£ç ï¼ˆScalaï¼‰
â”‚   â””â”€â”€ src/main/scala/kafka/
â”‚       â”œâ”€â”€ server/                # Broker æœåŠ¡æ ¸å¿ƒ
â”‚       â”‚   â”œâ”€â”€ KafkaServer.scala  # ZK æ¨¡å¼å¯åŠ¨å…¥å£
â”‚       â”‚   â”œâ”€â”€ BrokerServer.scala # KRaft æ¨¡å¼ Broker å¯åŠ¨
â”‚       â”‚   â”œâ”€â”€ ControllerServer.scala # KRaft Controller å¯åŠ¨
â”‚       â”‚   â”œâ”€â”€ KafkaApis.scala    # æ‰€æœ‰ API è¯·æ±‚å¤„ç†å…¥å£
â”‚       â”‚   â”œâ”€â”€ ReplicaManager.scala # å‰¯æœ¬ç®¡ç†ï¼ˆISRã€HWã€Fetchï¼‰
â”‚       â”‚   â””â”€â”€ KafkaConfig.scala  # é…ç½®è§£æ
â”‚       â”œâ”€â”€ log/                   # æ—¥å¿—å­˜å‚¨å¼•æ“
â”‚       â”‚   â”œâ”€â”€ UnifiedLog.scala   # åˆ†åŒºæ—¥å¿—ï¼ˆåŸ Log.scalaï¼‰
â”‚       â”‚   â”œâ”€â”€ LogSegment.scala   # æ®µæ–‡ä»¶ç®¡ç†
â”‚       â”‚   â”œâ”€â”€ LogManager.scala   # æ—¥å¿—ç”Ÿå‘½å‘¨æœŸç®¡ç†
â”‚       â”‚   â””â”€â”€ LogCleaner.scala   # Log Compaction å®ç°
â”‚       â”œâ”€â”€ coordinator/           # åè°ƒå™¨
â”‚       â”‚   â”œâ”€â”€ group/             # Consumer Group åè°ƒ
â”‚       â”‚   â””â”€â”€ transaction/       # äº‹åŠ¡åè°ƒ
â”‚       â”œâ”€â”€ network/               # ç½‘ç»œå±‚
â”‚       â”‚   â”œâ”€â”€ SocketServer.scala # Reactor ç½‘ç»œæ¨¡å‹
â”‚       â”‚   â””â”€â”€ RequestChannel.scala # è¯·æ±‚é˜Ÿåˆ—
â”‚       â””â”€â”€ controller/            # ZK æ¨¡å¼ Controllerï¼ˆdeprecatedï¼‰
â”‚
â”œâ”€â”€ clients/                       # å®¢æˆ·ç«¯ä»£ç ï¼ˆJavaï¼‰
â”‚   â””â”€â”€ src/main/java/org/apache/kafka/
â”‚       â”œâ”€â”€ clients/
â”‚       â”‚   â”œâ”€â”€ producer/          # KafkaProducer å®ç°
â”‚       â”‚   â”‚   â”œâ”€â”€ KafkaProducer.java
â”‚       â”‚   â”‚   â”œâ”€â”€ RecordAccumulator.java
â”‚       â”‚   â”‚   â””â”€â”€ Sender.java
â”‚       â”‚   â”œâ”€â”€ consumer/          # KafkaConsumer å®ç°
â”‚       â”‚   â”‚   â”œâ”€â”€ KafkaConsumer.java
â”‚       â”‚   â”‚   â””â”€â”€ ConsumerCoordinator.java
â”‚       â”‚   â””â”€â”€ NetworkClient.java # åº•å±‚ç½‘ç»œå®¢æˆ·ç«¯
â”‚       â””â”€â”€ common/                # å…¬å…±æ¨¡å—ï¼ˆåè®®ã€åºåˆ—åŒ–ã€é”™è¯¯ç ï¼‰
â”‚
â”œâ”€â”€ raft/                          # KRaft Raft åè®®å®ç°ï¼ˆJavaï¼‰
â”‚   â””â”€â”€ src/main/java/org/apache/kafka/raft/
â”‚       â”œâ”€â”€ KafkaRaftClient.java   # Raft å®¢æˆ·ç«¯æ ¸å¿ƒ
â”‚       â”œâ”€â”€ LeaderState.java       # Leader çŠ¶æ€
â”‚       â”œâ”€â”€ FollowerState.java     # Follower çŠ¶æ€
â”‚       â””â”€â”€ VoterState.java        # æŠ•ç¥¨çŠ¶æ€
â”‚
â”œâ”€â”€ metadata/                      # KRaft å…ƒæ•°æ®ç®¡ç†ï¼ˆJavaï¼‰
â”‚   â””â”€â”€ src/main/java/org/apache/kafka/
â”‚       â”œâ”€â”€ controller/            # KRaft Controller é€»è¾‘
â”‚       â”‚   â”œâ”€â”€ QuorumController.java # åŸºäº Raft çš„ Controller
â”‚       â”‚   â””â”€â”€ ReplicationControlManager.java # å‰¯æœ¬æ§åˆ¶
â”‚       â””â”€â”€ image/                 # å…ƒæ•°æ®å¿«ç…§
â”‚
â”œâ”€â”€ connect/                       # Kafka Connect æ¡†æ¶
â”œâ”€â”€ streams/                       # Kafka Streams æµå¤„ç†åº“
â”œâ”€â”€ tools/                         # å‘½ä»¤è¡Œå·¥å…·
â””â”€â”€ build.gradle                   # Gradle æ„å»ºå…¥å£
```

ğŸ¯ **æ ¸å¿ƒè¦ç‚¹**ï¼š
- `core/` æ˜¯ Broker ç«¯çš„æ ¸å¿ƒï¼Œç”¨ Scala ç¼–å†™ï¼ˆå†å²åŸå› ï¼‰ï¼ŒåŒ…å«ç½‘ç»œå±‚ã€å­˜å‚¨å±‚ã€å‰¯æœ¬ç®¡ç†ã€åè°ƒå™¨
- `clients/` æ˜¯ Producer/Consumer å®¢æˆ·ç«¯ï¼Œç”¨ Java ç¼–å†™ï¼Œæ˜¯å¤§å¤šæ•°å¼€å‘è€…ç›´æ¥ä½¿ç”¨çš„ API
- `raft/` æ˜¯ KRaft çš„ Raft åè®®å®ç°ï¼Œçº¯ Javaï¼Œç‹¬ç«‹äº Broker é€»è¾‘
- `metadata/` æ˜¯ KRaft Controller çš„ä¸šåŠ¡é€»è¾‘ï¼ŒåŸºäº `raft/` æ¨¡å—

### 3.2 å…³é”®æ•°æ®ç»“æ„

#### 3.2.1 ProducerBatchï¼ˆå®¢æˆ·ç«¯ï¼‰

```java
// ç®€åŒ–ç‰ˆ ProducerBatchï¼ˆæºç ä½äº clients/src/.../producer/internals/ProducerBatch.javaï¼‰
public final class ProducerBatch {
    final TopicPartition topicPartition;       // ç›®æ ‡åˆ†åŒº
    final MemoryRecordsBuilder recordsBuilder;  // æ¶ˆæ¯æ„å»ºå™¨ï¼ˆå†™å…¥ ByteBufferï¼‰
    final long createdMs;                       // åˆ›å»ºæ—¶é—´
    final long baseSequence;                    // èµ·å§‹åºåˆ—å·ï¼ˆå¹‚ç­‰ï¼‰

    private int recordCount;                    // å½“å‰è®°å½•æ•°
    private final List<Thunk> thunks;           // æ¯æ¡æ¶ˆæ¯çš„å›è°ƒï¼ˆCallbackï¼‰
    private long lastAttemptMs;                 // æœ€åä¸€æ¬¡å‘é€å°è¯•æ—¶é—´
    private int attempts;                       // é‡è¯•æ¬¡æ•°

    // å°è¯•è¿½åŠ ä¸€æ¡æ¶ˆæ¯åˆ° batch
    public FutureRecordMetadata tryAppend(long timestamp, byte[] key, byte[] value,
                                          Header[] headers, Callback callback, long now) {
        if (!recordsBuilder.hasRoomFor(timestamp, key, value, headers)) {
            return null;  // batch å·²æ»¡ï¼Œè¿”å› null è§¦å‘åˆ›å»ºæ–° batch
        }
        recordsBuilder.append(timestamp, key, value, headers);
        // ... è®°å½•å›è°ƒ
    }
}
```

#### 3.2.2 UnifiedLogï¼ˆBroker ç«¯æ—¥å¿—ï¼‰

```scala
// ç®€åŒ–ç‰ˆ UnifiedLogï¼ˆæºç ä½äº core/src/.../log/UnifiedLog.scalaï¼‰
class UnifiedLog(val logStartOffset: Long,
                 val localLog: LocalLog,        // æœ¬åœ°æ—¥å¿—æ®µç®¡ç†
                 val config: LogConfig,          // æ—¥å¿—é…ç½®
                 val producerStateManager: ProducerStateManager, // å¹‚ç­‰çŠ¶æ€
                 ...) {

  // è¿½åŠ æ¶ˆæ¯ï¼ˆLeader å†™å…¥ï¼‰
  def appendAsLeader(records: MemoryRecords,
                     leaderEpoch: Int,
                     origin: AppendOrigin): LogAppendInfo = {
    // 1. éªŒè¯æ¶ˆæ¯æ ¼å¼ã€CRC
    // 2. åˆ†é… offsetï¼ˆå•è°ƒé€’å¢ï¼‰
    // 3. éªŒè¯å¹‚ç­‰åºåˆ—å·ï¼ˆPID + Seqï¼‰
    // 4. å†™å…¥ activeSegment
    // 5. æ›´æ–° LEO
    append(records, origin, ...)
  }

  // è¯»å–æ¶ˆæ¯ï¼ˆFetch è¯·æ±‚ï¼‰
  def read(startOffset: Long,
           maxLength: Int,
           isolation: FetchIsolation,  // READ_UNCOMMITTED / READ_COMMITTED / LOG_END
           minOneMessage: Boolean): FetchDataInfo = {
    // 1. æ ¹æ® isolation ç¡®å®šå¯è¯»èŒƒå›´ï¼ˆHW æˆ– LSOï¼‰
    // 2. å®šä½ Segment
    // 3. ä½¿ç”¨ FileChannel.transferToï¼ˆé›¶æ‹·è´ï¼‰è¯»å–æ•°æ®
    localLog.read(startOffset, maxLength, ...)
  }
}
```

### 3.3 å¹¶å‘æ¨¡å‹

#### 3.3.1 Reactor ç½‘ç»œæ¨¡å‹

Kafka Broker ä½¿ç”¨ç»å…¸çš„ **å¤š Reactor å¤šçº¿ç¨‹** æ¨¡å‹å¤„ç†ç½‘ç»œè¯·æ±‚ï¼š

```mermaid
graph LR
    subgraph "ç½‘ç»œå±‚ï¼ˆSocketServerï¼‰"
        Acceptor[Acceptor çº¿ç¨‹<br/>ç›‘å¬ç«¯å£, æ¥å—è¿æ¥]
        NP1[Network Processor 1<br/>å¤„ç† I/O è¯»å†™]
        NP2[Network Processor 2]
        NP3[Network Processor N]
    end

    subgraph "è¯·æ±‚é˜Ÿåˆ—"
        RQ[RequestChannel<br/>å…±äº«è¯·æ±‚é˜Ÿåˆ—]
    end

    subgraph "ä¸šåŠ¡å¤„ç†ï¼ˆKafkaRequestHandlerPoolï¼‰"
        H1[Handler çº¿ç¨‹ 1]
        H2[Handler çº¿ç¨‹ 2]
        H3[Handler çº¿ç¨‹ N]
    end

    Client1[å®¢æˆ·ç«¯] --> Acceptor
    Client2[å®¢æˆ·ç«¯] --> Acceptor
    Acceptor --> NP1 & NP2 & NP3
    NP1 & NP2 & NP3 -->|è¯·æ±‚å…¥é˜Ÿ| RQ
    RQ -->|è¯·æ±‚å‡ºé˜Ÿ| H1 & H2 & H3
    H1 & H2 & H3 -->|å“åº”| NP1 & NP2 & NP3
    NP1 & NP2 & NP3 --> Client1 & Client2
```

**çº¿ç¨‹æ¨¡å‹è¯´æ˜**ï¼š

| çº¿ç¨‹ç±»å‹ | æ•°é‡ | é…ç½®å‚æ•° | èŒè´£ |
|---------|------|---------|------|
| Acceptor | æ¯ä¸ª Listener 1 ä¸ª | - | æ¥å—æ–°è¿æ¥ï¼Œè½®è¯¢åˆ†é…ç»™ Network Processor |
| Network Processor | `num.network.threads`ï¼ˆé»˜è®¤ 3ï¼‰ | `num.network.threads` | NIO Selectorï¼Œå¤„ç† Socket è¯»å†™ |
| Request Handler | `num.io.threads`ï¼ˆé»˜è®¤ 8ï¼‰ | `num.io.threads` | æ‰§è¡Œä¸šåŠ¡é€»è¾‘ï¼ˆProduceã€Fetchã€Metadata ç­‰ï¼‰ |
| Purgatory Reaper | å°‘é‡ | - | æ¸…ç†å»¶è¿Ÿæ“ä½œä¸­å·²è¶…æ—¶çš„è¯·æ±‚ |

#### 3.3.2 Purgatoryï¼ˆå»¶è¿Ÿæ“ä½œï¼‰

Kafka ä¸­å¾ˆå¤šæ“ä½œéœ€è¦"ç­‰å¾…æ¡ä»¶æ»¡è¶³åå†å“åº”"ï¼Œä¾‹å¦‚ï¼š
- `acks=all` çš„ Produce è¯·æ±‚éœ€è¦ç­‰å¾…æ‰€æœ‰ ISR å‰¯æœ¬åŒæ­¥å®Œæˆ
- `fetch.min.bytes` çš„ Fetch è¯·æ±‚éœ€è¦ç­‰å¾…è¶³å¤Ÿçš„æ•°æ®

Kafka ä½¿ç”¨ **Purgatoryï¼ˆç‚¼ç‹±ï¼‰** æœºåˆ¶å®ç°å»¶è¿Ÿæ“ä½œï¼š

```scala
// ç®€åŒ–ç‰ˆ DelayedOperation
abstract class DelayedOperation(delayMs: Long) extends TimerTask {
  // å°è¯•å®Œæˆæ“ä½œï¼ˆæ¡ä»¶æ˜¯å¦æ»¡è¶³ï¼‰
  def tryComplete(): Boolean

  // æ¡ä»¶æ»¡è¶³æ—¶çš„å›è°ƒ
  def onComplete(): Unit

  // è¶…æ—¶æ—¶çš„å›è°ƒ
  def onExpiration(): Unit
}

// ç¤ºä¾‹ï¼šDelayedProduce
// å½“ acks=all æ—¶ï¼ŒProduce è¯·æ±‚è¿›å…¥ Purgatory
// æ¯æ¬¡ Follower Fetch æ¨è¿› HW åï¼Œå°è¯• tryComplete
// å¦‚æœæ‰€æœ‰ ISR éƒ½åŒæ­¥å®Œæˆ â†’ onComplete â†’ è¿”å›å“åº”
// å¦‚æœè¶…æ—¶ â†’ onExpiration â†’ è¿”å›è¶…æ—¶é”™è¯¯
```

### 3.4 é‡è¦ç±»/æ¥å£è®¾è®¡

#### 3.4.1 KafkaApis â€” è¯·æ±‚è·¯ç”±ä¸­å¿ƒ

```scala
// æºç ä½äº core/src/.../server/KafkaApis.scala
class KafkaApis(/* ... */) {
  // æ‰€æœ‰ API è¯·æ±‚çš„å…¥å£
  def handle(request: RequestChannel.Request): Unit = {
    request.header.apiKey match {
      case ApiKeys.PRODUCE            => handleProduceRequest(request)
      case ApiKeys.FETCH              => handleFetchRequest(request)
      case ApiKeys.LIST_OFFSETS       => handleListOffsetRequest(request)
      case ApiKeys.METADATA           => handleTopicMetadataRequest(request)
      case ApiKeys.OFFSET_COMMIT      => handleOffsetCommitRequest(request)
      case ApiKeys.OFFSET_FETCH       => handleOffsetFetchRequest(request)
      case ApiKeys.FIND_COORDINATOR   => handleFindCoordinatorRequest(request)
      case ApiKeys.JOIN_GROUP         => handleJoinGroupRequest(request)
      case ApiKeys.SYNC_GROUP         => handleSyncGroupRequest(request)
      case ApiKeys.HEARTBEAT          => handleHeartbeatRequest(request)
      case ApiKeys.INIT_PRODUCER_ID   => handleInitProducerIdRequest(request)
      // ... 60+ API ç±»å‹
    }
  }
}
```

#### 3.4.2 ReplicaManager â€” å‰¯æœ¬ç®¡ç†æ ¸å¿ƒ

```scala
// æºç ä½äº core/src/.../server/ReplicaManager.scala
class ReplicaManager(/* ... */) {
  // å¤„ç† Produce è¯·æ±‚
  def appendToLocalLog(/* ... */): Map[TopicPartition, LogAppendResult]

  // å¤„ç† Fetch è¯·æ±‚ï¼ˆConsumer å’Œ Follower å…±ç”¨ï¼‰
  def fetchMessages(/* ... */): Unit

  // ISR å˜æ›´
  def maybeShrinkIsr(): Unit   // ç¼©å‡ ISRï¼ˆFollower è½åï¼‰
  def maybeExpandIsr(): Unit   // æ‰©å±• ISRï¼ˆFollower è¿½ä¸Šï¼‰

  // Leader/Follower è§’è‰²åˆ‡æ¢
  def becomeLeaderOrFollower(/* ... */): Unit
}
```

### 3.5 å¯åŠ¨æµç¨‹

Kafka 3.9.x KRaft æ¨¡å¼çš„å¯åŠ¨æµç¨‹ï¼š

```mermaid
graph TB
    A["main() â€” Kafka.scala"] --> B["KafkaRaftServer æˆ– KafkaServer"]
    B --> C{process.roles?}
    C -->|broker,controller| D["å¯åŠ¨ BrokerServer + ControllerServer"]
    C -->|broker| E["ä»…å¯åŠ¨ BrokerServer"]
    C -->|controller| F["ä»…å¯åŠ¨ ControllerServer"]

    D --> G["ControllerServer.startup()"]
    G --> G1["åˆå§‹åŒ– RaftManager<br/>åŠ å…¥ Raft Quorum"]
    G1 --> G2["åˆå§‹åŒ– QuorumController<br/>åŠ è½½å…ƒæ•°æ®å¿«ç…§"]
    G2 --> G3["å¼€å§‹å¤„ç†å…ƒæ•°æ®å˜æ›´"]

    D --> H["BrokerServer.startup()"]
    H --> H1["åˆå§‹åŒ– SocketServer<br/>ï¼ˆAcceptor + NetworkProcessorï¼‰"]
    H1 --> H2["åˆå§‹åŒ– LogManager<br/>åŠ è½½æ‰€æœ‰åˆ†åŒºæ—¥å¿—"]
    H2 --> H3["åˆå§‹åŒ– ReplicaManager"]
    H3 --> H4["åˆå§‹åŒ– GroupCoordinator"]
    H4 --> H5["åˆå§‹åŒ– TransactionCoordinator"]
    H5 --> H6["æ³¨å†Œåˆ° Controller<br/>ï¼ˆBrokerRegistrationï¼‰"]
    H6 --> H7["å¼€å§‹æ¥å—å®¢æˆ·ç«¯è¯·æ±‚"]
    H7 --> I["âœ… Broker å°±ç»ª"]

    style I fill:#c8e6c9
```

```bash
# KRaft æ¨¡å¼ï¿½ï¿½ï¿½åŠ¨å‘½ä»¤
# 1. ç”Ÿæˆé›†ç¾¤ ID
KAFKA_CLUSTER_ID="$(bin/kafka-storage.sh random-uuid)"

# 2. æ ¼å¼åŒ–å­˜å‚¨ç›®å½•
bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c config/kraft/server.properties

# 3. å¯åŠ¨ Broker
bin/kafka-server-start.sh config/kraft/server.properties
```

---

## ç¬¬å››ç« ï¼šè®¾è®¡æ¨¡å¼æ·±åº¦å‰–æ

### 4.1 æ¶æ„å±‚é¢çš„æ¨¡å¼

#### 4.1.1 Controller æ¨¡å¼

Kafka é›†ç¾¤ä¸­æœ‰ä¸”ä»…æœ‰ä¸€ä¸ª Active Controllerï¼Œè´Ÿè´£æ‰€æœ‰å…ƒæ•°æ®å†³ç­–ï¼ˆåˆ†åŒºåˆ†é…ã€Leader é€‰ä¸¾ã€ISR å˜æ›´ï¼‰ã€‚å…¶ä»– Broker è¢«åŠ¨æ¥æ”¶ Controller çš„æŒ‡ä»¤ã€‚

**KRaft æ¨¡å¼ä¸‹çš„ Controller**ï¼š
- Controller èŠ‚ç‚¹ç»„æˆ Raft Quorumï¼Œé€šè¿‡ Raft é€‰ä¸¾äº§ç”Ÿ Active Controller
- å…ƒæ•°æ®å˜æ›´ä»¥ Raft Log çš„å½¢å¼å¤åˆ¶åˆ°æ‰€æœ‰ Controller èŠ‚ç‚¹
- Broker é€šè¿‡ `MetadataFetch` è¯·æ±‚ä» Controller æ‹‰å–æœ€æ–°å…ƒæ•°æ®
- ä¸ ZK æ¨¡å¼çš„å…³é”®åŒºåˆ«ï¼šå…ƒæ•°æ®å˜æ›´æ˜¯äº‹ä»¶é©±åŠ¨çš„æ—¥å¿—æµï¼Œè€Œé ZK çš„ Watch é€šçŸ¥

#### 4.1.2 æ—¥å¿—æŠ½è±¡ï¼ˆAppend-Only Logï¼‰

Kafka çš„æ ¸å¿ƒæŠ½è±¡æ˜¯ **ä¸å¯å˜çš„è¿½åŠ æ—¥å¿—ï¼ˆImmutable Append-Only Logï¼‰**ã€‚è¿™ä¸ªæŠ½è±¡è´¯ç©¿æ•´ä¸ªç³»ç»Ÿï¼š

```
åº”ç”¨åœºæ™¯                    æ—¥å¿—å®ä¾‹
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ï¿½ï¿½ï¿½â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
æ¶ˆæ¯å­˜å‚¨                    Topic Partition Log
Consumer Offset å­˜å‚¨        __consumer_offsetsï¼ˆCompacted Logï¼‰
äº‹åŠ¡çŠ¶æ€å­˜å‚¨                __transaction_stateï¼ˆCompacted Logï¼‰
é›†ç¾¤å…ƒæ•°æ®å­˜å‚¨ï¼ˆKRaftï¼‰      __cluster_metadataï¼ˆRaft Logï¼‰
```

**ä¸ºä»€ä¹ˆé€‰æ‹©æ—¥å¿—æŠ½è±¡**ï¼š
- é¡ºåºå†™å…¥ â†’ ç£ç›˜é¡ºåº I/Oï¼Œæ€§èƒ½æ¥è¿‘å†…å­˜
- ä¸å¯å˜ â†’ æ— éœ€åŠ é”ï¼Œå¤©ç„¶æ”¯æŒå¹¶å‘è¯»
- æœ‰åº â†’ é€šè¿‡ offset å®ç°ç²¾ç¡®çš„æ¶ˆæ¯å®šä½å’Œå›æº¯
- å¯å¤åˆ¶ â†’ Follower åªéœ€è¿½åŠ  Leader çš„æ—¥å¿—å³å¯ä¿æŒåŒæ­¥

### 4.2 GoF è®¾è®¡æ¨¡å¼åœ¨æºç ä¸­çš„åº”ç”¨

#### 4.2.1 ç­–ç•¥æ¨¡å¼ï¼ˆStrategyï¼‰â€” åˆ†åŒºå™¨

Producer çš„åˆ†åŒºç­–ç•¥æ˜¯å…¸å‹çš„ç­–ç•¥æ¨¡å¼ï¼š

```java
// ç­–ç•¥æ¥å£ï¼ˆclients/src/.../clients/producer/Partitioner.javaï¼‰
public interface Partitioner extends Configurable, Closeable {
    int partition(String topic, Object key, byte[] keyBytes,
                  Object value, byte[] valueBytes, Cluster cluster);
}

// å…·ä½“ç­–ç•¥
// 1. DefaultPartitioner â€” æœ‰ Key ç”¨ murmur2 hashï¼Œæ—  Key ç”¨ Sticky
// 2. RoundRobinPartitioner â€” è½®è¯¢
// 3. UniformStickyPartitioner â€” ç²˜æ€§åˆ†åŒºï¼ˆå‡å°‘å° batchï¼‰
// 4. ç”¨æˆ·è‡ªå®šä¹‰ Partitioner

// ä½¿ç”¨æ–¹å¼
props.put("partitioner.class", "com.example.MyPartitioner");
```

#### 4.2.2 è§‚å¯Ÿè€…æ¨¡å¼ï¼ˆObserverï¼‰â€” MetadataListener

Broker å†…éƒ¨ä½¿ç”¨è§‚å¯Ÿè€…æ¨¡å¼ç›‘å¬å…ƒæ•°æ®å˜æ›´ï¼š

```java
// KRaft æ¨¡å¼ä¸‹ï¼ŒBroker æ³¨å†Œ MetadataListener ç›‘å¬ Controller çš„å…ƒæ•°æ®å˜æ›´
// å½“ Topic åˆ›å»ºã€åˆ†åŒºé‡åˆ†é…ã€ISR å˜æ›´æ—¶ï¼ŒListener è¢«é€šçŸ¥
public interface RaftClient.Listener<T> {
    void handleCommit(BatchReader<T> reader);    // æ–°çš„å…ƒæ•°æ®æäº¤
    void handleLoadSnapshot(SnapshotReader<T> reader); // åŠ è½½å¿«ç…§
    void handleLeaderChange(LeaderAndEpoch leaderAndEpoch); // Leader å˜æ›´
}
```

#### 4.2.3 æ„å»ºè€…æ¨¡å¼ï¼ˆBuilderï¼‰â€” ProducerRecord / ConsumerRecord

```java
// Kafka å¹¿æ³›ä½¿ç”¨ Builder æ¨¡å¼æ„å»ºå¤æ‚å¯¹è±¡
// ç¤ºä¾‹ï¼šAdminClient åˆ›å»º Topic
NewTopic newTopic = new NewTopic("my-topic", 6, (short) 3)
    .configs(Map.of(
        "retention.ms", "604800000",
        "cleanup.policy", "delete"
    ));

AdminClient admin = AdminClient.create(props);
admin.createTopics(Collections.singleton(newTopic));
```

#### 4.2.4 æ¨¡æ¿æ–¹æ³•æ¨¡å¼ï¼ˆTemplate Methodï¼‰â€” AbstractFetcherThread

```scala
// Follower æ‹‰å– Leader æ•°æ®çš„æŠ½è±¡æ¨¡æ¿
// æºç ä½äº core/src/.../server/AbstractFetcherThread.scala
abstract class AbstractFetcherThread(/* ... */) {
  // æ¨¡æ¿æ–¹æ³•ï¼šå®šä¹‰ Fetch æµç¨‹éª¨æ¶
  def doWork(): Unit = {
    maybeTruncate()           // 1. å¯èƒ½éœ€è¦æˆªæ–­æ—¥å¿—
    maybeFetch()              // 2. å‘é€ Fetch è¯·æ±‚
    // â†’ å­ç±»å®ç°å…·ä½“çš„ processPartitionData()
  }

  // å­ç±»å®ç°ï¼šå¤„ç†æ‹‰å–åˆ°çš„æ•°æ®
  protected def processPartitionData(/* ... */): Option[LogAppendInfo]

  // å­ç±»å®ç°ï¼šæˆªæ–­æ—¥å¿—
  protected def truncate(/* ... */): Unit
}

// å…·ä½“å®ç°
class ReplicaFetcherThread extends AbstractFetcherThread { ... }
```

### 4.3 åˆ†å¸ƒå¼ç³»ç»Ÿæ¨¡å¼

#### 4.3.1 Leader Electionï¼ˆé¢†å¯¼è€…é€‰ä¸¾ï¼‰

Kafka ä¸­æœ‰ä¸¤å±‚ Leader é€‰ä¸¾ï¼š

| å±‚çº§ | é€‰ä¸¾å¯¹è±¡ | æœºåˆ¶ | è§¦å‘æ¡ä»¶ |
|------|---------|------|---------|
| Controller é€‰ä¸¾ | Active Controller | KRaft Raft åè®®ï¼ˆå¤šæ•°æ´¾æŠ•ç¥¨ï¼‰ | Controller èŠ‚ç‚¹æ•…éšœ |
| Partition Leader é€‰ä¸¾ | åˆ†åŒº Leader å‰¯æœ¬ | Controller ä» ISR ä¸­æŒ‡å®š | Broker æ•…éšœã€æ‰‹åŠ¨é‡åˆ†é… |

#### 4.3.2 Epoch Fencingï¼ˆçºªå…ƒéš”ç¦»ï¼‰

Kafka ä½¿ç”¨ Epoch æœºåˆ¶é˜²æ­¢"è„‘è£‚"å’Œè¿‡æœŸè¯·æ±‚ï¼š

```
Leader Epoch æœºåˆ¶ï¼š
- æ¯æ¬¡ Leader åˆ‡æ¢ï¼ŒEpoch é€’å¢
- Follower æ‹‰å–æ•°æ®æ—¶æºå¸¦ Leader Epoch
- å¦‚æœ Broker æ”¶åˆ°æ—§ Epoch çš„è¯·æ±‚ï¼Œç›´æ¥æ‹’ç»

ç¤ºä¾‹ï¼š
  Epoch=5: Broker 1 æ˜¯ Leader
  Broker 1 å®•æœº â†’ Epoch=6: Broker 2 æˆä¸ºæ–° Leader
  Broker 1 æ¢å¤ï¼Œä»ä»¥ Epoch=5 å‘é€è¯·æ±‚ â†’ è¢«æ‹’ç»
  Broker 1 å‘ç°æ–° Epoch=6 â†’ æˆªæ–­å¤šä½™æ—¥å¿— â†’ ä½œä¸º Follower åŒæ­¥
```

### 4.4 è®¾è®¡æƒè¡¡åˆ†æ

| è®¾è®¡å†³ç­– | é€‰æ‹© | æ›¿ä»£æ–¹æ¡ˆ | æƒè¡¡ç†ç”± |
|---------|------|---------|---------|
| æ¶ˆè´¹æ¨¡å‹ | Pullï¼ˆConsumer ä¸»åŠ¨æ‹‰å–ï¼‰ | Pushï¼ˆBroker æ¨é€ï¼‰ | Pull è®© Consumer æ§åˆ¶æ¶ˆè´¹é€Ÿç‡ï¼Œé¿å… Broker ç«¯å¤æ‚çš„æµæ§é€»è¾‘ |
| å­˜å‚¨æ¨¡å‹ | è¿½åŠ æ—¥å¿— + é¡ºåº I/O | B-Tree ç´¢å¼• | é¡ºåºå†™æ€§èƒ½æé«˜ï¼Œä½†ä¸æ”¯æŒæŒ‰ Key éšæœºæŸ¥è¯¢ |
| å‰¯æœ¬åŒæ­¥ | ISRï¼ˆåŠ¨æ€åŒæ­¥å‰¯æœ¬é›†ï¼‰ | å›ºå®šå¤šæ•°æ´¾ï¼ˆRaftï¼‰ | ISR æ›´çµæ´»ï¼Œå…è®¸å‰¯æœ¬æš‚æ—¶è½åè€Œä¸å½±å“å†™å…¥ï¼Œä½†å¯èƒ½åœ¨æç«¯æƒ…å†µä¸‹ä¸¢æ•°æ® |
| æ¶ˆæ¯ä¿ç•™ | åŸºäºæ—¶é—´/å¤§å°çš„ä¿ç•™ç­–ç•¥ | æ¶ˆè´¹å³åˆ é™¤ï¼ˆRabbitMQï¼‰ | æ”¯æŒå¤šæ¶ˆè´¹è€…ã€æ¶ˆæ¯å›æº¯ã€äº‹ä»¶æº¯æº |
| å…ƒæ•°æ®ç®¡ç† | KRaftï¼ˆå†…ç½® Raftï¼‰ | ZooKeeperï¼ˆå¤–éƒ¨ä¾èµ–ï¼‰ | æ¶ˆé™¤å¤–éƒ¨ä¾èµ–ï¼Œç®€åŒ–è¿ç»´ï¼Œæå‡å…ƒæ•°æ®æ›´æ–°æ€§èƒ½ |
| åˆ†åŒºæœ‰åº | åˆ†åŒºå†…æœ‰åºï¼Œåˆ†åŒºé—´æ— åº | å…¨å±€æœ‰åº | åˆ†åŒºæ˜¯å¹¶è¡Œåº¦çš„åŸºæœ¬å•ä½ï¼Œå…¨å±€æœ‰åºä¼šç‰ºç‰²åå |

ğŸ’¡ **è¿›é˜¶æ€è€ƒ**ï¼šKafka çš„ ISR æœºåˆ¶æ˜¯ä¸€ä¸ªç²¾å¦™çš„è®¾è®¡ã€‚ä¸ Raft çš„"å¤šæ•°æ´¾"ä¸åŒï¼ŒISR å…è®¸å‰¯æœ¬é›†åˆåŠ¨æ€å˜åŒ–ã€‚å½“ `acks=all` ä¸” `min.insync.replicas=2` æ—¶ï¼Œåªè¦ ISR ä¸­æœ‰ 2 ä¸ªå‰¯æœ¬ç¡®è®¤å³å¯ï¼Œä¸éœ€è¦ç­‰å¾…æ‰€æœ‰å‰¯æœ¬ã€‚è¿™åœ¨å‰¯æœ¬æš‚æ—¶ä¸å¯ç”¨æ—¶ä»èƒ½ä¿æŒå†™å…¥å¯ç”¨æ€§ã€‚

---

## ç¬¬äº”ç« ï¼šé«˜å¯é ä¸é«˜å¯ç”¨æ–¹æ¡ˆ

### 5.1 é›†ç¾¤éƒ¨ç½²æ¶æ„

| éƒ¨ç½²æ¨¡å¼ | èŠ‚ç‚¹æ•° | Controller | é€‚ç”¨åœºæ™¯ | å®¹é”™èƒ½åŠ› |
|---------|--------|-----------|---------|---------|
| å•æœºï¼ˆCombinedï¼‰ | 1 | åŒä¸€èŠ‚ç‚¹ | å¼€å‘æµ‹è¯• | æ— å®¹é”™ |
| å°é›†ç¾¤ï¼ˆCombinedï¼‰ | 3 | 3 èŠ‚ç‚¹å‡ä¸º broker+controller | ä¸­å°ä¸šåŠ¡ | å®¹å¿ 1 èŠ‚ç‚¹æ•…éšœ |
| ä¸­å‹é›†ç¾¤ï¼ˆåˆ†ç¦»ï¼‰ | 3 Controller + N Broker | ç‹¬ç«‹ Controller | ç”Ÿäº§æ¨è | Controller å’Œ Broker ç‹¬ç«‹å®¹é”™ |
| å¤§å‹é›†ç¾¤ | 3-5 Controller + æ•°å Broker | ç‹¬ç«‹ Controller | å¤§è§„æ¨¡ç”Ÿäº§ | é«˜å¯ç”¨ + é«˜åå |
| è·¨æœºæˆ¿ | å¤šé›†ç¾¤ + MirrorMaker 2 | æ¯é›†ç¾¤ç‹¬ç«‹ | å®¹ç¾ | è·¨åœ°åŸŸå®¹ç¾ |

```properties
# ç”Ÿäº§æ¨èï¼šç‹¬ç«‹ Controller èŠ‚ç‚¹é…ç½®
# controller-server.properties
process.roles=controller
node.id=100
controller.quorum.voters=100@ctrl1:9093,101@ctrl2:9093,102@ctrl3:9093
listeners=CONTROLLER://:9093

# broker-server.properties
process.roles=broker
node.id=1
controller.quorum.voters=100@ctrl1:9093,101@ctrl2:9093,102@ctrl3:9093
listeners=PLAINTEXT://:9092
```

### 5.2 æ•°æ®ä¸€è‡´æ€§ä¿è¯

#### 5.2.1 acks é…ç½®ä¸æ•°æ®å¯é æ€§

| acks å€¼ | å«ä¹‰ | å¯é æ€§ | æ€§èƒ½ | é€‚ç”¨åœºæ™¯ |
|---------|------|--------|------|---------|
| `0` | ä¸ç­‰å¾…ä»»ä½•ç¡®è®¤ | å¯èƒ½ä¸¢æ•°æ® | æœ€é«˜ | æ—¥å¿—ã€ç›‘æ§æŒ‡æ ‡ï¼ˆå…è®¸ä¸¢å¤±ï¼‰ |
| `1` | ç­‰å¾… Leader ç¡®è®¤ | Leader å®•æœºå¯èƒ½ä¸¢ | é«˜ | ä¸€èˆ¬ä¸šåŠ¡ |
| `all`ï¼ˆ-1ï¼‰ | ç­‰å¾…æ‰€æœ‰ ISR ç¡®è®¤ | ä¸ä¸¢æ•°æ®ï¼ˆé…åˆ min.insync.replicasï¼‰ | ä¸­ | é‡‘èã€è®¢å•ç­‰å…³é”®ä¸šåŠ¡ |

**ä¸ä¸¢æ•°æ®çš„é»„é‡‘é…ç½®**ï¼š
```properties
# Producer ç«¯
acks=all
retries=2147483647          # æ— é™é‡è¯•
enable.idempotence=true     # å¹‚ç­‰ï¼ˆ3.0+ é»˜è®¤å¼€å¯ï¼‰
max.in.flight.requests.per.connection=5  # å¹‚ç­‰æ¨¡å¼ä¸‹æœ€å¤§ 5

# Broker ç«¯
min.insync.replicas=2       # ISR æœ€å°‘ 2 ä¸ªå‰¯æœ¬
unclean.leader.election.enable=false  # ç¦æ­¢é ISR é€‰ä¸¾
default.replication.factor=3  # é»˜è®¤ 3 å‰¯æœ¬
```

#### 5.2.2 Exactly-Once è¯­ä¹‰

```java
// äº‹åŠ¡ Producer ç¤ºä¾‹ï¼ˆè·¨åˆ†åŒº Exactly-Onceï¼‰
Properties props = new Properties();
props.put("bootstrap.servers", "broker1:9092");
props.put("transactional.id", "my-transactional-id");  // å¿…é¡»è®¾ç½®
props.put("enable.idempotence", true);

KafkaProducer<String, String> producer = new KafkaProducer<>(props);
producer.initTransactions();

try {
    producer.beginTransaction();
    producer.send(new ProducerRecord<>("topic-a", "key1", "value1"));
    producer.send(new ProducerRecord<>("topic-b", "key2", "value2"));
    // åŒæ—¶æäº¤ Consumer Offsetï¼ˆConsume-Transform-Produce æ¨¡å¼ï¼‰
    producer.sendOffsetsToTransaction(offsets, consumerGroupMetadata);
    producer.commitTransaction();
} catch (Exception e) {
    producer.abortTransaction();
}
```

### 5.3 æ•…éšœæ£€æµ‹ä¸æ¢å¤

#### 5.3.1 Controller Failover

```
KRaft Controller Failover æµç¨‹ï¼š
1. Active Controller å®•æœº
2. å…¶ä»– Controller èŠ‚ç‚¹æ£€æµ‹åˆ°å¿ƒè·³è¶…æ—¶ï¼ˆcontroller.quorum.election.timeout.msï¼‰
3. å‘èµ· Raft é€‰ä¸¾ï¼Œè·å¾—å¤šæ•°ç¥¨çš„èŠ‚ç‚¹æˆä¸ºæ–° Active Controller
4. æ–° Controller ä» Raft Log æˆ– Snapshot æ¢å¤å…ƒæ•°æ®çŠ¶æ€
5. Broker é€šè¿‡ MetadataFetch å‘ç°æ–° Controllerï¼Œå¼€å§‹æ‹‰å–æœ€æ–°å…ƒæ•°æ®
```

#### 5.3.2 Broker æ•…éšœæ¢å¤

```
Broker æ•…éšœæ¢å¤æµç¨‹ï¼š
1. Broker å®•æœº â†’ Controller æ£€æµ‹åˆ° BrokerRegistration è¿‡æœŸ
2. Controller å¯¹è¯¥ Broker ä¸Šçš„æ‰€æœ‰ Leader åˆ†åŒºæ‰§è¡Œ Leader é€‰ä¸¾
3. ä» ISR ä¸­é€‰æ‹©æ–° Leaderï¼Œæ›´æ–°å…ƒæ•°æ®
4. å…¶ä»– Broker å’Œ Client é€šè¿‡ Metadata æ›´æ–°æ„ŸçŸ¥å˜åŒ–
5. æ•…éšœ Broker æ¢å¤åï¼š
   a. é‡æ–°æ³¨å†Œåˆ° Controller
   b. åŠ è½½æœ¬åœ°æ—¥å¿—
   c. ä½œä¸º Follower ä»æ–° Leader æ‹‰å–ç¼ºå¤±æ•°æ®
   d. è¿½ä¸Š Leader åé‡æ–°åŠ å…¥ ISR
```

### 5.4 å®¹ç¾ç­–ç•¥

#### MirrorMaker 2ï¼ˆè·¨é›†ç¾¤å¤åˆ¶ï¼‰

```properties
# mm2.properties â€” MirrorMaker 2 é…ç½®
clusters = source, target
source.bootstrap.servers = source-broker1:9092,source-broker2:9092
target.bootstrap.servers = target-broker1:9092,target-broker2:9092

# å¤åˆ¶ source é›†ç¾¤çš„æ‰€æœ‰ Topic åˆ° target
source->target.enabled = true
source->target.topics = .*

# åŒæ­¥ Consumer Group Offset
sync.group.offsets.enabled = true
emit.heartbeats.enabled = true

# å¯åŠ¨
bin/connect-mirror-maker.sh mm2.properties
```

### 5.5 æ€§èƒ½ä¼˜åŒ–ï¼ˆ30+ è°ƒä¼˜å‚æ•°ï¼‰

#### 5.5.1 Broker ç«¯

| å‚æ•° | é»˜è®¤å€¼ | å»ºè®®å€¼ | è¯´æ˜ |
|------|--------|--------|------|
| `num.network.threads` | 3 | CPU æ ¸æ•° | ç½‘ç»œ I/O çº¿ç¨‹æ•° |
| `num.io.threads` | 8 | CPU æ ¸æ•° * 2 | è¯·æ±‚å¤„ç†çº¿ç¨‹æ•° |
| `socket.send.buffer.bytes` | 100KB | 1MB | Socket å‘é€ç¼“å†²åŒº |
| `socket.receive.buffer.bytes` | 100KB | 1MB | Socket æ¥æ”¶ç¼“ï¿½ï¿½ï¿½åŒº |
| `log.segment.bytes` | 1GB | 1GB | å•ä¸ª Segment æ–‡ä»¶å¤§å° |
| `log.retention.hours` | 168ï¼ˆ7å¤©ï¼‰ | æŒ‰ä¸šåŠ¡éœ€æ±‚ | æ¶ˆæ¯ä¿ç•™æ—¶é—´ |
| `log.retention.bytes` | -1ï¼ˆæ— é™ï¼‰ | æŒ‰ç£ç›˜å®¹é‡ | åˆ†åŒºæ—¥å¿—æœ€å¤§å¤§å° |
| `num.partitions` | 1 | 6-12 | æ–° Topic é»˜è®¤åˆ†åŒºæ•° |
| `default.replication.factor` | 1 | 3 | é»˜è®¤å‰¯æœ¬æ•° |
| `min.insync.replicas` | 1 | 2 | ISR æœ€å°å‰¯æœ¬æ•° |
| `log.flush.interval.messages` | Long.MAX | ä¸å»ºè®®ä¿®æ”¹ | åˆ·ç›˜æ¶ˆæ¯é—´éš”ï¼ˆä¾èµ– OS Page Cacheï¼‰ |
| `replica.fetch.max.bytes` | 1MB | 10MB | Follower å•æ¬¡ Fetch æœ€å¤§å­—èŠ‚æ•° |
| `message.max.bytes` | 1MB | æŒ‰éœ€è°ƒæ•´ | å•æ¡æ¶ˆæ¯æœ€å¤§å¤§å° |
| `compression.type` | producer | lz4 | Broker ç«¯å‹ç¼©ç­–ç•¥ |

#### 5.5.2 Producer ç«¯

| å‚æ•° | é»˜è®¤å€¼ | å»ºè®®å€¼ | è¯´æ˜ |
|------|--------|--------|------|
| `batch.size` | 16KB | 32-64KB | æ‰¹é‡å¤§å°ï¼Œå¢å¤§å¯æé«˜åå |
| `linger.ms` | 0 | 5-20ms | ç­‰å¾…å‡‘æ‰¹æ—¶é—´ |
| `buffer.memory` | 32MB | 64-128MB | Producer ç¼“å†²åŒºæ€»å¤§å° |
| `compression.type` | none | lz4 / zstd | å‹ç¼©ç®—æ³•ï¼ˆzstd å‹ç¼©ç‡æœ€é«˜ï¼Œlz4 é€Ÿåº¦æœ€å¿«ï¼‰ |
| `max.in.flight.requests.per.connection` | 5 | 5 | å¹‚ç­‰æ¨¡å¼ä¸‹æœ€å¤§ 5 |
| `retries` | 2147483647 | 2147483647 | é‡è¯•æ¬¡æ•° |
| `delivery.timeout.ms` | 120000 | 120000 | æ¶ˆæ¯å‘é€æ€»è¶…æ—¶ |
| `max.request.size` | 1MB | æŒ‰éœ€è°ƒæ•´ | å•æ¬¡è¯·æ±‚æœ€å¤§å¤§å° |

#### 5.5.3 Consumer ç«¯

| å‚æ•° | é»˜è®¤å€¼ | å»ºè®®å€¼ | è¯´æ˜ |
|------|--------|--------|------|
| `fetch.min.bytes` | 1 | 1KB-1MB | æœ€å°æ‹‰å–å­—èŠ‚æ•°ï¼ˆå¢å¤§å¯å‡å°‘è¯·æ±‚æ¬¡æ•°ï¼‰ |
| `fetch.max.wait.ms` | 500 | 100-500ms | æœ€å¤§ç­‰å¾…æ—¶é—´ |
| `max.poll.records` | 500 | 100-1000 | å•æ¬¡ poll æœ€å¤§è®°å½•æ•° |
| `max.poll.interval.ms` | 300000 | æŒ‰å¤„ç†æ—¶é—´è°ƒæ•´ | ä¸¤æ¬¡ poll æœ€å¤§é—´éš” |
| `session.timeout.ms` | 45000 | 10000-30000 | å¿ƒè·³è¶…æ—¶ |
| `heartbeat.interval.ms` | 3000 | session.timeout.ms / 3 | å¿ƒè·³é—´éš” |
| `auto.offset.reset` | latest | earliest / latest | æ—  Offset æ—¶ä»å“ªé‡Œå¼€å§‹æ¶ˆè´¹ |
| `max.partition.fetch.bytes` | 1MB | 1-10MB | å•åˆ†åŒºæœ€å¤§æ‹‰å–å­—èŠ‚æ•° |
| `partition.assignment.strategy` | RangeAssignor | CooperativeStickyAssignor | åˆ†åŒºåˆ†é…ç­–ç•¥ |

### 5.6 å¯è§‚æµ‹æ€§

#### 5.6.1 å…³é”® JMX Metrics

| æŒ‡æ ‡ç±»åˆ« | Metric åç§° | è¯´æ˜ | å‘Šè­¦é˜ˆå€¼å»ºè®® |
|---------|------------|------|------------|
| **Broker** | `kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec` | æ¯ç§’æ¥æ”¶æ¶ˆæ¯æ•° | æ ¹æ®åŸºçº¿ |
| **Broker** | `kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec` | æ¯ç§’æ¥æ”¶å­—èŠ‚æ•° | æ ¹æ®ç½‘ç»œå¸¦å®½ |
| **Broker** | `kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions` | å‰¯æœ¬ä¸è¶³çš„åˆ†åŒºæ•° | > 0 éœ€å‘Šè­¦ |
| **Broker** | `kafka.server:type=ReplicaManager,name=IsrShrinksPerSec` | ISR ç¼©å‡é€Ÿç‡ | æŒç»­ > 0 éœ€æ’æŸ¥ |
| **Broker** | `kafka.controller:type=KafkaController,name=ActiveControllerCount` | æ´»è·ƒ Controller æ•° | å¿…é¡» = 1 |
| **Broker** | `kafka.controller:type=KafkaController,name=OfflinePartitionsCount` | ç¦»çº¿åˆ†åŒºæ•° | > 0 éœ€å‘Šè­¦ |
| **Broker** | `kafka.network:type=RequestMetrics,name=TotalTimeMs,request=Produce` | Produce è¯·æ±‚å»¶è¿Ÿ | P99 > 100ms éœ€å…³æ³¨ |
| **Broker** | `kafka.network:type=RequestMetrics,name=TotalTimeMs,request=Fetch` | Fetch è¯·æ±‚å»¶è¿Ÿ | P99 > 100ms éœ€å…³æ³¨ |
| **Consumer** | `kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*,records-lag-max` | æœ€å¤§æ¶ˆè´¹å»¶è¿Ÿ | > 10000 éœ€å‘Šè­¦ |
| **Producer** | `kafka.producer:type=producer-metrics,client-id=*,record-send-rate` | å‘é€é€Ÿç‡ | æ ¹æ®åŸºçº¿ |

```bash
# ä½¿ç”¨ kafka-consumer-groups.sh æŸ¥çœ‹æ¶ˆè´¹å»¶è¿Ÿ
bin/kafka-consumer-groups.sh --bootstrap-server broker1:9092 \
  --describe --group my-consumer-group

# è¾“å‡ºç¤ºä¾‹ï¼š
# GROUP           TOPIC     PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG
# my-group        my-topic  0          1000            1050            50
# my-group        my-topic  1          2000            2000            0
```

> è§ Kafka å®˜æ–¹æ–‡æ¡£ï¼š[Monitoring](https://kafka.apache.org/documentation/#monitoring)

---