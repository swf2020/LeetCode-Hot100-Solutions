# Kubernetes çŸ¥å¤šå°‘ v1.0

> ç‰ˆæœ¬ï¼šKubernetes 1.32ï¼ˆä»£å· "Penelope"ï¼Œ2024å¹´12æœˆå‘å¸ƒï¼‰
> æ–‡æ¡£ç‰ˆæœ¬ï¼šv1.0
> æœ€åæ›´æ–°æ—¶é—´ï¼š2025-01-15

---

## ğŸ“– å‰è¨€

### æŠ€æœ¯èƒŒæ™¯ä¸å­¦ä¹ ä»·å€¼

Kubernetesï¼ˆå¸¸ç¼©å†™ä¸º K8sï¼‰æ˜¯å½“ä»Šäº‘åŸç”Ÿç”Ÿæ€çš„åŸºçŸ³ã€‚è‡ª 2014 å¹´ Google å°†å…¶å¼€æºä»¥æ¥ï¼Œå®ƒå·²ä»ä¸€ä¸ªå®¹å™¨ç¼–æ’å·¥å…·æ¼”å˜ä¸ºæ•´ä¸ªäº‘åŸç”ŸæŠ€æœ¯æ ˆçš„"æ“ä½œç³»ç»Ÿ"ã€‚CNCF 2023 å¹´åº¦è°ƒæŸ¥æ˜¾ç¤ºï¼Œè¶…è¿‡ 84% çš„ç»„ç»‡åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨æˆ–è¯„ä¼° Kubernetesï¼Œå®ƒå·²æˆä¸ºäº‹å®ä¸Šçš„å®¹å™¨ç¼–æ’æ ‡å‡†ã€‚

ğŸ¯ å­¦ä¹  Kubernetes çš„æ ¸å¿ƒä»·å€¼ï¼š
- **èŒä¸šç«äº‰åŠ›**ï¼šäº‘åŸç”Ÿå·²æˆä¸ºåç«¯/è¿ç»´/æ¶æ„å¸ˆçš„å¿…å¤‡æŠ€èƒ½
- **ç³»ç»Ÿè®¾è®¡æ€ç»´**ï¼šK8s çš„å£°æ˜å¼ APIã€æ§åˆ¶å™¨æ¨¡å¼ã€æœ€ç»ˆä¸€è‡´æ€§ç­‰è®¾è®¡ç†å¿µï¼Œæ˜¯åˆ†å¸ƒå¼ç³»ç»Ÿè®¾è®¡çš„æ•™ç§‘ä¹¦çº§èŒƒä¾‹
- **ç”Ÿæ€æ æ†**ï¼šæŒæ¡ K8s å³æ‰“å¼€äº† Service Meshï¼ˆIstioï¼‰ã€Serverlessï¼ˆKnativeï¼‰ã€GitOpsï¼ˆArgoCDï¼‰ç­‰æ•´ä¸ªäº‘åŸç”Ÿç”Ÿæ€çš„å¤§é—¨

### ä¸ºä»€ä¹ˆæ˜¯ 1.32 ç‰ˆæœ¬

Kubernetes 1.32 "Penelope" äº 2024 å¹´ 12 æœˆå‘å¸ƒï¼Œæ˜¯ä¸€ä¸ªé‡è¦çš„é‡Œç¨‹ç¢‘ç‰ˆæœ¬ï¼š
- **Sidecar Containers æ­£å¼ GA**ï¿½ï¿½ï¿½åŸç”Ÿæ”¯æŒ Sidecar ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼Œä¸å†ä¾èµ–ç¤¾åŒº Workaround
- **åŠ¨æ€èµ„æºåˆ†é…ï¼ˆDRAï¼‰æŒç»­æ¼”è¿›**ï¼šä¸º GPU/FPGA ç­‰å¼‚æ„èµ„æºç®¡ç†å¥ å®šåŸºç¡€
- **å¤šé¡¹ç¨³å®šæ€§å¢å¼º**ï¼šå¤§é‡ Beta ç‰¹æ€§æ™‹å‡ GAï¼Œæ ‡å¿—ç€å¹³å°æˆç†Ÿåº¦è¿›ä¸€æ­¥æå‡

### é˜…è¯»æŒ‡å—

| è¯»è€…ç±»å‹ | æ¨èç« èŠ‚ | é¢„æœŸæ”¶è· |
|---------|---------|---------|
| K8s åˆå­¦è€… | ç¬¬ä¸€ç«  â†’ ç¬¬äºŒç« ï¼ˆ2.1-2.2ï¼‰â†’ ç¬¬å…­ç«  | å»ºç«‹å…¨å±€è®¤çŸ¥ï¼ŒæŒæ¡æ ¸å¿ƒæ¦‚å¿µä¸æ’éšœèƒ½åŠ› |
| ä¸­çº§å¼€å‘è€… | ç¬¬äºŒç«  â†’ ç¬¬ä¸‰ç«  â†’ ç¬¬å››ç«  | ç†è§£å®ç°åŸç†ï¼Œå…·å¤‡ Operator å¼€å‘èƒ½åŠ› |
| é«˜çº§æ¶æ„å¸ˆ | ç¬¬å››ç«  â†’ ç¬¬äº”ç«  â†’ ç¬¬å…­ç«  | æŒæ¡è®¾è®¡å“²å­¦ï¼Œå…·å¤‡å¤§è§„æ¨¡é›†ç¾¤æ²»ç†èƒ½åŠ› |
| é¢è¯•å¤‡æˆ˜ | ç¬¬ä¸ƒç« ï¼ˆé…åˆå¯¹åº”ç« èŠ‚æ·±å…¥ï¼‰ | ç³»ç»ŸåŒ–é¢è¯•å‡†å¤‡ |

---

## ç¬¬ä¸€ç« ï¼šåŸºç¡€ç†è®ºä¸æ¶æ„æ¼”è¿›

### 1.1 æŠ€æœ¯è¯ç”ŸèƒŒæ™¯ä¸æ ¸å¿ƒé—®é¢˜

#### ä»ç‰©ç†æœºåˆ°å®¹å™¨çš„æ¼”è¿›ä¹‹è·¯

```
ç‰©ç†æœºæ—¶ä»£        è™šæ‹Ÿæœºæ—¶ä»£          å®¹å™¨æ—¶ä»£            äº‘åŸç”Ÿæ—¶ä»£
(~2005)          (2005~2013)        (2013~2017)        (2017~è‡³ä»Š)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ App A/B/Câ”‚     â”‚ VM1â”‚VM2â”‚VM3â”‚    â”‚ å®¹å™¨1â”‚å®¹å™¨2â”‚å®¹å™¨3â”‚  â”‚ K8s ç¼–æ’  â”‚
â”‚ å…±äº«OS   â”‚     â”‚ å„è‡ªOS  â”‚       â”‚ å…±äº«OSå†…æ ¸â”‚       â”‚ å£°æ˜å¼ç®¡ç†â”‚
â”‚ èµ„æºäº‰æŠ¢ â”‚     â”‚ èµ„æºéš”ç¦» â”‚       â”‚ è½»é‡éš”ç¦»  â”‚       â”‚ è‡ªåŠ¨åŒ–è¿ç»´â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
é—®é¢˜ï¼šèµ„æºæµªè´¹    é—®é¢˜ï¼šå¯åŠ¨æ…¢/é‡     é—®é¢˜ï¼šè§„æ¨¡åŒ–ç®¡ç†éš¾   è§£å†³ï¼šå…¨è‡ªåŠ¨ç¼–æ’
```

ğŸ¯ æ ¸å¿ƒæ¼”è¿›é€»è¾‘ï¼šæ¯ä¸€ä»£æŠ€æœ¯éƒ½åœ¨è§£å†³ä¸Šä¸€ä»£çš„æ ¸å¿ƒç—›ç‚¹â€”â€”èµ„æºåˆ©ç”¨ç‡ â†’ éš”ç¦»æ€§ â†’ è½»é‡åŒ– â†’ è§„æ¨¡åŒ–ç®¡ç†ã€‚

#### Google Borg/Omega çš„é—äº§

Kubernetes å¹¶éå‡­ç©ºè¯ç”Ÿï¼Œå®ƒç›´æ¥ç»§æ‰¿äº† Google å†…éƒ¨ä¸¤ä»£é›†ç¾¤ç®¡ç†ç³»ç»Ÿçš„ç»éªŒï¼š

| ç³»ç»Ÿ | æ—¶é—´ | æ ¸å¿ƒè´¡çŒ® | K8s ä¸­çš„ä½“ç° |
|------|------|---------|-------------|
| Borg | 2003~ | å¤§è§„æ¨¡é›†ç¾¤ç®¡ç†ã€å£°æ˜å¼ä»»åŠ¡æè¿° | Pod æ¦‚å¿µã€Label/Selector æœºåˆ¶ |
| Omega | 2013~ | å…±äº«çŠ¶æ€è°ƒåº¦ã€ä¹è§‚å¹¶å‘æ§åˆ¶ | åŸºäº etcd çš„å…±äº«çŠ¶æ€ã€ResourceVersion ä¹è§‚é” |
| Kubernetes | 2014~ | å¼€æºã€å¯æ‰©å±•ã€å£°æ˜å¼ API | CRD/Operator æ‰©å±•ä½“ç³» |

> ğŸ“„ å‚è€ƒè®ºæ–‡ï¼š*"Large-scale cluster management at Google with Borg"*ï¼ˆEuroSys 2015ï¼‰ï¼›*"Borg, Omega, and Kubernetes"*ï¼ˆACM Queue 2016ï¼‰

#### Kubernetes è¦è§£å†³çš„ä¸‰å¤§æ ¸å¿ƒé—®é¢˜

1. **å®¹å™¨ç¼–æ’**ï¼šæˆç™¾ä¸Šåƒä¸ªå®¹å™¨å¦‚ä½•è‡ªåŠ¨éƒ¨ç½²ã€æ›´æ–°ã€å›æ»šï¼Ÿ
2. **èµ„æºè°ƒåº¦**ï¼šå¦‚ä½•å°†å®¹å™¨é«˜æ•ˆåœ°åˆ†é…åˆ°é›†ç¾¤èŠ‚ç‚¹ä¸Šï¼Œæœ€å¤§åŒ–èµ„æºåˆ©ç”¨ç‡ï¼Ÿ
3. **æœåŠ¡æ²»ç†**ï¼šå®¹å™¨é—´å¦‚ä½•å‘ç°å½¼æ­¤ã€è´Ÿè½½å‡è¡¡ã€æ•…éšœè‡ªæ„ˆï¼Ÿ

ğŸ’¡ ç”¨ä¸€å¥è¯ç†è§£ Kubernetesï¼š**å®ƒæ˜¯æ•°æ®ä¸­å¿ƒçš„"åˆ†å¸ƒå¼æ“ä½œç³»ç»Ÿ"ï¼Œå°†ä¸€ç»„æœºå™¨æŠ½è±¡ä¸ºä¸€ä¸ªç»Ÿä¸€çš„è®¡ç®—èµ„æºæ± ï¼Œç”¨æˆ·åªéœ€å£°æ˜"æˆ‘è¦ä»€ä¹ˆ"ï¼ŒK8s è´Ÿè´£"æ€ä¹ˆåš"ã€‚**

### 1.2 æ¶æ„æ¼”è¿›å†ç¨‹

#### ç¬¬ä¸€é˜¶æ®µï¼šå¥ åŸºæœŸï¼ˆv1.0 ~ v1.5ï¼Œ2015-2016ï¼‰

- v1.0ï¼ˆ2015.07ï¼‰ï¼šé¦–ä¸ªæ­£å¼ç‰ˆæœ¬ï¼Œç¡®ç«‹ Pod/Service/ReplicationController æ ¸å¿ƒæ¨¡å‹
- v1.1ï¼šå¼•å…¥ HPAï¼ˆHorizontal Pod Autoscalerï¼‰ã€Job
- v1.2ï¼šå¼•å…¥ Deploymentï¼ˆæ›¿ä»£ ReplicationControllerï¼‰ã€ConfigMap
- v1.3ï¼šå¼•å…¥ PetSetï¼ˆåæ›´åä¸º StatefulSetï¼‰ã€Init Containers
- v1.4ï¼šå¼•å…¥ ScheduledJobï¼ˆåæ›´åä¸º CronJobï¼‰
- v1.5ï¼šå¼•å…¥ StatefulSetï¼ˆBetaï¼‰ã€RBACï¼ˆAlphaï¼‰ã€PodDisruptionBudget

ğŸ¯ è¿™ä¸€é˜¶æ®µçš„æ ¸å¿ƒç›®æ ‡ï¼š**å»ºç«‹åŸºç¡€ç¼–æ’èƒ½åŠ›ï¼ŒéªŒè¯å£°æ˜å¼ API æ¨¡å‹çš„å¯è¡Œæ€§ã€‚**

#### ç¬¬äºŒé˜¶æ®µï¼šæˆç†ŸæœŸï¼ˆv1.6 ~ v1.12ï¼Œ2017-2018ï¼‰

- v1.6ï¼šetcd v3 æˆä¸ºé»˜è®¤å­˜å‚¨åç«¯ï¼ˆæ€§èƒ½å¤§å¹…æå‡ï¼‰ã€RBAC è¿›å…¥ Beta
- v1.7ï¼šCRDï¼ˆCustomResourceDefinitionï¼‰å–ä»£ ThirdPartyResourceï¼Œå¼€å¯æ‰©å±•æ€§æ–°çºªå…ƒ
- v1.8ï¼šRBAC GAã€CronJob è¿›å…¥ Beta
- v1.9ï¼šWorkloads APIï¼ˆDeployment/DaemonSet/ReplicaSet/StatefulSetï¼‰GA
- v1.10ï¼šCSIï¼ˆContainer Storage Interfaceï¼‰Alphaï¼Œå­˜å‚¨æ’ä»¶åŒ–
- v1.11ï¼šCoreDNS æˆä¸ºé»˜è®¤ DNSã€IPVS kube-proxy GA
- v1.12ï¼šRuntimeClass å¼•å…¥ã€Kubelet TLS Bootstrap GA

ğŸ¯ è¿™ä¸€é˜¶æ®µçš„æ ¸å¿ƒç›®æ ‡ï¼š**æ’ä»¶åŒ–æ¶æ„æˆå‹ï¼ˆCRI/CNI/CSIï¼‰ï¼ŒRBAC å®‰å…¨ä½“ç³»å®Œå–„ï¼Œæ ¸å¿ƒ Workload API ç¨³å®šã€‚**

#### ç¬¬ä¸‰é˜¶æ®µï¼šä¼ä¸šçº§ï¼ˆv1.13 ~ v1.20ï¼Œ2018-2020ï¼‰

- v1.13ï¼škubeadm GAï¼ˆç”Ÿäº§çº§é›†ç¾¤éƒ¨ç½²å·¥å…·ï¼‰
- v1.14ï¼šWindows èŠ‚ç‚¹æ”¯æŒ GAã€kubectl æ’ä»¶æœºåˆ¶
- v1.16ï¼šCRD GAã€Admission Webhook GAï¼ˆæ‰©å±•æ€§é‡Œç¨‹ç¢‘ï¼‰
- v1.18ï¼šTopology Manager GAã€kubectl debugï¼ˆAlphaï¼‰
- v1.19ï¼šIngress API GAã€EndpointSlice GA
- v1.20ï¼šdockershim åºŸå¼ƒå…¬å‘Šï¼ˆæ¨åŠ¨ containerd/CRI-O è¿ç§»ï¼‰

ğŸ¯ è¿™ä¸€é˜¶æ®µçš„æ ¸å¿ƒç›®æ ‡ï¼š**CRD/Webhook æ‰©å±•ä½“ç³»æˆç†Ÿï¼Œä¸º Operator ç”Ÿæ€çˆ†å‘å¥ å®šåŸºç¡€ã€‚**

#### ç¬¬å››é˜¶æ®µï¼šäº‘åŸç”Ÿæ·±æ°´åŒºï¼ˆv1.21 ~ v1.28ï¼Œ2021-2023ï¼‰

- v1.21ï¼šPodSecurityPolicy åºŸå¼ƒï¼Œå¼•å…¥ PodSecurity Admission
- v1.22ï¼šç§»é™¤å¤§é‡è¿‡æœŸ Beta APIï¼ˆé‡å¤§ Breaking Changeï¼‰
- v1.24ï¼šæ­£å¼ç§»é™¤ dockershimã€Gatekeeper æˆç†Ÿ
- v1.25ï¼šPod Security Admission GAã€Ephemeral Containers GA
- v1.26ï¼šJob å¯å˜è°ƒåº¦æŒ‡ä»¤ã€CEL for Admission
- v1.27ï¼šIn-Place Pod Resizeï¼ˆAlphaï¼‰ã€kubectl events æ”¹è¿›
- v1.28ï¼šSidecar Containersï¼ˆAlphaï¼‰ã€Native Sidecar æ”¯æŒ

ğŸ¯ è¿™ä¸€é˜¶æ®µçš„æ ¸å¿ƒç›®æ ‡ï¼š**å®‰å…¨æ¨¡å‹é‡æ„ï¼ˆPSA æ›¿ä»£ PSPï¼‰ï¼Œç§»é™¤å†å²åŒ…è¢±ï¼Œå¼•å…¥ Sidecar åŸç”Ÿæ”¯æŒã€‚**

#### ç¬¬äº”é˜¶æ®µï¼šç²¾ç»†åŒ–æ²»ç†ï¼ˆv1.29 ~ v1.32ï¼Œ2023-2024ï¼‰

- v1.29ï¼šKMS v2 GAã€nftables kube-proxyï¼ˆAlphaï¼‰
- v1.30ï¼šç»“æ„åŒ–æˆæƒé…ç½®ã€Pod Scheduling Readiness GA
- v1.31ï¼šAppArmor GAã€nftables kube-proxyï¼ˆBetaï¼‰
- v1.32 "Penelope"ï¼š
  - **Sidecar Containers GA**ï¼š`restartPolicy: Always` çš„ Init Container æ­£å¼ç¨³å®š
  - **DRAï¼ˆDynamic Resource Allocationï¼‰æŒç»­æ¼”è¿›**ï¼šç»“æ„åŒ–å‚æ•°æ¨¡å‹
  - **å¤šé¡¹ Beta â†’ GA æ™‹å‡**ï¼šæ ‡å¿—å¹³å°è¿›å…¥é«˜åº¦ç¨³å®šæœŸ

ğŸ¯ è¿™ä¸€é˜¶æ®µçš„æ ¸å¿ƒç›®æ ‡ï¼š**ç²¾ç»†åŒ–èµ„æºç®¡ç†ï¼ˆDRAï¼‰ï¼Œå®‰å…¨åŠ å›ºï¼ˆKMS v2/AppArmorï¼‰ï¼ŒSidecar åŸç”ŸåŒ–ã€‚**

### 1.3 æ ¸å¿ƒæ¦‚å¿µæœ¯è¯­è¡¨

| è‹±æ–‡æœ¯è¯­ | ä¸­æ–‡ | é€šä¿—è§£é‡Š |
|---------|------|---------|
| Pod | å®¹å™¨ç»„ | K8s æœ€å°è°ƒåº¦å•å…ƒï¼Œä¸€ä¸ªæˆ–å¤šä¸ªå…±äº«ç½‘ç»œ/å­˜å‚¨çš„å®¹å™¨ |
| Node | èŠ‚ç‚¹ | é›†ç¾¤ä¸­çš„ä¸€å°å·¥ä½œæœºå™¨ï¼ˆç‰©ç†æœºæˆ–è™šæ‹Ÿæœºï¼‰ |
| Cluster | é›†ç¾¤ | ä¸€ç»„ Node çš„é›†åˆï¼Œç”±æ§åˆ¶å¹³é¢ç»Ÿä¸€ç®¡ç† |
| Namespace | å‘½åç©ºé—´ | é›†ç¾¤å†…çš„è™šæ‹Ÿéš”ç¦»åˆ†åŒºï¼Œç”¨äºå¤šç§Ÿæˆ·èµ„æºéš”ç¦» |
| Deployment | éƒ¨ç½² | ç®¡ç†æ— çŠ¶æ€åº”ç”¨çš„æ§åˆ¶å™¨ï¼Œæ”¯æŒæ»šåŠ¨æ›´æ–°å’Œå›æ»š |
| StatefulSet | æœ‰çŠ¶æ€å‰¯æœ¬é›† | ç®¡ç†æœ‰çŠ¶æ€åº”ç”¨ï¼ˆå¦‚æ•°æ®åº“ï¼‰ï¼Œä¿è¯ Pod æœ‰åºæ€§å’ŒæŒä¹…æ ‡è¯† |
| DaemonSet | å®ˆæŠ¤è¿›ç¨‹é›† | ç¡®ä¿æ¯ä¸ªï¼ˆæˆ–æŒ‡å®šï¼‰Node ä¸Šè¿è¡Œä¸€ä¸ª Pod å‰¯æœ¬ |
| Service | æœåŠ¡ | ä¸ºä¸€ç»„ Pod æä¾›ç¨³å®šçš„ç½‘ç»œè®¿é—®å…¥å£å’Œè´Ÿè½½å‡è¡¡ |
| Ingress | å…¥å£ | HTTP/HTTPS å±‚çš„è·¯ç”±è§„åˆ™ï¼Œå°†å¤–éƒ¨æµé‡å¯¼å…¥é›†ç¾¤å†… Service |
| ConfigMap | é…ç½®æ˜ å°„ | å­˜å‚¨éæ•æ„Ÿé…ç½®æ•°æ®çš„ API å¯¹è±¡ |
| Secret | å¯†é’¥ | å­˜å‚¨æ•æ„Ÿæ•°æ®ï¼ˆå¯†ç ã€Token ç­‰ï¼‰ï¼ŒBase64 ç¼–ç å­˜å‚¨ |
| PV / PVC | æŒä¹…å· / æŒä¹…å·å£°æ˜ | PV æ˜¯å­˜å‚¨èµ„æºï¼ŒPVC æ˜¯ç”¨æˆ·å¯¹å­˜å‚¨çš„ç”³è¯· |
| CRD | è‡ªå®šä¹‰èµ„æºå®šä¹‰ | æ‰©å±• K8s API çš„æœºåˆ¶ï¼Œå…è®¸ç”¨æˆ·å®šä¹‰æ–°çš„èµ„æºç±»å‹ |
| Operator | æ“ä½œå™¨ | CRD + è‡ªå®šä¹‰ Controllerï¼Œå°†è¿ç»´çŸ¥è¯†ç¼–ç ä¸ºè‡ªåŠ¨åŒ–ç¨‹åº |
| Label / Selector | æ ‡ç­¾ / é€‰æ‹©å™¨ | é”®å€¼å¯¹æ ‡ç­¾ç³»ç»Ÿï¼Œç”¨äºèµ„æºåˆ†ç»„å’Œç­›é€‰ |
| Annotation | æ³¨è§£ | é™„åŠ åˆ°å¯¹è±¡çš„éæ ‡è¯†æ€§å…ƒæ•°æ® |
| kubelet | èŠ‚ç‚¹ä»£ç† | è¿è¡Œåœ¨æ¯ä¸ª Node ä¸Šï¼Œè´Ÿè´£ç®¡ç† Pod ç”Ÿå‘½å‘¨æœŸ |
| kube-proxy | ç½‘ç»œä»£ç† | ç»´æŠ¤èŠ‚ç‚¹ä¸Šçš„ç½‘ç»œè§„åˆ™ï¼Œå®ç° Service çš„æµé‡è½¬å‘ |
| etcd | åˆ†å¸ƒå¼é”®å€¼å­˜å‚¨ | K8s çš„"å¤§è„‘"ï¼Œå­˜å‚¨æ‰€æœ‰é›†ç¾¤çŠ¶æ€æ•°æ® |
| Controller | æ§åˆ¶å™¨ | ç›‘å¬ API å¯¹è±¡å˜åŒ–å¹¶é©±åŠ¨å®é™…çŠ¶æ€å‘æœŸæœ›çŠ¶æ€æ”¶æ•›çš„å¾ªç¯ |
| Scheduler | è°ƒåº¦å™¨ | å†³å®š Pod åº”è¯¥è¿è¡Œåœ¨å“ªä¸ª Node ä¸Š |

### 1.4 é€‚ç”¨åœºæ™¯ vs ä¸é€‚ç”¨åœºæ™¯

| åœºæ™¯ | é€‚ç”¨æ€§ | è¯´æ˜ |
|------|--------|------|
| å¾®æœåŠ¡æ¶æ„ç¼–æ’ | âœ… | K8s çš„æ ¸å¿ƒè®¾è®¡ç›®æ ‡ï¼ŒService/Ingress/DNS å¤©ç„¶æ”¯æŒ |
| CI/CD æµæ°´çº¿åŸºç¡€è®¾æ–½ | âœ… | Jenkins/Tekton/ArgoCD ç­‰å‡åŸç”Ÿè¿è¡Œäº K8s |
| å¼¹æ€§ä¼¸ç¼© Web åº”ç”¨ | âœ… | HPA/VPA/Cluster Autoscaler æä¾›å¤šå±‚å¼¹æ€§ |
| æ‰¹å¤„ç†ä¸å¤§æ•°æ®ä»»åŠ¡ | âœ… | Job/CronJob + Spark on K8s/Flink on K8s |
| æ··åˆäº‘/å¤šäº‘ç»Ÿä¸€ç®¡ç† | âœ… | æŠ½è±¡å±‚å±è”½åº•å±‚å·®å¼‚ï¼ŒKubeFed/Karmada æ”¯æŒå¤šé›†ç¾¤ |
| AI/ML è®­ç»ƒä»»åŠ¡ | âœ… | GPU è°ƒåº¦ + DRA + Kubeflow ç”Ÿæ€ |
| å•ä½“å°åº”ç”¨ï¼ˆ< 3 ä¸ªæœåŠ¡ï¼‰ | âŒ | è¿ç»´å¤æ‚åº¦è¿œè¶…æ”¶ç›Šï¼ŒDocker Compose è¶³çŸ£ |
| å¼ºå®æ—¶ç³»ç»Ÿï¼ˆé«˜é¢‘äº¤æ˜“ï¼‰ | âŒ | å®¹å™¨ç½‘ç»œå’Œè°ƒåº¦å¼•å…¥çš„å»¶è¿Ÿä¸å¯æ¥å— |
| è£¸é‡‘å±ç‰¹æ®Šå†…æ ¸ä¾èµ– | âŒ | å®¹å™¨å…±äº«å®¿ä¸»å†…æ ¸ï¼Œæ— æ³•æ»¡è¶³ç‰¹æ®Šå†…æ ¸éœ€æ±‚ |
| æå°å›¢é˜Ÿæ— è¿ç»´èƒ½åŠ› | âŒ | K8s è¿ç»´é—¨æ§›é«˜ï¼Œå»ºè®®ä½¿ç”¨æ‰˜ç®¡æœåŠ¡ï¼ˆEKS/GKE/AKSï¼‰ |

âš ï¸ å¸¸è§è¯¯åŒºï¼š**"ä¸Šäº† K8s å°±æ˜¯äº‘åŸç”Ÿ"**â€”â€”Kubernetes åªæ˜¯äº‘åŸç”Ÿçš„åŸºç¡€è®¾æ–½å±‚ï¼ŒçœŸæ­£çš„äº‘åŸç”Ÿè¿˜éœ€è¦å¾®æœåŠ¡æ‹†åˆ†ã€DevOps æ–‡åŒ–ã€å¯è§‚æµ‹æ€§ä½“ç³»ç­‰é…å¥—ã€‚

### 1.5 ä¸åŒç±»æŠ€æœ¯å¯¹æ¯”

| ç»´åº¦ | Kubernetes | Docker Swarm | Apache Mesos | HashiCorp Nomad |
|------|-----------|-------------|-------------|----------------|
| **è®¾è®¡å“²å­¦** | å£°æ˜å¼ã€å¯æ‰©å±•çš„å¹³å° | ç®€å•æ˜“ç”¨çš„ç¼–æ’å·¥å…· | ä¸¤å±‚è°ƒåº¦çš„èµ„æºç®¡ç†å™¨ | ç®€æ´çµæ´»çš„å·¥ä½œè´Ÿè½½ç¼–æ’ |
| **æ¶æ„å¤æ‚åº¦** | é«˜ï¼ˆç»„ä»¶å¤šã€æ¦‚å¿µå¤šï¼‰ | ä½ï¼ˆå†…ç½®äº Dockerï¼‰ | é«˜ï¼ˆMesos + Marathon/Auroraï¼‰ | ä¸­ï¼ˆå•äºŒè¿›åˆ¶ã€æ¶æ„ç®€æ´ï¼‰ |
| **è°ƒåº¦èƒ½åŠ›** | å¼ºï¼ˆæ’ä»¶åŒ–è°ƒåº¦æ¡†æ¶ï¼‰ | åŸºç¡€ï¼ˆå†…ç½®ç­–ç•¥æœ‰é™ï¼‰ | å¼ºï¼ˆä¸¤å±‚è°ƒåº¦ã€å¤§è§„æ¨¡éªŒè¯ï¼‰ | ä¸­ï¼ˆæ”¯æŒå¤šç§é©±åŠ¨ï¼‰ |
| **æ‰©å±•æ€§** | æå¼ºï¼ˆCRD/Operator/Webhookï¼‰ | å¼±ï¼ˆæ‰©å±•æœºåˆ¶æœ‰é™ï¼‰ | ä¸­ï¼ˆFramework æœºåˆ¶ï¼‰ | ä¸­ï¼ˆTask Driver æ’ä»¶ï¼‰ |
| **ç”Ÿæ€ä¸°å¯Œåº¦** | æä¸°å¯Œï¼ˆCNCF ç”Ÿæ€ï¼‰ | è¾ƒå°‘ï¼ˆç¤¾åŒºèç¼©ï¼‰ | ä¸­ç­‰ï¼ˆå¤§æ•°æ®ç”Ÿæ€ï¼‰ | ä¸­ç­‰ï¼ˆHashiCorp ç”Ÿæ€ï¼‰ |
| **ç¤¾åŒºæ´»è·ƒåº¦** | æé«˜ï¼ˆæœ€å¤§å¼€æºé¡¹ç›®ä¹‹ä¸€ï¼‰ | ä½ï¼ˆå·²åŸºæœ¬åœæ­¢å‘å±•ï¼‰ | ä½ï¼ˆApache å½’æ¡£ï¼‰ | ä¸­ï¼ˆHashiCorp ç»´æŠ¤ï¼‰ |
| **å­¦ä¹ æ›²çº¿** | é™¡å³­ | å¹³ç¼“ | é™¡å³­ | ä¸­ç­‰ |
| **ç”Ÿäº§é‡‡ç”¨ç‡** | æé«˜ï¼ˆ>84% ç»„ç»‡ï¼‰ | ä½ | ä½ï¼ˆé€æ­¥é€€å‡ºï¼‰ | ä¸­ï¼ˆç‰¹å®šåœºæ™¯ï¼‰ |
| **å¤šå·¥ä½œè´Ÿè½½** | å®¹å™¨ä¸ºä¸» | ä»…å®¹å™¨ | å®¹å™¨+å¤§æ•°æ®+è‡ªå®šä¹‰ | å®¹å™¨+VM+äºŒè¿›åˆ¶+Java |
| **é€‚åˆè§„æ¨¡** | ä¸­å¤§è§„æ¨¡ | å°è§„æ¨¡ | è¶…å¤§è§„æ¨¡ | ä¸­å°è§„æ¨¡ |

ğŸ’¡ é€‰å‹å»ºè®®ï¼š
- **ç»å¤§å¤šæ•°åœºæ™¯é€‰ Kubernetes**ï¼šç”Ÿæ€æœ€å®Œå–„ï¼Œäººæ‰æœ€å¤šï¼Œé•¿æœŸæŠ•èµ„æœ€å®‰å…¨
- **æç®€åœºæ™¯é€‰ Nomad**ï¼šå¦‚æœå›¢é˜Ÿå°ã€ä¸éœ€è¦ K8s çš„å¤æ‚æ€§ï¼ŒNomad æ˜¯è½»é‡æ›¿ä»£
- **Docker Swarm / Mesos**ï¼šä¸å»ºè®®æ–°é¡¹ç›®é‡‡ç”¨ï¼Œç¤¾åŒºå·²åŸºæœ¬åœæ»

---

## ç¬¬äºŒç« ï¼šå®ç°åŸç†è§£æ

### 2.1 æ ¸å¿ƒç»„ä»¶æ¶æ„å›¾

```mermaid
graph TB
    subgraph ControlPlane["æ§åˆ¶å¹³é¢ (Control Plane)"]
        API["kube-apiserver<br/>API ç½‘å…³ & è®¤è¯æˆæƒ"]
        ETCD["etcd é›†ç¾¤<br/>åˆ†å¸ƒå¼é”®å€¼å­˜å‚¨"]
        SCHED["kube-scheduler<br/>Pod è°ƒåº¦å†³ç­–"]
        CM["kube-controller-manager<br/>å†…ç½®æ§åˆ¶å™¨é›†åˆ"]
        CCM["cloud-controller-manager<br/>äº‘å‚å•†é€‚é…å±‚"]
    end

    subgraph WorkerNode1["å·¥ä½œèŠ‚ç‚¹ (Node)"]
        KUBELET1["kubelet<br/>Pod ç”Ÿå‘½å‘¨æœŸç®¡ç†"]
        PROXY1["kube-proxy<br/>Service ç½‘ç»œè§„åˆ™"]
        CRI1["Container Runtime<br/>(containerd / CRI-O)"]
        POD1["Pod A"]
        POD2["Pod B"]
    end

    subgraph Addons["é™„åŠ ç»„ä»¶"]
        DNS["CoreDNS<br/>é›†ç¾¤ DNS æœåŠ¡"]
        METRICS["Metrics Server<br/>èµ„æºæŒ‡æ ‡é‡‡é›†"]
        INGRESS["Ingress Controller<br/>HTTP è·¯ç”±"]
    end

    USER["kubectl / API å®¢æˆ·ç«¯"] -->|"REST/gRPC"| API
    API -->|"è¯»å†™çŠ¶æ€"| ETCD
    API -->|"Watch äº‹ä»¶"| SCHED
    API -->|"Watch äº‹ä»¶"| CM
    API -->|"Watch äº‹ä»¶"| CCM
    SCHED -->|"ç»‘å®š Podâ†’Node"| API
    CM -->|"æ›´æ–°èµ„æºçŠ¶æ€"| API
    KUBELET1 -->|"ä¸ŠæŠ¥çŠ¶æ€/Watch Pod"| API
    KUBELET1 -->|"CRI gRPC"| CRI1
    CRI1 --> POD1
    CRI1 --> POD2
    PROXY1 -->|"Watch Service/Endpoint"| API
    DNS -->|"Watch Service"| API
    METRICS -->|"é‡‡é›† kubelet /metrics"| KUBELET1
```

ğŸ¯ æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼š**æ‰€æœ‰ç»„ä»¶é€šè¿‡ kube-apiserver é€šä¿¡ï¼Œapiserver æ˜¯å”¯ä¸€ç›´æ¥è¯»å†™ etcd çš„ç»„ä»¶ã€‚** è¿™ç§"æ˜Ÿå‹æ‹“æ‰‘"è®¾è®¡ç®€åŒ–äº†å®‰å…¨æ¨¡å‹ï¼ˆåªéœ€ä¿æŠ¤ apiserverï¼‰ï¼Œä¹Ÿä½¿å¾—å„ç»„ä»¶å¯ä»¥ç‹¬ç«‹æ‰©å±•å’Œæ›¿æ¢ã€‚

#### å„ç»„ä»¶èŒè´£è¯¦è§£

| ç»„ä»¶ | èŒè´£ | æ˜¯å¦æœ‰çŠ¶æ€ | å¯æ°´å¹³æ‰©å±• |
|------|------|-----------|-----------|
| kube-apiserver | REST API ç½‘å…³ã€è®¤è¯æˆæƒã€å‡†å…¥æ§åˆ¶ã€etcd ä»£ç† | æ— çŠ¶æ€ | âœ… å¤šå®ä¾‹ + LB |
| etcd | å­˜å‚¨æ‰€æœ‰é›†ç¾¤çŠ¶æ€ï¼ˆå”¯ä¸€æŒä¹…åŒ–ç»„ä»¶ï¼‰ | æœ‰çŠ¶æ€ | âœ… 3/5/7 èŠ‚ç‚¹é›†ç¾¤ |
| kube-scheduler | ç›‘å¬æœªè°ƒåº¦ Podï¼Œæ‰§è¡Œè°ƒåº¦å†³ç­– | æ— çŠ¶æ€ï¼ˆLeader Electionï¼‰ | âœ… å¤šå®ä¾‹ä¸»å¤‡ |
| kube-controller-manager | è¿è¡Œå†…ç½®æ§åˆ¶å™¨ï¼ˆDeployment/ReplicaSet/Node ç­‰ï¼‰ | æ— çŠ¶æ€ï¼ˆLeader Electionï¼‰ | âœ… å¤šå®ä¾‹ä¸»å¤‡ |
| cloud-controller-manager | å¯¹æ¥äº‘å‚å•† APIï¼ˆLB/Node/Routeï¼‰ | æ— çŠ¶æ€ï¼ˆLeader Electionï¼‰ | âœ… å¤šå®ä¾‹ä¸»å¤‡ |
| kubelet | ç®¡ç†æœ¬èŠ‚ç‚¹ Pod ç”Ÿå‘½å‘¨æœŸã€ä¸ŠæŠ¥èŠ‚ç‚¹çŠ¶æ€ | æ— çŠ¶æ€ | âŒ æ¯èŠ‚ç‚¹ä¸€ä¸ª |
| kube-proxy | ç»´æŠ¤ iptables/IPVS è§„åˆ™å®ç° Service è½¬å‘ | æ— çŠ¶æ€ | âŒ æ¯èŠ‚ç‚¹ä¸€ä¸ª |

### 2.2 æ ¸å¿ƒå·¥ä½œæµç¨‹

#### æµç¨‹ä¸€ï¼šPod åˆ›å»ºå…¨æµç¨‹

```mermaid
sequenceDiagram
    participant User as kubectl
    participant API as kube-apiserver
    participant ETCD as etcd
    participant Sched as kube-scheduler
    participant KL as kubelet
    participant CRI as containerd

    User->>API: 1. POST /api/v1/namespaces/default/pods (åˆ›å»º Pod)
    API->>API: 2. è®¤è¯(AuthN) â†’ æˆæƒ(AuthZ) â†’ å‡†å…¥æ§åˆ¶(Admission)
    API->>ETCD: 3. æŒä¹…åŒ– Pod å¯¹è±¡ (status.phase=Pending, nodeName="")
    ETCD-->>API: 4. ç¡®è®¤å†™å…¥
    API-->>User: 5. è¿”å› 201 Created

    Note over Sched: Watch åˆ°æ–°çš„æœªè°ƒåº¦ Pod
    Sched->>Sched: 6. é¢„é€‰(Filtering): è¿‡æ»¤ä¸æ»¡è¶³æ¡ä»¶çš„ Node
    Sched->>Sched: 7. ä¼˜é€‰(Scoring): å¯¹å€™é€‰ Node æ‰“åˆ†æ’åº
    Sched->>API: 8. POST /bindding: ç»‘å®š Pod â†’ é€‰ä¸­çš„ Node
    API->>ETCD: 9. æ›´æ–° Pod.spec.nodeName

    Note over KL: Watch åˆ°åˆ†é…ç»™æœ¬èŠ‚ç‚¹çš„ Pod
    KL->>KL: 10. å‡†å…¥æ£€æŸ¥(èµ„æºæ˜¯å¦å……è¶³)
    KL->>CRI: 11. CRI.RunPodSandbox() åˆ›å»º Pod æ²™ç®±(pause å®¹å™¨)
    CRI-->>KL: 12. æ²™ç®±å°±ç»ª
    KL->>CRI: 13. CRI.CreateContainer() + StartContainer()
    CRI-->>KL: 14. å®¹å™¨å¯åŠ¨æˆåŠŸ
    KL->>API: 15. æ›´æ–° Pod status (phase=Running, conditions, containerStatuses)
```

âš ï¸ å¼‚å¸¸æµç¨‹å¤„ç†ï¼š

| å¼‚å¸¸åœºæ™¯ | è§¦å‘é˜¶æ®µ | è¡¨ç° | å¤„ç†æœºåˆ¶ |
|---------|---------|------|---------|
| å‡†å…¥æ§åˆ¶æ‹’ç» | æ­¥éª¤ 2 | API è¿”å› 403 | Webhook è¿”å›æ‹’ç»åŸå› ï¼Œç”¨æˆ·ä¿®æ­£åé‡è¯• |
| è°ƒåº¦å¤±è´¥ï¼ˆæ— åˆé€‚èŠ‚ç‚¹ï¼‰ | æ­¥éª¤ 6-7 | Pod æŒç»­ Pending | Scheduler å‘¨æœŸæ€§é‡è¯•ï¼›è§¦å‘ Cluster Autoscaler æ‰©å®¹ |
| é•œåƒæ‹‰å–å¤±è´¥ | æ­¥éª¤ 13 | ImagePullBackOff | kubelet æŒ‡æ•°é€€é¿é‡è¯•ï¼ˆ10sâ†’20sâ†’40s...â†’5minï¼‰ |
| OOMKilled | è¿è¡Œæ—¶ | CrashLoopBackOff | kubelet æŒ‰ restartPolicy é‡å¯ï¼ŒæŒ‡æ•°é€€é¿ |
| èŠ‚ç‚¹æ•…éšœ | è¿è¡Œæ—¶ | Node NotReady | node-controller ç­‰å¾… grace period åé©±é€ Pod |

#### æµç¨‹äºŒï¼šService è¯·æ±‚è·¯ç”±æµç¨‹

```mermaid
sequenceDiagram
    participant Client as å®¢æˆ·ç«¯ Pod
    participant DNS as CoreDNS
    participant Proxy as kube-proxy (iptables/IPVS)
    participant Pod1 as åç«¯ Pod 1
    participant Pod2 as åç«¯ Pod 2

    Client->>DNS: 1. è§£æ my-svc.default.svc.cluster.local
    DNS-->>Client: 2. è¿”å› ClusterIP (å¦‚ 10.96.0.100)
    Client->>Proxy: 3. å‘é€è¯·æ±‚åˆ° ClusterIP:Port

    alt iptables æ¨¡å¼
        Proxy->>Proxy: 4a. DNAT è§„åˆ™éšæœºé€‰æ‹©åç«¯ Pod IP
        Proxy->>Pod1: 5a. è½¬å‘åˆ° Pod1 IP:TargetPort
    else IPVS æ¨¡å¼
        Proxy->>Proxy: 4b. IPVS è™šæ‹ŸæœåŠ¡å™¨æŒ‰ç®—æ³•(rr/lc/sh)é€‰æ‹©åç«¯
        Proxy->>Pod2: 5b. è½¬å‘åˆ° Pod2 IP:TargetPort
    end

    Pod1-->>Client: 6. å“åº”ï¼ˆç›´æ¥è¿”å›ï¼Œä¸ç»è¿‡ Proxyï¼‰
```

ğŸ’¡ iptables vs IPVS æ¨¡å¼å¯¹æ¯”ï¼š

| ç»´åº¦ | iptables æ¨¡å¼ | IPVS æ¨¡å¼ |
|------|-------------|----------|
| å®ç°æ–¹å¼ | iptables è§„åˆ™é“¾ | Linux IPVS å†…æ ¸æ¨¡å— |
| æ—¶é—´å¤æ‚åº¦ | O(n)ï¼Œè§„åˆ™çº¿æ€§åŒ¹é… | O(1)ï¼Œå“ˆå¸Œè¡¨æŸ¥æ‰¾ |
| é€‚ç”¨è§„æ¨¡ | < 1000 Service | > 1000 Service |
| è´Ÿè½½å‡è¡¡ç®—æ³• | éšæœºï¼ˆiptables probabilityï¼‰ | rr/lc/dh/sh/sed/nq å¤šç§ç®—æ³• |
| è¿æ¥è¿½è¸ª | conntrack | conntrack |
| æ¨èåœºæ™¯ | å°è§„æ¨¡é›†ç¾¤ | ä¸­å¤§è§„æ¨¡é›†ç¾¤ |

#### æµç¨‹ä¸‰ï¼šDeployment æ»šåŠ¨æ›´æ–°æµç¨‹

```mermaid
sequenceDiagram
    participant User as kubectl
    participant API as kube-apiserver
    participant DC as Deployment Controller
    participant RSC as ReplicaSet Controller
    participant KL as kubelet

    User->>API: 1. kubectl set image deployment/app nginx=nginx:1.25
    API->>API: 2. æ›´æ–° Deployment.spec.template

    Note over DC: Watch åˆ° Deployment å˜æ›´
    DC->>API: 3. åˆ›å»ºæ–° ReplicaSet (RS-v2, replicas=1)
    DC->>API: 4. ç¼©å®¹æ—§ ReplicaSet (RS-v1, replicas=N-1)

    Note over RSC: Watch åˆ° RS-v2 å˜æ›´
    RSC->>API: 5. åˆ›å»ºæ–° Pod (v2-pod-1)

    Note over KL: å¯åŠ¨æ–° Pod
    KL->>API: 6. æ–° Pod Ready

    Note over DC: æ£€æŸ¥ maxSurge/maxUnavailable ç­–ç•¥
    DC->>API: 7. ç»§ç»­æ‰©å®¹ RS-v2, ç¼©å®¹ RS-v1

    Note over DC: å¾ªç¯ç›´åˆ° RS-v2 è¾¾åˆ°ç›®æ ‡å‰¯æœ¬æ•°
    DC->>API: 8. RS-v1 replicas=0, RS-v2 replicas=N
    DC->>API: 9. æ›´æ–° Deployment status (å®Œæˆæ»šåŠ¨æ›´æ–°)
```

âš ï¸ æ»šåŠ¨æ›´æ–°å…³é”®å‚æ•°ï¼š

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 10
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 25%        # æœ€å¤šå…è®¸è¶…å‡ºæœŸæœ›å‰¯æœ¬æ•°çš„æ¯”ä¾‹ï¼ˆå‘ä¸Šå–æ•´=3ï¼‰
      maxUnavailable: 25%  # æœ€å¤šå…è®¸ä¸å¯ç”¨çš„å‰¯æœ¬æ•°æ¯”ä¾‹ï¼ˆå‘ä¸‹å–æ•´=2ï¼‰
  revisionHistoryLimit: 10 # ä¿ç•™çš„å†å² ReplicaSet æ•°é‡ï¼ˆç”¨äºå›æ»šï¼‰
  minReadySeconds: 5       # Pod Ready åç­‰å¾…å¤šä¹…æ‰è®¤ä¸ºå¯ç”¨
  progressDeadlineSeconds: 600 # æ›´æ–°è¶…æ—¶æ—¶é—´
```

å›æ»šå‘½ä»¤ï¼š
```bash
# æŸ¥çœ‹æ›´æ–°å†å²
kubectl rollout history deployment/nginx-deployment

# å›æ»šåˆ°ä¸Šä¸€ç‰ˆæœ¬
kubectl rollout undo deployment/nginx-deployment

# å›æ»šåˆ°æŒ‡å®šç‰ˆæœ¬
kubectl rollout undo deployment/nginx-deployment --to-revision=2
```

#### æµç¨‹å››ï¼šHPA è‡ªåŠ¨æ‰©ç¼©å®¹æµç¨‹

```mermaid
graph LR
    A["Metrics Server<br/>é‡‡é›† Pod CPU/Memory"] -->|"metrics.k8s.io API"| B["HPA Controller<br/>(æ¯15sæ£€æŸ¥ä¸€æ¬¡)"]
    C["Prometheus Adapter<br/>è‡ªå®šä¹‰æŒ‡æ ‡"] -->|"custom.metrics.k8s.io"| B
    B -->|"è®¡ç®—æœŸæœ›å‰¯æœ¬æ•°"| D{"æœŸæœ›å‰¯æœ¬æ•° â‰  å½“å‰å‰¯æœ¬æ•°?"}
    D -->|"æ˜¯"| E["è°ƒç”¨ Scale API<br/>æ›´æ–° Deployment replicas"]
    D -->|"å¦"| F["æ— æ“ä½œ"]
    E --> G["Deployment Controller<br/>åˆ›å»º/åˆ é™¤ Pod"]
```

HPA æ ¸å¿ƒç®—æ³•ï¼š

```
æœŸæœ›å‰¯æœ¬æ•° = ceil(å½“å‰å‰¯æœ¬æ•° Ã— (å½“å‰æŒ‡æ ‡å€¼ / ç›®æ ‡æŒ‡æ ‡å€¼))
```

ç¤ºä¾‹é…ç½®ï¼š
```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx-deployment
  minReplicas: 2
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70  # CPU ä½¿ç”¨ç‡è¶…è¿‡ 70% è§¦å‘æ‰©å®¹
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60   # æ‰©å®¹å†·å´æœŸ
      policies:
      - type: Percent
        value: 100    # æ¯æ¬¡æœ€å¤šæ‰©å®¹ 100%
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300  # ç¼©å®¹å†·å´æœŸï¼ˆæ›´ä¿å®ˆï¼‰
      policies:
      - type: Percent
        value: 10     # æ¯æ¬¡æœ€å¤šç¼©å®¹ 10%
        periodSeconds: 60
```

âš ï¸ HPA æ˜“é”™ç‚¹ï¼š
- Pod å¿…é¡»è®¾ç½® `resources.requests`ï¼Œå¦åˆ™ HPA æ— æ³•è®¡ç®—åˆ©ç”¨ç‡
- `stabilizationWindowSeconds` ç¼©å®¹å»ºè®®è®¾ç½® 300s+ï¼Œé¿å…æµé‡æ³¢åŠ¨å¯¼è‡´é¢‘ç¹ç¼©å®¹

### 2.3 å…³é”®ç®—æ³•ä¸åè®®è¯¦è§£

#### etcd çš„ Raft ä¸€è‡´æ€§åè®®

etcd æ˜¯ Kubernetes çš„"å¤§è„‘"ï¼Œä½¿ç”¨ Raft åè®®ä¿è¯åˆ†å¸ƒå¼ä¸€è‡´æ€§ã€‚

```mermaid
stateDiagram-v2
    [*] --> Follower: èŠ‚ç‚¹å¯åŠ¨
    Follower --> Candidate: é€‰ä¸¾è¶…æ—¶(150~300mséšæœº)
    Candidate --> Leader: è·å¾—å¤šæ•°ç¥¨
    Candidate --> Follower: å‘ç°æ›´é«˜ Term çš„ Leader
    Candidate --> Candidate: é€‰ä¸¾è¶…æ—¶(åˆ†ç¥¨)ï¼Œé‡æ–°é€‰ä¸¾
    Leader --> Follower: å‘ç°æ›´é«˜ Term
    Leader --> Leader: æŒç»­å‘é€å¿ƒè·³(æ¯100ms)
```

ğŸ¯ Raft åœ¨ K8s ä¸­çš„ä¸‰ä¸ªå…³é”®æœºåˆ¶ï¼š

1. **Leader é€‰ä¸¾**ï¼šetcd é›†ç¾¤ä¸­åªæœ‰ä¸€ä¸ª Leader å¤„ç†å†™è¯·æ±‚ã€‚é€‰ä¸¾è¶…æ—¶éšæœºåŒ–ï¼ˆ150~300msï¼‰é¿å…æ´»é”ã€‚
2. **æ—¥å¿—å¤åˆ¶**ï¼šLeader å°†å†™æ“ä½œä½œä¸ºæ—¥å¿—æ¡ç›®å¤åˆ¶åˆ°å¤šæ•° Follower åæ‰ç¡®è®¤æäº¤ï¼ˆWrite Quorum = N/2 + 1ï¼‰ã€‚
3. **å¿«ç…§ï¼ˆSnapshotï¼‰**ï¼šå½“æ—¥å¿—è¿‡é•¿æ—¶ï¼Œetcd è‡ªåŠ¨åˆ›å»ºå¿«ç…§å‹ç¼©å†å²æ—¥å¿—ï¼Œé»˜è®¤æ¯ 10000 æ¡æ—¥å¿—è§¦å‘ä¸€æ¬¡ï¼ˆ`--snapshot-count=10000`ï¼‰ã€‚

ğŸ’¡ ä¸ºä»€ä¹ˆ etcd é›†ç¾¤æ¨èå¥‡æ•°èŠ‚ç‚¹ï¼ˆ3/5/7ï¼‰ï¼Ÿ
- 3 èŠ‚ç‚¹ï¼šå®¹å¿ 1 èŠ‚ç‚¹æ•…éšœï¼ˆQuorum=2ï¼‰
- 5 èŠ‚ç‚¹ï¼šå®¹å¿ 2 èŠ‚ç‚¹æ•…éšœï¼ˆQuorum=3ï¼‰
- 4 èŠ‚ç‚¹ vs 3 èŠ‚ç‚¹ï¼šå®¹é”™èƒ½åŠ›ç›¸åŒï¼ˆéƒ½åªå®¹å¿ 1 èŠ‚ç‚¹æ•…éšœï¼‰ï¼Œä½† 4 èŠ‚ç‚¹å¢åŠ äº†ç½‘ç»œå¼€é”€

#### kube-scheduler è°ƒåº¦ç®—æ³•

Kubernetes 1.32 ä½¿ç”¨ **Scheduling Framework**ï¼ˆè°ƒåº¦æ¡†æ¶ï¼‰ï¼Œå°†è°ƒåº¦è¿‡ç¨‹åˆ†ä¸ºå¤šä¸ªæ‰©å±•ç‚¹ï¼š

```
è°ƒåº¦ä¸€ä¸ª Pod çš„å®Œæ•´æµç¨‹ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    è°ƒåº¦å‘¨æœŸ (Scheduling Cycle)                â”‚
â”‚                                                             â”‚
â”‚  PreFilter â†’ Filter â†’ PostFilter â†’ PreScore â†’ Score â†’ Reserveâ”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç»‘å®šå‘¨æœŸ (Binding Cycle)                   â”‚
â”‚                                                             â”‚
â”‚              Permit â†’ PreBind â†’ Bind â†’ PostBind              â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

å„é˜¶æ®µè¯´æ˜ï¼š

| é˜¶æ®µ | ä½œç”¨ | å†…ç½®æ’ä»¶ç¤ºä¾‹ |
|------|------|------------|
| PreFilter | é¢„å¤„ç†ï¼Œæ£€æŸ¥ Pod æ˜¯å¦å¯è°ƒåº¦ | NodeResourcesFitï¼ˆé¢„è®¡ç®—èµ„æºéœ€æ±‚ï¼‰ |
| Filter | è¿‡æ»¤ä¸æ»¡è¶³æ¡ä»¶çš„èŠ‚ç‚¹ | NodeAffinityã€TaintTolerationã€PodTopologySpread |
| PostFilter | Filter æ— ç»“æœæ—¶è§¦å‘ï¼ˆå¦‚æŠ¢å ï¼‰ | DefaultPreemptionï¼ˆæŠ¢å ä½ä¼˜å…ˆçº§ Podï¼‰ |
| PreScore | è¯„åˆ†å‰é¢„å¤„ç† | InterPodAffinityï¼ˆé¢„è®¡ç®—äº²å’Œæ€§æ‹“æ‰‘ï¼‰ |
| Score | å¯¹å€™é€‰èŠ‚ç‚¹æ‰“åˆ†ï¼ˆ0~100ï¼‰ | NodeResourcesBalancedAllocationã€ImageLocality |
| Reserve | é¢„ç•™èµ„æºï¼ˆä¹è§‚å‡è®¾ç»‘å®šæˆåŠŸï¼‰ | VolumeBindingï¼ˆé¢„ç•™ PVï¼‰ |
| Permit | æ‰¹å‡†/æ‹’ç»/ç­‰å¾… | â€” |
| Bind | æ‰§è¡Œç»‘å®šï¼ˆå†™å…¥ apiserverï¼‰ | DefaultBinder |

âš ï¸ è°ƒåº¦æ€§èƒ½ä¼˜åŒ–ï¼š`percentageOfNodesToScore` å‚æ•°æ§åˆ¶ Score é˜¶æ®µè¯„ä¼°çš„èŠ‚ç‚¹æ¯”ä¾‹ã€‚åœ¨ 5000+ èŠ‚ç‚¹é›†ç¾¤ä¸­ï¼Œé»˜è®¤å€¼ä¼šè‡ªåŠ¨é™ä½ä»¥ä¿è¯è°ƒåº¦å»¶è¿Ÿã€‚

#### kube-proxy è´Ÿè½½å‡è¡¡å®ç°

**iptables æ¨¡å¼**ï¼ˆé»˜è®¤ï¼‰ï¼š
```bash
# kube-proxy ä¸ºæ¯ä¸ª Service ç”Ÿæˆçš„ iptables è§„åˆ™ç¤ºä¾‹
# Service: my-svc (ClusterIP: 10.96.0.100, Port: 80)
# Endpoints: 10.244.1.5:8080, 10.244.2.6:8080

-A KUBE-SERVICES -d 10.96.0.100/32 -p tcp --dport 80 -j KUBE-SVC-XXXX
-A KUBE-SVC-XXXX -m statistic --mode random --probability 0.5 -j KUBE-SEP-AAA
-A KUBE-SVC-XXXX -j KUBE-SEP-BBB
-A KUBE-SEP-AAA -p tcp -j DNAT --to-destination 10.244.1.5:8080
-A KUBE-SEP-BBB -p tcp -j DNAT --to-destination 10.244.2.6:8080
```

**IPVS æ¨¡å¼**ï¼š
```bash
# ç­‰æ•ˆçš„ IPVS é…ç½®
# ipvsadm -Ln
TCP  10.96.0.100:80 rr
  -> 10.244.1.5:8080    Masq    1      0      0
  -> 10.244.2.6:8080    Masq    1      0      0
```

#### Lease æœºåˆ¶

Kubernetes ä½¿ç”¨ Lease å¯¹è±¡å®ç°ä¸¤ä¸ªå…³é”®åŠŸèƒ½ï¼š

1. **Node å¿ƒè·³**ï¼škubelet æ¯ 10s æ›´æ–°ä¸€æ¬¡ `kube-node-lease` å‘½åç©ºé—´ä¸­çš„ Lease å¯¹è±¡ï¼Œæ¯”æ›´æ–° NodeStatus æ›´è½»é‡ï¼ˆå‡å°‘ etcd å†™å…¥é‡ï¼‰ã€‚

2. **Leader Election**ï¼škube-scheduler å’Œ kube-controller-manager é€šè¿‡ Lease å®ç°ä¸»å¤‡é€‰ä¸¾ï¼š
```go
// ç®€åŒ–çš„ Leader Election é€»è¾‘
leaseClient.Get(leaseName)
if lease.holderIdentity == "" || lease.renewTime + leaseDuration < now {
    // å°è¯•è·å– Leader
    lease.holderIdentity = myIdentity
    lease.renewTime = now
    leaseClient.Update(lease)  // åˆ©ç”¨ ResourceVersion ä¹è§‚é”
}
```

### 2.4 æ•°æ®æ¨¡å‹ä¸å­˜å‚¨ç»“æ„

#### etcd ä¸­çš„æ•°æ®ç»„ç»‡

etcd ä¸­æ‰€æœ‰ Kubernetes å¯¹è±¡æŒ‰ä»¥ä¸‹é”®å€¼ç»“æ„å­˜å‚¨ï¼š

```
/registry/<resource-type>/<namespace>/<name>

ç¤ºä¾‹ï¼š
/registry/pods/default/nginx-pod-abc123
/registry/deployments/kube-system/coredns
/registry/services/specs/default/kubernetes
/registry/configmaps/default/my-config
/registry/nodes/worker-node-1          # éå‘½åç©ºé—´èµ„æºæ—  namespace å±‚çº§
```

æŸ¥çœ‹ etcd ä¸­çš„å®é™…æ•°æ®ï¼š
```bash
# åˆ—å‡ºæ‰€æœ‰é”®ï¼ˆéœ€è¦ etcdctl è®¿é—® etcdï¼‰
ETCDCTL_API=3 etcdctl get /registry --prefix --keys-only

# æŸ¥çœ‹æŸä¸ª Pod çš„å­˜å‚¨å†…å®¹ï¼ˆProtobuf ç¼–ç ï¼‰
ETCDCTL_API=3 etcdctl get /registry/pods/default/nginx-pod --print-value-only | \
  auger decode
```

#### GVK ä¸ GVR

Kubernetes API å¯¹è±¡é€šè¿‡ä¸¤å¥—åæ ‡ç³»ç»Ÿå®šä½ï¼š

| æ¦‚å¿µ | å…¨ç§° | ç¤ºä¾‹ | ç”¨é€” |
|------|------|------|------|
| GVK | Group/Version/Kind | apps/v1/Deployment | æ ‡è¯†å¯¹è±¡ç±»å‹ï¼ˆä»£ç å±‚é¢ï¼‰ |
| GVR | Group/Version/Resource | apps/v1/deployments | æ ‡è¯† REST è·¯å¾„ï¼ˆAPI å±‚é¢ï¼‰ |

```
GVK: apps/v1/Deployment
     â†“ æ˜ å°„
GVR: apps/v1/deployments
     â†“ æ„æˆ REST è·¯å¾„
URL: /apis/apps/v1/namespaces/{ns}/deployments/{name}

æ ¸å¿ƒç»„ï¼ˆcore groupï¼‰çš„ GVR è·¯å¾„ç‰¹æ®Šï¼š
URL: /api/v1/namespaces/{ns}/pods/{name}  ï¼ˆæ³¨æ„æ˜¯ /api è€Œé /apisï¼‰
```

#### Watch æœºåˆ¶ä¸ ResourceVersion

Watch æ˜¯ Kubernetes å®ç°"äº‹ä»¶é©±åŠ¨"çš„æ ¸å¿ƒæœºåˆ¶ï¼š

```
å®¢æˆ·ç«¯                          apiserver                    etcd
  â”‚                               â”‚                           â”‚
  â”‚â”€â”€ GET /api/v1/pods?watch=true â”‚                           â”‚
  â”‚   &resourceVersion=1000       â”‚                           â”‚
  â”‚                               â”‚â”€â”€ Watch /registry/pods    â”‚
  â”‚                               â”‚   (ä» revision 1000 å¼€å§‹)  â”‚
  â”‚                               â”‚                           â”‚
  â”‚                               â”‚â—„â”€â”€ Event: Pod A created   â”‚
  â”‚â—„â”€â”€ {"type":"ADDED",           â”‚    (revision 1001)        â”‚
  â”‚     "object":{...}}           â”‚                           â”‚
  â”‚                               â”‚â—„â”€â”€ Event: Pod B modified  â”‚
  â”‚â—„â”€â”€ {"type":"MODIFIED",        â”‚    (revision 1002)        â”‚
  â”‚     "object":{...}}           â”‚                           â”‚
  â”‚         ...                   â”‚         ...               â”‚
```

ğŸ¯ å…³é”®æ¦‚å¿µï¼š
- **ResourceVersion**ï¼šæ¯ä¸ªå¯¹è±¡éƒ½æœ‰ä¸€ä¸ª ResourceVersionï¼ˆå¯¹åº” etcd çš„ revisionï¼‰ï¼Œç”¨äºä¹è§‚å¹¶å‘æ§åˆ¶å’Œ Watch æ–­ç‚¹ç»­ä¼ 
- **Watch Bookmark**ï¼šapiserver å®šæœŸå‘é€ Bookmark äº‹ä»¶ï¼ˆåªå« ResourceVersionï¼Œæ— å¯¹è±¡æ•°æ®ï¼‰ï¼Œå¸®åŠ©å®¢æˆ·ç«¯æ›´æ–°è¿›åº¦ï¼Œé¿å… Watch é‡è¿æ—¶ä»è¿‡æ—§çš„ç‰ˆæœ¬å¼€å§‹
- **Watch Cache**ï¼šapiserver å†…ç½® Watch Cacheï¼Œé¿å…æ¯ä¸ª Watch è¯·æ±‚éƒ½ç›´æ¥è®¿é—® etcd

### 2.5 é€šä¿¡åè®®

| é€šä¿¡è·¯å¾„ | åè®® | è¯´æ˜ |
|---------|------|------|
| kubectl â†’ apiserver | HTTPS (REST) | æ ‡å‡† RESTful APIï¼Œæ”¯æŒ JSON/YAML/Protobuf |
| apiserver â†’ etcd | gRPC (TLS) | etcd v3 APIï¼Œä½¿ç”¨ Protobuf åºåˆ—åŒ– |
| kubelet â†’ apiserver | HTTPS (REST) | ä¸ŠæŠ¥çŠ¶æ€ã€Watch Pod å˜æ›´ |
| apiserver â†’ kubelet | HTTPS | exec/logs/port-forward ç­‰æµå¼æ“ä½œ |
| kubelet â†’ CRI | gRPC (Unix Socket) | å®¹å™¨è¿è¡Œæ—¶æ¥å£ï¼Œå¦‚ `/run/containerd/containerd.sock` |
| kubelet â†’ CNI | å¯æ‰§è¡Œæ–‡ä»¶è°ƒç”¨ | ç½‘ç»œæ’ä»¶é€šè¿‡ exec è°ƒç”¨ CNI äºŒè¿›åˆ¶ |
| kubelet â†’ CSI | gRPC (Unix Socket) | å­˜å‚¨æ’ä»¶æ¥å£ |
| Admission Webhook | HTTPS (å›è°ƒ) | apiserver ä¸»åŠ¨è°ƒç”¨å¤–éƒ¨ Webhook æœåŠ¡ |
| Aggregated API | HTTPS (ä»£ç†) | apiserver ä»£ç†è¯·æ±‚åˆ°æ‰©å±• API Server |

ğŸ’¡ ä¸ºä»€ä¹ˆ apiserver å¯¹å¤–ç”¨ RESTï¼Œå¯¹ etcd ç”¨ gRPCï¼Ÿ
- **å¯¹å¤– REST**ï¼šé™ä½å®¢æˆ·ç«¯æ¥å…¥é—¨æ§›ï¼Œä»»ä½• HTTP å®¢æˆ·ç«¯éƒ½èƒ½è°ƒç”¨
- **å¯¹ etcd gRPC**ï¼šé«˜æ€§èƒ½ã€å¼ºç±»å‹ã€æ”¯æŒåŒå‘æµï¼ˆWatchï¼‰ï¼Œé€‚åˆå†…éƒ¨é«˜é¢‘é€šä¿¡

---

## ç¬¬ä¸‰ç« ï¼šæºç çº§å®ç°ç»†èŠ‚

> æºç ä»“åº“ï¼šhttps://github.com/kubernetes/kubernetes
> æœ¬ç« åŸºäº Kubernetes 1.32 æºç åˆ†æï¼Œä¸»è¦è¯­è¨€ä¸º Goã€‚

### 3.1 ä»£ç ç»„ç»‡ç»“æ„

```
kubernetes/
â”œâ”€â”€ cmd/                          # å„ç»„ä»¶çš„ main å…¥å£
â”‚   â”œâ”€â”€ kube-apiserver/           # API Server å…¥å£
â”‚   â”œâ”€â”€ kube-controller-manager/  # Controller Manager å…¥å£
â”‚   â”œâ”€â”€ kube-scheduler/           # Scheduler å…¥å£
â”‚   â”œâ”€â”€ kubelet/                  # Kubelet å…¥å£
â”‚   â”œâ”€â”€ kube-proxy/               # Kube-proxy å…¥å£
â”‚   â””â”€â”€ kubectl/                  # kubectl CLI å…¥å£
â”œâ”€â”€ pkg/                          # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚   â”œâ”€â”€ api/                      # å†…éƒ¨ API ç±»å‹å®šä¹‰
â”‚   â”œâ”€â”€ controller/               # å†…ç½®æ§åˆ¶å™¨å®ç°
â”‚   â”œâ”€â”€ kubelet/                  # kubelet æ ¸å¿ƒé€»è¾‘
â”‚   â”œâ”€â”€ scheduler/                # è°ƒåº¦å™¨æ ¸å¿ƒé€»è¾‘
â”‚   â”œâ”€â”€ proxy/                    # kube-proxy æ ¸å¿ƒé€»è¾‘
â”‚   â””â”€â”€ registry/                 # API èµ„æºçš„ REST å­˜å‚¨å®ç°
â”œâ”€â”€ staging/src/k8s.io/           # ç‹¬ç«‹å‘å¸ƒçš„åº“ï¼ˆé€šè¿‡ symlink å¼•ç”¨ï¼‰
â”‚   â”œâ”€â”€ api/                      # å¤–éƒ¨ API ç±»å‹å®šä¹‰ï¼ˆå¦‚ corev1.Podï¼‰
â”‚   â”œâ”€â”€ apimachinery/             # API åŸºç¡€è®¾æ–½ï¼ˆSchemeã€GVKã€åºåˆ—åŒ–ï¼‰
â”‚   â”œâ”€â”€ apiserver/                # é€šç”¨ API Server æ¡†æ¶
â”‚   â”œâ”€â”€ client-go/                # å®˜æ–¹ Go å®¢æˆ·ç«¯åº“ï¼ˆInformer/Lister/ClientSetï¼‰
â”‚   â”œâ”€â”€ controller-manager/       # Controller Manager æ¡†æ¶
â”‚   â””â”€â”€ kubectl/                  # kubectl å‘½ä»¤å®ç°
â”œâ”€â”€ plugin/                       # æ’ä»¶ï¼ˆå¦‚ Admission æ’ä»¶ï¼‰
â”œâ”€â”€ hack/                         # æ„å»ºã€æµ‹è¯•ã€ä»£ç ç”Ÿæˆè„šæœ¬
â”œâ”€â”€ api/                          # OpenAPI è§„èŒƒå®šä¹‰
â”œâ”€â”€ build/                        # æ„å»ºç›¸å…³ï¼ˆDockerfile ç­‰ï¼‰
â””â”€â”€ test/                         # é›†æˆæµ‹è¯•å’Œ e2e æµ‹è¯•
```

ğŸ¯ æ ¸å¿ƒæ¨¡å—åŠŸèƒ½è¯´æ˜ï¼š

| æ¨¡å— | è·¯å¾„ | èŒè´£ |
|------|------|------|
| client-go | `staging/src/k8s.io/client-go/` | K8s å®˜æ–¹ Go å®¢æˆ·ç«¯ï¼ŒåŒ…å« Informer/Lister/ClientSetï¼Œæ˜¯å¼€å‘ Controller/Operator çš„åŸºç¡€ |
| apimachinery | `staging/src/k8s.io/apimachinery/` | API åŸºç¡€è®¾æ–½ï¼šSchemeï¼ˆç±»å‹æ³¨å†Œï¼‰ã€GVK/GVR æ˜ å°„ã€åºåˆ—åŒ–/ååºåˆ—åŒ–ã€å­—æ®µé€‰æ‹©å™¨ |
| apiserver | `staging/src/k8s.io/apiserver/` | é€šç”¨ API Server æ¡†æ¶ï¼šè¯·æ±‚å¤„ç†é“¾ã€è®¤è¯æˆæƒã€å‡†å…¥æ§åˆ¶ã€å®¡è®¡ã€Watch ç¼“å­˜ |
| controller | `pkg/controller/` | å†…ç½®æ§åˆ¶å™¨ï¼šDeploymentã€ReplicaSetã€StatefulSetã€Jobã€Nodeã€Endpoint ç­‰ |
| scheduler | `pkg/scheduler/` | è°ƒåº¦æ¡†æ¶ï¼šScheduling Framework æ’ä»¶ä½“ç³»ã€è°ƒåº¦é˜Ÿåˆ—ã€è°ƒåº¦ç¼“å­˜ |
| kubelet | `pkg/kubelet/` | èŠ‚ç‚¹ä»£ç†ï¼šPod ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€PLEGã€syncLoopã€Volume ç®¡ç†ã€æ¢é’ˆæ£€æŸ¥ |

### 3.2 å…³é”®æ•°æ®ç»“æ„

#### Pod ç»“æ„ä½“

```go
// staging/src/k8s.io/api/core/v1/types.go
type Pod struct {
    metav1.TypeMeta   `json:",inline"`          // apiVersion + kind
    metav1.ObjectMeta `json:"metadata,omitempty"` // name, namespace, labels, annotations, resourceVersion...

    Spec   PodSpec   `json:"spec,omitempty"`   // æœŸæœ›çŠ¶æ€ï¼šå®¹å™¨å®šä¹‰ã€å·ã€è°ƒåº¦çº¦æŸ
    Status PodStatus `json:"status,omitempty"` // å®é™…çŠ¶æ€ï¼šphase, conditions, podIP, containerStatuses
}

type PodSpec struct {
    Containers     []Container     `json:"containers"`               // ä¸»å®¹å™¨åˆ—è¡¨
    InitContainers []Container     `json:"initContainers,omitempty"` // Init å®¹å™¨ï¼ˆå« Sidecarï¼‰
    Volumes        []Volume        `json:"volumes,omitempty"`        // å·å®šä¹‰
    NodeName       string          `json:"nodeName,omitempty"`       // è°ƒåº¦ç»“æœï¼šç›®æ ‡èŠ‚ç‚¹
    NodeSelector   map[string]string `json:"nodeSelector,omitempty"` // èŠ‚ç‚¹é€‰æ‹©å™¨
    Tolerations    []Toleration    `json:"tolerations,omitempty"`    // å®¹å¿åº¦
    // ... æ›´å¤šå­—æ®µ
}

// 1.32 Sidecar Container ç¤ºä¾‹ï¼šrestartPolicy=Always çš„ Init Container
type Container struct {
    Name          string          `json:"name"`
    Image         string          `json:"image"`
    Resources     ResourceRequirements `json:"resources,omitempty"`
    RestartPolicy *ContainerRestartPolicy `json:"restartPolicy,omitempty"` // Sidecar: Always
    // ...
}
```

#### Informer æ ¸å¿ƒæ¶æ„

```go
// staging/src/k8s.io/client-go/tools/cache/shared_informer.go

// SharedIndexInformer æ˜¯ client-go çš„æ ¸å¿ƒç¼“å­˜æœºåˆ¶
// å®ƒå°† Watch äº‹ä»¶è½¬åŒ–ä¸ºæœ¬åœ°ç¼“å­˜ + äº‹ä»¶å›è°ƒ
type SharedIndexInformer interface {
    // æ·»åŠ äº‹ä»¶å¤„ç†å™¨
    AddEventHandler(handler ResourceEventHandler) (ResourceEventHandlerRegistration, error)
    // è·å–æœ¬åœ°ç¼“å­˜çš„ Indexer
    GetIndexer() Indexer
    // å¯åŠ¨ Informer
    Run(stopCh <-chan struct{})
}

// ResourceEventHandler å®šä¹‰äº†ä¸‰ç§äº‹ä»¶å›è°ƒ
type ResourceEventHandler interface {
    OnAdd(obj interface{}, isInInitialList bool)
    OnUpdate(oldObj, newObj interface{})
    OnDelete(obj interface{})
}
```

Informer å†…éƒ¨æ•°æ®æµï¼š

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  API Server  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ List + Watch
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Reflector   â”‚  è´Ÿè´£ List-Watchï¼Œå°†äº‹ä»¶å†™å…¥ DeltaFIFO
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  DeltaFIFO   â”‚  å¢é‡é˜Ÿåˆ—ï¼šå­˜å‚¨ (key, DeltaType) å¯¹
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ Pop()
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Indexer     â”‚  æœ¬åœ°ç¼“å­˜ï¼ˆçº¿ç¨‹å®‰å…¨çš„ Store + ç´¢å¼•ï¼‰
                    â”‚  (Store)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ åŒæ—¶è§¦å‘
                    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ EventHandler â”‚  OnAdd / OnUpdate / OnDelete
                    â”‚  å›è°ƒ        â”‚  â†’ å°† key æ”¾å…¥ workqueue
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### workqueueï¼ˆå·¥ä½œé˜Ÿåˆ—ï¼‰

```go
// staging/src/k8s.io/client-go/util/workqueue/

// ä¸‰ç§é˜Ÿåˆ—ç±»å‹ï¼Œå±‚å±‚å¢å¼ºï¼š
// 1. åŸºç¡€é˜Ÿåˆ—ï¼šå»é‡ + FIFO
type Interface interface {
    Add(item interface{})           // æ·»åŠ å…ƒç´ ï¼ˆè‡ªåŠ¨å»é‡ï¼‰
    Get() (item interface{}, shutdown bool) // è·å–å…ƒç´ 
    Done(item interface{})          // æ ‡è®°å¤„ç†å®Œæˆ
    ShutDown()
}

// 2. å»¶è¿Ÿé˜Ÿåˆ—ï¼šæ”¯æŒå»¶è¿Ÿå…¥é˜Ÿ
type DelayingInterface interface {
    Interface
    AddAfter(item interface{}, duration time.Duration)
}

// 3. é™é€Ÿé˜Ÿåˆ—ï¼šæ”¯æŒæŒ‡æ•°é€€é¿é‡è¯•
type RateLimitingInterface interface {
    DelayingInterface
    AddRateLimited(item interface{})  // æŒ‰é™é€Ÿç­–ç•¥å»¶è¿Ÿå…¥é˜Ÿ
    Forget(item interface{})          // é‡ç½®é‡è¯•è®¡æ•°
    NumRequeues(item interface{}) int // æŸ¥è¯¢é‡è¯•æ¬¡æ•°
}
```

ğŸ’¡ ä¸ºä»€ä¹ˆéœ€è¦ä¸‰å±‚é˜Ÿåˆ—ï¼Ÿ
- **å»é‡**ï¼šåŒä¸€ä¸ªå¯¹è±¡çŸ­æ—¶é—´å†…å¤šæ¬¡å˜æ›´ï¼Œåªéœ€å¤„ç†ä¸€æ¬¡ï¼ˆæœ€ç»ˆçŠ¶æ€ï¼‰
- **å»¶è¿Ÿ**ï¼šæŸäº›æ“ä½œéœ€è¦ç­‰å¾…ï¼ˆå¦‚ç­‰å¾… Pod å°±ç»ªåå†æ£€æŸ¥ï¼‰
- **é™é€Ÿ**ï¼šå¤„ç†å¤±è´¥æ—¶æŒ‡æ•°é€€é¿é‡è¯•ï¼ˆ10sâ†’20sâ†’40s...â†’maxï¼‰ï¼Œé¿å…çƒ­å¾ªç¯

### 3.3 å¹¶å‘æ¨¡å‹

Kubernetes å¤§é‡ä½¿ç”¨ Go çš„å¹¶å‘åŸè¯­ï¼š

#### Informer çš„ Reflector â†’ DeltaFIFO â†’ Indexer æµæ°´çº¿

```go
// ç®€åŒ–çš„ Reflector è¿è¡Œé€»è¾‘
func (r *Reflector) Run(stopCh <-chan struct{}) {
    // 1. é¦–æ¬¡ Listï¼šè·å–å…¨é‡æ•°æ®
    list, resourceVersion := r.listerWatcher.List(options)
    r.syncWith(list, resourceVersion)  // å†™å…¥ DeltaFIFO

    // 2. æŒç»­ Watchï¼šå¢é‡æ›´æ–°
    for {
        watcher := r.listerWatcher.Watch(options{ResourceVersion: resourceVersion})
        for event := range watcher.ResultChan() {
            switch event.Type {
            case watch.Added:
                r.store.Add(event.Object)    // å†™å…¥ DeltaFIFO
            case watch.Modified:
                r.store.Update(event.Object)
            case watch.Deleted:
                r.store.Delete(event.Object)
            }
            resourceVersion = event.Object.GetResourceVersion()
        }
        // Watch æ–­å¼€åè‡ªåŠ¨é‡è¿ï¼Œä» resourceVersion ç»­ä¼ 
    }
}
```

#### Controller çš„ worker åç¨‹æ± 

```go
// å…¸å‹çš„ Controller å¯åŠ¨æ¨¡å¼
func (c *Controller) Run(workers int, stopCh <-chan struct{}) {
    defer c.queue.ShutDown()

    // ç­‰å¾… Informer ç¼“å­˜åŒæ­¥å®Œæˆ
    if !cache.WaitForCacheSync(stopCh, c.hasSynced) {
        return
    }

    // å¯åŠ¨ N ä¸ª worker åç¨‹å¹¶å‘å¤„ç†
    for i := 0; i < workers; i++ {
        go wait.Until(c.runWorker, time.Second, stopCh)
    }

    <-stopCh // é˜»å¡ç›´åˆ°æ”¶åˆ°åœæ­¢ä¿¡å·
}

func (c *Controller) runWorker() {
    for c.processNextWorkItem() {
    }
}

func (c *Controller) processNextWorkItem() bool {
    key, quit := c.queue.Get()  // ä» workqueue å–å‡ºä¸€ä¸ª key
    if quit { return false }
    defer c.queue.Done(key)

    err := c.syncHandler(key.(string))  // æ‰§è¡Œ Reconcile é€»è¾‘
    if err != nil {
        c.queue.AddRateLimited(key)     // å¤±è´¥åˆ™é™é€Ÿé‡å…¥é˜Ÿåˆ—
        return true
    }
    c.queue.Forget(key)                 // æˆåŠŸåˆ™é‡ç½®é‡è¯•è®¡æ•°
    return true
}
```

ğŸ¯ å¹¶å‘æ¨¡å‹æ€»ç»“ï¼š
- **Reflector**ï¼šå•åç¨‹æ‰§è¡Œ List-Watchï¼Œå†™å…¥ DeltaFIFO
- **Informer processLoop**ï¼šå•åç¨‹ä» DeltaFIFO Popï¼Œæ›´æ–° Indexer + è§¦å‘ EventHandler
- **Controller workers**ï¼šå¤šåç¨‹ä» workqueue å– key å¹¶å‘å¤„ç†ï¼ˆé»˜è®¤ 2~5 ä¸ª workerï¼‰
- **ä¼˜é›…é€€å‡º**ï¼šé€šè¿‡ `stopCh`ï¼ˆ`<-chan struct{}`ï¼‰å’Œ `context.Context` çº§è”å–æ¶ˆ

### 3.4 é‡è¦ç±»/æ¥å£è®¾è®¡

#### runtime.Object â€” æ‰€æœ‰ API å¯¹è±¡çš„åŸºæ¥å£

```go
// staging/src/k8s.io/apimachinery/pkg/runtime/interfaces.go
type Object interface {
    GetObjectKind() schema.ObjectKind  // è¿”å› GVK ä¿¡æ¯
    DeepCopyObject() Object            // æ·±æ‹·è´ï¼ˆå¹¶å‘å®‰å…¨ï¼‰
}
```

æ‰€æœ‰ K8s API å¯¹è±¡ï¼ˆPodã€Deploymentã€Service ç­‰ï¼‰éƒ½å®ç°æ­¤æ¥å£ã€‚

#### Scheme â€” ç±»å‹æ³¨å†Œä¸è½¬æ¢ï¼ˆå·¥å‚æ¨¡å¼ + æ³¨å†Œè¡¨æ¨¡å¼ï¼‰

```go
// staging/src/k8s.io/apimachinery/pkg/runtime/scheme.go
type Scheme struct {
    gvkToType map[schema.GroupVersionKind]reflect.Type  // GVK â†’ Go ç±»å‹
    typeToGVK map[reflect.Type][]schema.GroupVersionKind // Go ç±»å‹ â†’ GVK
    converter *conversion.Converter                      // ç‰ˆæœ¬è½¬æ¢å™¨
    // ...
}

// æ³¨å†Œç±»å‹
scheme.AddKnownTypes(corev1.SchemeGroupVersion,
    &corev1.Pod{},
    &corev1.Service{},
    &corev1.ConfigMap{},
)

// ä½¿ç”¨ï¼šæ ¹æ® GVK åˆ›å»ºå¯¹è±¡å®ä¾‹ï¼ˆå·¥å‚æ¨¡å¼ï¼‰
obj, err := scheme.New(schema.GroupVersionKind{
    Group: "", Version: "v1", Kind: "Pod",
})
// obj æ˜¯ *corev1.Pod ç±»å‹
```

#### RESTStorage â€” API èµ„æºçš„ CRUD æŠ½è±¡ï¼ˆç­–ç•¥æ¨¡å¼ï¼‰

```go
// staging/src/k8s.io/apiserver/pkg/registry/rest/rest.go

// æ¯ä¸ª API èµ„æºå®ç°ä»¥ä¸‹æ¥å£çš„å­é›†
type Storage interface {
    New() runtime.Object  // åˆ›å»ºç©ºå¯¹è±¡
}

type Getter interface {
    Get(ctx context.Context, name string, options *metav1.GetOptions) (runtime.Object, error)
}

type Lister interface {
    NewList() runtime.Object
    List(ctx context.Context, options *metainternalversion.ListOptions) (runtime.Object, error)
}

type Creater interface {
    Create(ctx context.Context, obj runtime.Object, ...) (runtime.Object, error)
}

type Updater interface {
    Update(ctx context.Context, name string, objInfo UpdatedObjectInfo, ...) (runtime.Object, bool, error)
}

type GracefulDeleter interface {
    Delete(ctx context.Context, name string, ...) (runtime.Object, bool, error)
}

type Watcher interface {
    Watch(ctx context.Context, options *metainternalversion.ListOptions) (watch.Interface, error)
}
```

ğŸ’¡ è®¾è®¡æ¨¡å¼æ ‡æ³¨ï¼š
- **å·¥å‚æ¨¡å¼**ï¼š`Scheme.New()` æ ¹æ® GVK åˆ›å»ºå¯¹è±¡å®ä¾‹
- **ç­–ç•¥æ¨¡å¼**ï¼šRESTStorage æ¥å£ç»„åˆï¼Œä¸åŒèµ„æºå®ç°ä¸åŒçš„æ¥å£å­é›†
- **è§‚å¯Ÿè€…æ¨¡å¼**ï¼šInformer çš„ EventHandler å›è°ƒæœºåˆ¶
- **æ¨¡æ¿æ–¹æ³•æ¨¡å¼**ï¼šController çš„ `processNextWorkItem` å®šä¹‰å¤„ç†éª¨æ¶ï¼Œ`syncHandler` ç”±å…·ä½“æ§åˆ¶å™¨å®ç°

### 3.5 å¯åŠ¨æµç¨‹

#### kube-apiserver å¯åŠ¨å…¨è¿‡ç¨‹

```
cmd/kube-apiserver/apiserver.go: main()
  â”‚
  â”œâ”€â”€ 1. å‘½ä»¤è¡Œè§£æï¼ˆcobra.Commandï¼‰
  â”‚     è§£æ --etcd-servers, --service-cluster-ip-range, --tls-cert-file ç­‰
  â”‚
  â”œâ”€â”€ 2. æ„å»º ServerConfig
  â”‚     â”œâ”€â”€ GenericConfigï¼ˆè®¤è¯ã€æˆæƒã€å®¡è®¡ã€å‡†å…¥æ§åˆ¶é“¾ï¼‰
  â”‚     â”œâ”€â”€ EtcdConfigï¼ˆetcd è¿æ¥ã€å­˜å‚¨åç«¯ï¼‰
  â”‚     â””â”€â”€ ServiceIPRangeï¼ˆService ClusterIP åˆ†é…èŒƒå›´ï¼‰
  â”‚
  â”œâ”€â”€ 3. åˆ›å»º API Server å®ä¾‹
  â”‚     â”œâ”€â”€ KubeAPIServerï¼ˆæ ¸å¿ƒ APIï¼šPod/Service/Deployment ç­‰ï¼‰
  â”‚     â”œâ”€â”€ APIExtensionsServerï¼ˆCRD ç›¸å…³ APIï¼‰
  â”‚     â””â”€â”€ AggregatorServerï¼ˆAPI èšåˆå±‚ï¼‰
  â”‚     ä¸‰è€…é€šè¿‡ Delegation é“¾ä¸²è”ï¼šAggregator â†’ KubeAPI â†’ APIExtensions
  â”‚
  â”œâ”€â”€ 4. æ³¨å†Œ API èµ„æºçš„ Handler
  â”‚     æ¯ä¸ª GVR æ³¨å†Œåˆ° HTTP è·¯ç”±ï¼š
  â”‚     /apis/{group}/{version}/namespaces/{ns}/{resource}/{name}
  â”‚     Handler é“¾ï¼šè®¤è¯ â†’ æˆæƒ â†’ å‡†å…¥ â†’ RESTStorage.CRUD
  â”‚
  â”œâ”€â”€ 5. å¯åŠ¨åå° goroutine
  â”‚     â”œâ”€â”€ PostStartHookï¼ˆå¦‚å¯åŠ¨å†…ç½®æ§åˆ¶å™¨ã€GCï¼‰
  â”‚     â”œâ”€â”€ Watch Cache åˆå§‹åŒ–
  â”‚     â””â”€â”€ å¥åº·æ£€æŸ¥ç«¯ç‚¹ (/healthz, /livez, /readyz)
  â”‚
  â””â”€â”€ 6. å¯åŠ¨ HTTPS æœåŠ¡
        ç›‘å¬ --secure-portï¼ˆé»˜è®¤ 6443ï¼‰
        å¼€å§‹æ¥å—è¯·æ±‚
```

#### kubelet å¯åŠ¨å…¨è¿‡ç¨‹

```
cmd/kubelet/kubelet.go: main()
  â”‚
  â”œâ”€â”€ 1. é…ç½®åŠ è½½
  â”‚     â”œâ”€â”€ å‘½ä»¤è¡Œå‚æ•° + KubeletConfigurationï¼ˆæ–‡ä»¶/ConfigMapï¼‰
  â”‚     â””â”€â”€ æ³¨å†ŒèŠ‚ç‚¹åˆ° apiserver
  â”‚
  â”œâ”€â”€ 2. åˆå§‹åŒ–æ ¸å¿ƒæ¨¡å—
  â”‚     â”œâ”€â”€ containerRuntimeï¼ˆé€šè¿‡ CRI è¿æ¥ containerdï¼‰
  â”‚     â”œâ”€â”€ podManagerï¼ˆPod å…ƒæ•°æ®ç®¡ç†ï¼‰
  â”‚     â”œâ”€â”€ statusManagerï¼ˆPod çŠ¶æ€ä¸ŠæŠ¥ï¼‰
  â”‚     â”œâ”€â”€ volumeManagerï¼ˆå·æŒ‚è½½/å¸è½½ï¼‰
  â”‚     â”œâ”€â”€ imageManagerï¼ˆé•œåƒ GCï¼‰
  â”‚     â””â”€â”€ probeManagerï¼ˆå¥åº·æ£€æŸ¥æ¢é’ˆï¼‰
  â”‚
  â”œâ”€â”€ 3. å¯åŠ¨ PLEGï¼ˆPod Lifecycle Event Generatorï¼‰
  â”‚     æ¯ç§’æ£€æŸ¥å®¹å™¨è¿è¡Œæ—¶çŠ¶æ€ï¼Œç”Ÿæˆ Pod ç”Ÿå‘½å‘¨æœŸäº‹ä»¶
  â”‚     ï¼ˆå¦‚ ContainerStarted, ContainerDiedï¼‰
  â”‚
  â”œâ”€â”€ 4. å¯åŠ¨ syncLoopï¼ˆæ ¸å¿ƒä¸»å¾ªç¯ï¼‰
  â”‚     ç›‘å¬å¤šä¸ªäº‹ä»¶æºï¼š
  â”‚     â”œâ”€â”€ configChï¼šæ¥è‡ª apiserver çš„ Pod é…ç½®å˜æ›´
  â”‚     â”œâ”€â”€ plegChï¼šæ¥è‡ª PLEG çš„å®¹å™¨çŠ¶æ€å˜æ›´
  â”‚     â”œâ”€â”€ syncChï¼šå®šæ—¶å…¨é‡åŒæ­¥ï¼ˆé»˜è®¤æ¯ 1 åˆ†é’Ÿï¼‰
  â”‚     â”œâ”€â”€ housekeepingChï¼šæ¸…ç†ä»»åŠ¡ï¼ˆé»˜è®¤æ¯ 2 ç§’ï¼‰
  â”‚     â””â”€â”€ livenessManagerï¼šæ¢é’ˆç»“æœ
  â”‚
  â””â”€â”€ 5. æœåŠ¡å°±ç»ª
        â”œâ”€â”€ å¼€æ”¾ /healthz, /pods, /metrics ç«¯ç‚¹
        â””â”€â”€ å¼€å§‹å¤„ç† Pod åˆ›å»º/æ›´æ–°/åˆ é™¤è¯·æ±‚
```

âš ï¸ kubelet çš„ syncLoop æ˜¯æ•´ä¸ªèŠ‚ç‚¹ç®¡ç†çš„"å¿ƒè„"â€”â€”å®ƒæ˜¯ä¸€ä¸ª `select` å¤šè·¯å¤ç”¨å¾ªç¯ï¼ŒæŒç»­ç›‘å¬ä¸Šè¿°æ‰€æœ‰äº‹ä»¶æºï¼Œç¡®ä¿èŠ‚ç‚¹ä¸Šçš„ Pod çŠ¶æ€ä¸æœŸæœ›çŠ¶æ€ä¸€è‡´ã€‚

---

## ç¬¬å››ç« ï¼šè®¾è®¡æ¨¡å¼æ·±åº¦å‰–æ

### 4.1 æ¶æ„å±‚é¢çš„æ¨¡å¼

#### å£°æ˜å¼ API + æ§åˆ¶å™¨æ¨¡å¼ï¼ˆReconciliation Loopï¼‰

ğŸ¯ è¿™æ˜¯ Kubernetes æœ€æ ¸å¿ƒçš„è®¾è®¡å“²å­¦ï¼Œç†è§£å®ƒå°±ç†è§£äº† K8s çš„çµé­‚ã€‚

**æ ¸å¿ƒæ€æƒ³**ï¼šç”¨æˆ·å£°æ˜æœŸæœ›çŠ¶æ€ï¼ˆDesired Stateï¼‰ï¼Œæ§åˆ¶å™¨æŒç»­å°†å®é™…çŠ¶æ€ï¼ˆActual Stateï¼‰å‘æœŸæœ›çŠ¶æ€æ”¶æ•›ã€‚

```
ç”¨æˆ·å£°æ˜ï¼š                    æ§åˆ¶å™¨å¾ªç¯ï¼š
"æˆ‘è¦ 3 ä¸ª nginx Pod"         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                              â”‚  è§‚å¯Ÿ(Observe)        â”‚
    Deployment YAML â”€â”€â”€â”€â”€â”€â–º   â”‚  å½“å‰æœ‰å‡ ä¸ª Podï¼Ÿ      â”‚
    replicas: 3               â”‚                      â”‚
                              â”‚  å¯¹æ¯”(Diff)           â”‚
                              â”‚  æœŸæœ›3ä¸ªï¼Œå®é™…2ä¸ª      â”‚
                              â”‚                      â”‚
                              â”‚  è¡ŒåŠ¨(Act)            â”‚
                              â”‚  åˆ›å»º1ä¸ªæ–° Pod         â”‚
                              â”‚                      â”‚
                              â”‚  å¾ªç¯(Loop)           â”‚
                              â”‚  ç»§ç»­è§‚å¯Ÿ...           â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ä¸ºä»€ä¹ˆé€‰æ‹©å£°æ˜å¼è€Œéå‘½ä»¤å¼ï¼Ÿ**

| ç»´åº¦ | å‘½ä»¤å¼ï¼ˆImperativeï¼‰ | å£°æ˜å¼ï¼ˆDeclarativeï¼‰ |
|------|---------------------|---------------------|
| è¡¨è¾¾æ–¹å¼ | "åˆ›å»º3ä¸ªPod" | "æˆ‘è¦3ä¸ªPod" |
| å¹‚ç­‰æ€§ | âŒ é‡å¤æ‰§è¡Œä¼šåˆ›å»º6ä¸ª | âœ… é‡å¤æ‰§è¡Œä»æ˜¯3ä¸ª |
| æ•…éšœæ¢å¤ | âŒ éœ€è¦äººå·¥å¹²é¢„ | âœ… æ§åˆ¶å™¨è‡ªåŠ¨ä¿®å¤ |
| çŠ¶æ€æ¼‚ç§» | âŒ æ— æ³•æ£€æµ‹ | âœ… æŒç»­æ”¶æ•› |
| å¤šäººåä½œ | âŒ æ“ä½œå†²çª | âœ… ä»¥æœ€ç»ˆçŠ¶æ€ä¸ºå‡† |
| GitOps å‹å¥½ | âŒ éš¾ä»¥ç‰ˆæœ¬åŒ– | âœ… YAML å³ä»£ç  |

ğŸ’¡ ç±»æ¯”ç†è§£ï¼šå£°æ˜å¼å°±åƒæ’æ¸©ç©ºè°ƒâ€”â€”ä½ è®¾å®š 25Â°Cï¼ˆæœŸæœ›çŠ¶æ€ï¼‰ï¼Œç©ºè°ƒè‡ªåŠ¨è°ƒèŠ‚åˆ¶å†·/åˆ¶çƒ­ï¼ˆæ§åˆ¶å™¨ï¼‰ï¼Œæ— è®ºå¤–ç•Œæ¸©åº¦å¦‚ä½•å˜åŒ–ï¼ˆæ•…éšœ/æ‰°åŠ¨ï¼‰ï¼Œå®¤æ¸©å§‹ç»ˆè¶‹å‘ 25Â°Cã€‚

#### Operator æ¨¡å¼

Operator = CRDï¼ˆè‡ªå®šä¹‰èµ„æºï¼‰ + è‡ªå®šä¹‰ Controller

```
ä¼ ç»Ÿè¿ç»´ï¼š                     Operator æ¨¡å¼ï¼š
DBA æ‰‹åŠ¨æ“ä½œ MySQL             MySQL Operator è‡ªåŠ¨åŒ–
â”œâ”€â”€ åˆ›å»ºä¸»ä»å®ä¾‹               â”œâ”€â”€ ç”¨æˆ·åˆ›å»º MySQLCluster CR
â”œâ”€â”€ é…ç½®å¤åˆ¶                   â”œâ”€â”€ Operator è‡ªåŠ¨åˆ›å»º StatefulSet
â”œâ”€â”€ ç›‘æ§å¥åº·çŠ¶æ€               â”œâ”€â”€ Operator è‡ªåŠ¨é…ç½®ä¸»ä»å¤åˆ¶
â”œâ”€â”€ æ•…éšœåˆ‡æ¢                   â”œâ”€â”€ Operator è‡ªåŠ¨æ•…éšœåˆ‡æ¢
â””â”€â”€ å¤‡ä»½æ¢å¤                   â””â”€â”€ Operator è‡ªåŠ¨å®šæ—¶å¤‡ä»½
```

Operator å¼€å‘æ¡†æ¶ï¼š
```go
// ä½¿ç”¨ controller-runtimeï¼ˆKubebuilder/Operator SDK çš„åŸºç¡€ï¼‰
// ä¸€ä¸ªæœ€ç®€ Operator çš„ Reconcile å‡½æ•°
func (r *MySQLClusterReconciler) Reconcile(ctx context.Context,
    req ctrl.Request) (ctrl.Result, error) {

    // 1. è·å– CR å¯¹è±¡
    cluster := &v1alpha1.MySQLCluster{}
    if err := r.Get(ctx, req.NamespacedName, cluster); err != nil {
        return ctrl.Result{}, client.IgnoreNotFound(err)
    }

    // 2. ç¡®ä¿ StatefulSet å­˜åœ¨
    sts := &appsv1.StatefulSet{}
    err := r.Get(ctx, types.NamespacedName{Name: cluster.Name, Namespace: cluster.Namespace}, sts)
    if errors.IsNotFound(err) {
        sts = r.buildStatefulSet(cluster)
        return ctrl.Result{}, r.Create(ctx, sts)
    }

    // 3. ç¡®ä¿å‰¯æœ¬æ•°ä¸€è‡´
    if *sts.Spec.Replicas != cluster.Spec.Replicas {
        sts.Spec.Replicas = &cluster.Spec.Replicas
        return ctrl.Result{}, r.Update(ctx, sts)
    }

    // 4. æ£€æŸ¥å¥åº·çŠ¶æ€ï¼Œå¿…è¦æ—¶è§¦å‘æ•…éšœåˆ‡æ¢
    // ...

    return ctrl.Result{RequeueAfter: 30 * time.Second}, nil
}
```

#### Sidecar æ¨¡å¼ï¼ˆ1.32 GAï¼‰

åœ¨ Kubernetes 1.32 ä¸­ï¼ŒSidecar Containers æ­£å¼ GAã€‚å®ç°æ–¹å¼æ˜¯åœ¨ `initContainers` ä¸­è®¾ç½® `restartPolicy: Always`ï¼š

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: app-with-sidecar
spec:
  initContainers:
  - name: istio-proxy          # Sidecar å®¹å™¨
    image: istio/proxyv2:1.20
    restartPolicy: Always      # å…³é”®ï¼šæ ‡è®°ä¸º Sidecar
    ports:
    - containerPort: 15090
  containers:
  - name: app                  # ä¸»å®¹å™¨
    image: my-app:v1
```

ğŸ¯ Sidecar GA è§£å†³çš„æ ¸å¿ƒé—®é¢˜ï¼š
- **ç”Ÿå‘½å‘¨æœŸç®¡ç†**ï¼šSidecar åœ¨æ‰€æœ‰ Init Container ä¹‹åå¯åŠ¨ï¼Œåœ¨ä¸»å®¹å™¨ä¹‹åç»ˆæ­¢
- **Job å…¼å®¹**ï¼šJob å®Œæˆæ—¶ Sidecar ä¼šè¢«æ­£ç¡®ç»ˆæ­¢ï¼ˆä¹‹å‰ Sidecar ä¸é€€å‡ºå¯¼è‡´ Job æ°¸è¿œä¸å®Œæˆï¼‰
- **å¯åŠ¨é¡ºåº**ï¼šSidecar å°±ç»ªåä¸»å®¹å™¨æ‰å¯åŠ¨ï¼Œä¿è¯ä»£ç†/æ—¥å¿—æ”¶é›†å™¨å…ˆäºä¸šåŠ¡å°±ç»ª

#### Ambassador / Adapter æ¨¡å¼

```yaml
# Ambassador æ¨¡å¼ï¼šä»£ç†å®¹å™¨å¤„ç†å¤–éƒ¨é€šä¿¡
spec:
  containers:
  - name: app
    image: my-app:v1
  - name: ambassador           # ä»£ç†å®¹å™¨
    image: haproxy:2.8         # å¤„ç†è¿æ¥æ± ã€TLS ç»ˆæ­¢ç­‰
    ports:
    - containerPort: 8080

# Adapter æ¨¡å¼ï¼šé€‚é…å®¹å™¨è½¬æ¢æ•°æ®æ ¼å¼
spec:
  containers:
  - name: app
    image: my-app:v1
  - name: log-adapter          # é€‚é…å®¹å™¨
    image: fluentd:v1.16       # å°†åº”ç”¨æ—¥å¿—è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
    volumeMounts:
    - name: log-volume
      mountPath: /var/log/app
```

### 4.2 GoF è®¾è®¡æ¨¡å¼åœ¨æºç ä¸­çš„åº”ç”¨

#### 1. å·¥å‚æ¨¡å¼ â€” cmdutil.Factory

```go
// staging/src/k8s.io/kubectl/pkg/cmd/util/factory.go
// kubectl ä½¿ç”¨ Factory æ¥å£æŠ½è±¡å®¢æˆ·ç«¯åˆ›å»ºè¿‡ç¨‹
type Factory interface {
    // åˆ›å»º REST å®¢æˆ·ç«¯æ˜ å°„å™¨
    ToRESTMapper() (meta.RESTMapper, error)
    // åˆ›å»º Discovery å®¢æˆ·ç«¯
    ToDiscoveryClient() (discovery.CachedDiscoveryInterface, error)
    // åˆ›å»º REST é…ç½®
    ToRESTConfig() (*rest.Config, error)
    // åˆ›å»ºåŠ¨æ€å®¢æˆ·ç«¯
    DynamicClient() (dynamic.Interface, error)
    // åˆ›å»º Kubernetes å®¢æˆ·ç«¯
    KubernetesClientSet() (*kubernetes.Clientset, error)
}
```

**ä¸ºä»€ä¹ˆç”¨å·¥å‚æ¨¡å¼**ï¼škubectl éœ€è¦æ”¯æŒå¤šç§è®¤è¯æ–¹å¼ï¼ˆkubeconfigã€ServiceAccountã€OIDC ç­‰ï¼‰ï¼Œå·¥å‚æ¨¡å¼å°†å®¢æˆ·ç«¯åˆ›å»ºé€»è¾‘ä¸ä½¿ç”¨é€»è¾‘è§£è€¦ã€‚

#### 2. ç­–ç•¥æ¨¡å¼ â€” è°ƒåº¦å™¨ Score æ’ä»¶

```go
// pkg/scheduler/framework/interface.go
type ScorePlugin interface {
    Plugin
    Score(ctx context.Context, state *CycleState, pod *v1.Pod, nodeName string) (int64, *Status)
    ScoreExtensions() ScoreExtensions
}

// ä¸åŒçš„è¯„åˆ†ç­–ç•¥å®ç°åŒä¸€æ¥å£ï¼š
// - NodeResourcesBalancedAllocationï¼šå€¾å‘èµ„æºå‡è¡¡çš„èŠ‚ç‚¹
// - ImageLocalityï¼šå€¾å‘å·²æœ‰é•œåƒçš„èŠ‚ç‚¹
// - InterPodAffinityï¼šå€¾å‘æ»¡è¶³äº²å’Œæ€§çš„èŠ‚ç‚¹
// - NodeResourcesFitï¼šå€¾å‘èµ„æºå……è¶³çš„èŠ‚ç‚¹
```

**ä¸ºä»€ä¹ˆç”¨ç­–ç•¥æ¨¡å¼**ï¼šè°ƒåº¦ç­–ç•¥éœ€è¦å¯æ’æ‹”ã€å¯ç»„åˆã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡ KubeSchedulerConfiguration å¯ç”¨/ç¦ç”¨/è°ƒæ•´æƒé‡ã€‚

#### 3. è§‚å¯Ÿè€…æ¨¡å¼ â€” Informer EventHandler

```go
// staging/src/k8s.io/client-go/tools/cache/shared_informer.go
// Informer å…è®¸æ³¨å†Œå¤šä¸ª EventHandlerï¼Œå½“èµ„æºå˜æ›´æ—¶é€šçŸ¥æ‰€æœ‰è§‚å¯Ÿè€…

podInformer.AddEventHandler(cache.ResourceEventHandlerFuncs{
    AddFunc: func(obj interface{}) {
        // Pod åˆ›å»ºæ—¶è§¦å‘
        controller.enqueue(obj)
    },
    UpdateFunc: func(oldObj, newObj interface{}) {
        // Pod æ›´æ–°æ—¶è§¦å‘
        controller.enqueue(newObj)
    },
    DeleteFunc: func(obj interface{}) {
        // Pod åˆ é™¤æ—¶è§¦å‘
        controller.enqueue(obj)
    },
})
```

**ä¸ºä»€ä¹ˆç”¨è§‚å¯Ÿè€…æ¨¡å¼**ï¼šå¤šä¸ªæ§åˆ¶å™¨å¯èƒ½å…³æ³¨åŒä¸€ç§èµ„æºï¼ˆå¦‚ Deployment Controller å’Œ HPA Controller éƒ½å…³æ³¨ Podï¼‰ï¼Œè§‚å¯Ÿè€…æ¨¡å¼å®ç°ä¸€å¯¹å¤šçš„äº‹ä»¶åˆ†å‘ã€‚

#### 4. è´£ä»»é“¾æ¨¡å¼ â€” Admission Webhook é“¾

```go
// staging/src/k8s.io/apiserver/pkg/admission/chain.go
type chainAdmissionHandler []Interface

func (admissionHandler chainAdmissionHandler) Admit(
    ctx context.Context, a Attributes, o ObjectInterfaces) error {
    for _, handler := range admissionHandler {
        if !handler.Handles(a.GetOperation()) {
            continue
        }
        err := handler.Admit(ctx, a, o)
        if err != nil {
            return err  // ä»»ä¸€ç¯èŠ‚æ‹’ç»åˆ™æ•´ä½“æ‹’ç»
        }
    }
    return nil
}
```

è¯·æ±‚å¤„ç†é“¾ï¼š`Mutating Webhook 1 â†’ Mutating Webhook 2 â†’ ... â†’ Validating Webhook 1 â†’ Validating Webhook 2 â†’ ...`

### 4.3 åˆ†å¸ƒå¼ç³»ç»Ÿæ¨¡å¼

#### Leader Election â€” åŸºäº Lease çš„é€‰ä¸»

```mermaid
sequenceDiagram
    participant A as å®ä¾‹ A
    participant API as kube-apiserver
    participant B as å®ä¾‹ B

    A->>API: åˆ›å»º/æ›´æ–° Lease (holderIdentity=A, renewTime=now)
    API-->>A: æˆåŠŸ â†’ A æˆä¸º Leader
    A->>A: æ‰§è¡Œæ§åˆ¶å™¨é€»è¾‘

    loop æ¯ 2 ç§’ç»­çº¦
        A->>API: æ›´æ–° Lease (renewTime=now)
    end

    Note over A: å®ä¾‹ A å´©æºƒï¼Œåœæ­¢ç»­çº¦

    B->>API: è¯»å– Leaseï¼Œå‘ç° renewTime å·²è¿‡æœŸ(>15s)
    B->>API: æ›´æ–° Lease (holderIdentity=B)
    API-->>B: æˆåŠŸï¼ˆResourceVersion ä¹è§‚é”ä¿è¯åªæœ‰ä¸€ä¸ªæˆåŠŸï¼‰
    B->>B: B æˆä¸ºæ–° Leader
```

#### Watch + Cacheï¼ˆList-Watch æ¨¡å¼ï¼‰

**é—®é¢˜**ï¼šå¦‚æœæ¯ä¸ªæ§åˆ¶å™¨éƒ½ç›´æ¥ List apiserverï¼Œapiserver å’Œ etcd ä¼šè¢«å‹å®ã€‚

**è§£å†³**ï¼šInformer çš„ List-Watch æ¨¡å¼â€”â€”é¦–æ¬¡ List å…¨é‡ï¼Œä¹‹å Watch å¢é‡ï¼Œæœ¬åœ°ç¼“å­˜ï¼ˆIndexerï¼‰æä¾›è¯»å–ã€‚

```
                    æ—  Informer                    æœ‰ Informer
Controller A â”€â”€Listâ”€â”€â–º                  Controller A â”€â”€Readâ”€â”€â–º Local Cache
Controller B â”€â”€Listâ”€â”€â–º apiserver        Controller B â”€â”€Readâ”€â”€â–º Local Cache
Controller C â”€â”€Listâ”€â”€â–º                  Controller C â”€â”€Readâ”€â”€â–º Local Cache
                    â†“                                          â†‘
              apiserver è¿‡è½½              Informer â”€â”€Watchâ”€â”€â–º apiserver
                                         (åªæœ‰ä¸€ä¸ªè¿æ¥)
```

#### Level-Triggered vs Edge-Triggered

ğŸ¯ Kubernetes é€‰æ‹© **Level-Triggeredï¼ˆç”µå¹³è§¦å‘ï¼‰** è€Œé Edge-Triggeredï¼ˆè¾¹æ²¿è§¦å‘ï¼‰ï¼š

| æ¨¡å¼ | å«ä¹‰ | ç‰¹ç‚¹ |
|------|------|------|
| Edge-Triggered | åªåœ¨çŠ¶æ€å˜åŒ–æ—¶è§¦å‘ | å¦‚æœé”™è¿‡ä¸€ä¸ªäº‹ä»¶ï¼ŒçŠ¶æ€å°±ä¸ä¸€è‡´äº† |
| Level-Triggered | åŸºäºå½“å‰çŠ¶æ€æŒç»­è§¦å‘ | å³ä½¿é”™è¿‡äº‹ä»¶ï¼Œä¸‹æ¬¡æ£€æŸ¥ä»èƒ½å‘ç°å·®å¼‚å¹¶ä¿®å¤ |

**ä¸ºä»€ä¹ˆé€‰æ‹© Level-Triggeredï¼Ÿ**
- åˆ†å¸ƒå¼ç³»ç»Ÿä¸­äº‹ä»¶å¯èƒ½ä¸¢å¤±ï¼ˆç½‘ç»œåˆ†åŒºã€Watch æ–­è¿ï¼‰
- Level-Triggered å¤©ç„¶å…·å¤‡è‡ªæ„ˆèƒ½åŠ›ï¼šæ§åˆ¶å™¨æ¯æ¬¡ Reconcile éƒ½æ¯”è¾ƒ"æœŸæœ›çŠ¶æ€ vs å®é™…çŠ¶æ€"ï¼Œè€Œéä¾èµ–"å‘ç”Ÿäº†ä»€ä¹ˆäº‹ä»¶"
- ä»£ä»·æ˜¯å¯èƒ½åšä¸€äº›ä¸å¿…è¦çš„æ£€æŸ¥ï¼Œä½†æ¢æ¥äº†æ›´å¼ºçš„é²æ£’æ€§

### 4.4 è®¾è®¡æƒè¡¡åˆ†æ

#### å£°æ˜å¼ vs å‘½ä»¤å¼

Kubernetes é€‰æ‹©å£°æ˜å¼ API çš„æ ¸å¿ƒæƒè¡¡ï¼š
- **æ”¶ç›Š**ï¼šå¹‚ç­‰æ€§ã€è‡ªæ„ˆèƒ½åŠ›ã€GitOps å‹å¥½ã€å¤šæ§åˆ¶å™¨åä½œ
- **ä»£ä»·**ï¼šå­¦ä¹ æ›²çº¿é™¡å³­ï¼ˆç”¨æˆ·éœ€è¦ç†è§£"æœŸæœ›çŠ¶æ€"æ€ç»´ï¼‰ã€è°ƒè¯•å›°éš¾ï¼ˆ"ä¸ºä»€ä¹ˆæˆ‘çš„ Pod æ²¡æœ‰æŒ‰é¢„æœŸè¿è¡Œï¼Ÿ"éœ€è¦ç†è§£æ§åˆ¶å™¨é€»è¾‘ï¼‰

#### æœ€ç»ˆä¸€è‡´æ€§ vs å¼ºä¸€è‡´æ€§

- **etcd å±‚**ï¼šå¼ºä¸€è‡´æ€§ï¼ˆRaft åè®®ä¿è¯ï¼‰
- **æ§åˆ¶å™¨å±‚**ï¼šæœ€ç»ˆä¸€è‡´æ€§ï¼ˆæ§åˆ¶å™¨å¼‚æ­¥æ”¶æ•›ï¼Œå¯èƒ½æœ‰çŸ­æš‚çš„çŠ¶æ€ä¸ä¸€è‡´çª—å£ï¼‰
- **æƒè¡¡**ï¼šå¼ºä¸€è‡´æ€§ä¿è¯æ•°æ®ä¸ä¸¢å¤±ï¼Œæœ€ç»ˆä¸€è‡´æ€§ä¿è¯ç³»ç»Ÿå¯ç”¨æ€§å’Œæ‰©å±•æ€§

#### CRD + Operator çš„æ‰©å±•å“²å­¦

- **æ”¶ç›Š**ï¼šæ— éœ€ä¿®æ”¹ K8s æ ¸å¿ƒä»£ç å³å¯æ‰©å±• APIï¼ŒOperator ç”Ÿæ€çˆ†å‘ï¼ˆOperatorHub ä¸Š 300+ Operatorï¼‰
- **ä»£ä»·**ï¼šCRD çš„åŠŸèƒ½ä¸å¦‚åŸç”Ÿ API ä¸°å¯Œï¼ˆå¦‚ç¼ºå°‘åŸç”Ÿçš„ `kubectl explain` æ”¯æŒã€å­—æ®µéªŒè¯éœ€è¦é¢å¤–é…ç½®ï¼‰
- **æ¼”è¿›æ–¹å‘**ï¼šCEL éªŒè¯è§„åˆ™ï¼ˆ1.25+ï¼‰ã€CRD Validation Ratchetingï¼ˆ1.28+ï¼‰æŒç»­ç¼©å°å·®è·

---

## ç¬¬äº”ç« ï¼šé«˜å¯é ä¸é«˜å¯ç”¨æ–¹æ¡ˆ

### 5.1 é›†ç¾¤éƒ¨ç½²æ¶æ„

#### å•èŠ‚ç‚¹å¼€å‘ç¯å¢ƒ

```bash
# Kindï¼ˆKubernetes in Dockerï¼‰â€” æ¨èçš„æœ¬åœ°å¼€å‘æ–¹æ¡ˆ
kind create cluster --name dev --config kind-config.yaml

# Minikube â€” å•èŠ‚ç‚¹è™šæ‹Ÿæœº
minikube start --cpus=4 --memory=8192 --driver=docker
```

é€‚ç”¨åœºæ™¯ï¼šæœ¬åœ°å¼€å‘ã€CI æµ‹è¯•ã€å­¦ä¹ å®éªŒã€‚ä¸é€‚ç”¨äºç”Ÿäº§ã€‚

#### ä¸‰èŠ‚ç‚¹é«˜å¯ç”¨æ§åˆ¶å¹³é¢ï¼ˆStacked etcdï¼‰

```mermaid
graph TB
    LB["è´Ÿè½½å‡è¡¡å™¨<br/>apiserver VIP:6443"]

    subgraph Master1["Master 1"]
        API1["kube-apiserver"]
        ETCD1["etcd"]
        CM1["controller-manager"]
        SCHED1["scheduler"]
    end

    subgraph Master2["Master 2"]
        API2["kube-apiserver"]
        ETCD2["etcd"]
        CM2["controller-manager<br/>(standby)"]
        SCHED2["scheduler<br/>(standby)"]
    end

    subgraph Master3["Master 3"]
        API3["kube-apiserver"]
        ETCD3["etcd"]
        CM3["controller-manager<br/>(standby)"]
        SCHED3["scheduler<br/>(standby)"]
    end

    LB --> API1
    LB --> API2
    LB --> API3
    ETCD1 <--> ETCD2
    ETCD2 <--> ETCD3
    ETCD1 <--> ETCD3

    Worker1["Worker Node 1"] --> LB
    Worker2["Worker Node 2"] --> LB
    Worker3["Worker Node N"] --> LB
```

ğŸ¯ Stacked etcd æ¨¡å¼ï¼šetcd ä¸ apiserver éƒ¨ç½²åœ¨åŒä¸€èŠ‚ç‚¹ï¼Œè¿ç»´ç®€å•ä½†è€¦åˆåº¦é«˜ã€‚

#### å¤–ç½® etcd é›†ç¾¤æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              etcd é›†ç¾¤ï¼ˆç‹¬ç«‹éƒ¨ç½²ï¼‰              â”‚
â”‚  etcd-1 â—„â”€â”€â–º etcd-2 â—„â”€â”€â–º etcd-3            â”‚
â”‚  (ç‹¬ç«‹ç¡¬ä»¶ï¼ŒSSD ç£ç›˜ï¼Œä½å»¶è¿Ÿç½‘ç»œ)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ gRPC
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           æ§åˆ¶å¹³é¢èŠ‚ç‚¹                         â”‚
â”‚  Master-1: apiserver + CM + scheduler       â”‚
â”‚  Master-2: apiserver + CM(standby)          â”‚
â”‚  Master-3: apiserver + scheduler(standby)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

ğŸ’¡ å¤–ç½® etcd çš„ä¼˜åŠ¿ï¼š
- etcd å’Œæ§åˆ¶å¹³é¢å¯ä»¥ç‹¬ç«‹æ‰©å±•å’Œç»´æŠ¤
- etcd èŠ‚ç‚¹å¯ä»¥ä½¿ç”¨ä¸“ç”¨ SSD å’Œç½‘ç»œ
- æ¨èç”¨äº 500+ èŠ‚ç‚¹çš„å¤§è§„æ¨¡é›†ç¾¤

#### éƒ¨ç½²æ¨¡å¼å¯¹æ¯”

| ç»´åº¦ | å•èŠ‚ç‚¹ | Stacked HA | å¤–ç½® etcd HA |
|------|--------|-----------|-------------|
| èŠ‚ç‚¹æ•° | 1 | 3+ Master | 3+ Master + 3+ etcd |
| å®¹é”™èƒ½åŠ› | æ—  | å®¹å¿ 1 Master æ•…éšœ | æ§åˆ¶å¹³é¢å’Œ etcd ç‹¬ç«‹å®¹é”™ |
| è¿ç»´å¤æ‚åº¦ | ä½ | ä¸­ | é«˜ |
| é€‚ç”¨è§„æ¨¡ | å¼€å‘æµ‹è¯• | ä¸­å°è§„æ¨¡ç”Ÿäº§ | å¤§è§„æ¨¡ç”Ÿäº§ |
| æˆæœ¬ | æœ€ä½ | ä¸­ | é«˜ |

### 5.2 æ•°æ®ä¸€è‡´æ€§ä¿è¯

#### etcd çš„ Raft å¼ºä¸€è‡´æ€§

- æ‰€æœ‰å†™æ“ä½œå¿…é¡»ç»è¿‡ Leaderï¼Œå¹¶å¤åˆ¶åˆ°å¤šæ•°èŠ‚ç‚¹åæ‰ç¡®è®¤
- è¯»æ“ä½œé»˜è®¤ Serializableï¼ˆå¯èƒ½è¯»åˆ°æ—§æ•°æ®ï¼‰ï¼Œå¯è®¾ç½® Linearizable ä¿è¯å¼ºä¸€è‡´è¯»
- K8s apiserver é»˜è®¤ä½¿ç”¨ Serializable è¯»ï¼ˆæ€§èƒ½ä¼˜å…ˆï¼‰ï¼Œå…³é”®æ“ä½œä½¿ç”¨ Quorum è¯»

#### apiserver ç¼“å­˜çš„æœ€ç»ˆä¸€è‡´æ€§

```
å†™è¯·æ±‚è·¯å¾„ï¼ˆå¼ºä¸€è‡´ï¼‰ï¼š
Client â†’ apiserver â†’ etcd (Raft Quorum Write) â†’ ç¡®è®¤

è¯»è¯·æ±‚è·¯å¾„ï¼ˆæœ€ç»ˆä¸€è‡´ï¼‰ï¼š
Client â†’ apiserver â†’ Watch Cache (å†…å­˜) â†’ è¿”å›
                     â†‘
                     etcd Watch äº‹ä»¶å¼‚æ­¥æ›´æ–°
```

âš ï¸ Watch Cache å¯èƒ½æœ‰æ¯«ç§’çº§å»¶è¿Ÿã€‚å¦‚æœéœ€è¦è¯»å–æœ€æ–°æ•°æ®ï¼Œä½¿ç”¨ `resourceVersion=""` å¼ºåˆ¶ä» etcd è¯»å–ï¼ˆä½†ä¼šå¢åŠ  etcd è´Ÿè½½ï¼‰ã€‚

#### ResourceVersion ä¹è§‚é”

```yaml
# æ›´æ–°æ—¶æºå¸¦ resourceVersionï¼Œé˜²æ­¢å¹¶å‘å†²çª
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-config
  resourceVersion: "12345"  # å¿…é¡»ä¸æœåŠ¡ç«¯ä¸€è‡´ï¼Œå¦åˆ™è¿”å› 409 Conflict
data:
  key: new-value
```

### 5.3 æ•…éšœæ£€æµ‹ä¸æ¢å¤

#### Node æ•…éšœæ£€æµ‹

```
kubelet                    kube-apiserver              node-controller
  â”‚                            â”‚                           â”‚
  â”‚â”€â”€ æ›´æ–° Lease (æ¯10s) â”€â”€â–º   â”‚                           â”‚
  â”‚â”€â”€ æ›´æ–° NodeStatus (æ¯10s)â”€â–ºâ”‚                           â”‚
  â”‚                            â”‚                           â”‚
  â”‚   (kubelet åœæ­¢å¿ƒè·³)       â”‚                           â”‚
  â”‚                            â”‚   (Lease è¿‡æœŸ)            â”‚
  â”‚                            â”‚â—„â”€â”€ æ£€æµ‹åˆ° Lease è¿‡æœŸ â”€â”€â”€â”€â”€â”‚
  â”‚                            â”‚                           â”‚
  â”‚                            â”‚   ç­‰å¾… node-monitor-      â”‚
  â”‚                            â”‚   grace-period (40s)      â”‚
  â”‚                            â”‚                           â”‚
  â”‚                            â”‚â—„â”€â”€ æ ‡è®° Node NotReady â”€â”€â”€â”€â”‚
  â”‚                            â”‚                           â”‚
  â”‚                            â”‚   ç­‰å¾… pod-eviction-      â”‚
  â”‚                            â”‚   timeout (5min)          â”‚
  â”‚                            â”‚                           â”‚
  â”‚                            â”‚â—„â”€â”€ é©±é€ Node ä¸Šçš„ Pod â”€â”€â”€â”€â”‚
```

å…³é”®è¶…æ—¶å‚æ•°ï¼š

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--node-monitor-period` | 5s | node-controller æ£€æŸ¥ Node çŠ¶æ€çš„é—´éš” |
| `--node-monitor-grace-period` | 40s | æ ‡è®° Node NotReady å‰çš„ç­‰å¾…æ—¶é—´ |
| `--pod-eviction-timeout` | 5m | Node NotReady åå¼€å§‹é©±é€ Pod çš„ç­‰å¾…æ—¶é—´ |
| kubelet `--node-status-update-frequency` | 10s | kubelet ä¸ŠæŠ¥ NodeStatus çš„é—´éš” |
| kubelet Lease ç»­çº¦é—´éš” | 10s | kubelet æ›´æ–° Lease å¯¹è±¡çš„é—´éš” |

#### Pod å¥åº·æ£€æŸ¥

```yaml
apiVersion: v1
kind: Pod
spec:
  containers:
  - name: app
    image: my-app:v1
    # å­˜æ´»æ¢é’ˆï¼šå¤±è´¥åˆ™é‡å¯å®¹å™¨
    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
      initialDelaySeconds: 15  # é¦–æ¬¡æ£€æŸ¥å»¶è¿Ÿ
      periodSeconds: 10        # æ£€æŸ¥é—´éš”
      failureThreshold: 3      # è¿ç»­å¤±è´¥æ¬¡æ•°åé‡å¯
      timeoutSeconds: 3        # å•æ¬¡è¶…æ—¶

    # å°±ç»ªæ¢é’ˆï¼šå¤±è´¥åˆ™ä» Service Endpoint ç§»é™¤
    readinessProbe:
      httpGet:
        path: /ready
        port: 8080
      periodSeconds: 5
      failureThreshold: 3

    # å¯åŠ¨æ¢é’ˆï¼ˆ1.20 GAï¼‰ï¼šå¯åŠ¨æœŸé—´æ›¿ä»£ liveness æ£€æŸ¥
    startupProbe:
      httpGet:
        path: /healthz
        port: 8080
      failureThreshold: 30     # 30 Ã— 10s = æœ€å¤šç­‰å¾… 5 åˆ†é’Ÿå¯åŠ¨
      periodSeconds: 10
```

ğŸ¯ ä¸‰ç§æ¢é’ˆçš„å…³ç³»ï¼š
- **startupProbe**ï¼šå¯åŠ¨é˜¶æ®µä½¿ç”¨ï¼ŒæˆåŠŸåä¸å†æ‰§è¡Œï¼Œäº¤ç»™ liveness/readiness
- **livenessProbe**ï¼šè¿è¡Œé˜¶æ®µæ£€æµ‹å®¹å™¨æ˜¯å¦å­˜æ´»ï¼Œå¤±è´¥åˆ™é‡å¯
- **readinessProbe**ï¼šè¿è¡Œé˜¶æ®µæ£€æµ‹å®¹å™¨æ˜¯å¦å°±ç»ªæ¥æ”¶æµé‡ï¼Œå¤±è´¥åˆ™ä» Endpoint ç§»é™¤

#### æ§åˆ¶å¹³é¢æ•…éšœæ¢å¤

```bash
# etcd å¤‡ä»½
ETCDCTL_API=3 etcdctl snapshot save /backup/etcd-snapshot.db \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/kubernetes/pki/etcd/ca.crt \
  --cert=/etc/kubernetes/pki/etcd/server.crt \
  --key=/etc/kubernetes/pki/etcd/server.key

# etcd æ¢å¤
ETCDCTL_API=3 etcdctl snapshot restore /backup/etcd-snapshot.db \
  --data-dir=/var/lib/etcd-restored \
  --name=etcd-0 \
  --initial-cluster=etcd-0=https://10.0.0.1:2380 \
  --initial-advertise-peer-urls=https://10.0.0.1:2380
```

### 5.4 å®¹ç¾ç­–ç•¥

#### Pod æ‹“æ‰‘åˆ†å¸ƒçº¦æŸ

```yaml
apiVersion: apps/v1
kind: Deployment
spec:
  replicas: 6
  template:
    spec:
      topologySpreadConstraints:
      - maxSkew: 1                          # æœ€å¤§ä¸å‡è¡¡åº¦
        topologyKey: topology.kubernetes.io/zone  # æŒ‰å¯ç”¨åŒºåˆ†å¸ƒ
        whenUnsatisfiable: DoNotSchedule    # ä¸æ»¡è¶³åˆ™ä¸è°ƒåº¦
        labelSelector:
          matchLabels:
            app: web
      - maxSkew: 1
        topologyKey: kubernetes.io/hostname  # æŒ‰èŠ‚ç‚¹åˆ†å¸ƒ
        whenUnsatisfiable: ScheduleAnyway   # å°½é‡æ»¡è¶³ï¼Œä¸å¼ºåˆ¶
        labelSelector:
          matchLabels:
            app: web
```

#### Velero å¤‡ä»½ä¸ç¾éš¾æ¢å¤

```bash
# å®‰è£… Velero
velero install --provider aws --bucket my-backup-bucket \
  --secret-file ./credentials-velero

# åˆ›å»ºå¤‡ä»½
velero backup create full-backup --include-namespaces default,production

# å®šæ—¶å¤‡ä»½
velero schedule create daily-backup --schedule="0 2 * * *" \
  --include-namespaces production --ttl 720h

# ç¾éš¾æ¢å¤
velero restore create --from-backup full-backup
```

### 5.5 æ€§èƒ½ä¼˜åŒ–ï¼ˆ30+ è°ƒä¼˜å‚æ•°ï¼‰

#### kube-apiserver è°ƒä¼˜

| å‚æ•° | é»˜è®¤å€¼ | æ¨èå€¼ï¼ˆå¤§è§„æ¨¡ï¼‰ | è¯´æ˜ |
|------|--------|----------------|------|
| `--max-requests-inflight` | 400 | 800~1600 | é mutating è¯·æ±‚å¹¶å‘ä¸Šé™ |
| `--max-mutating-requests-inflight` | 200 | 400~800 | mutating è¯·æ±‚å¹¶å‘ä¸Šé™ |
| `--watch-cache-sizes` | è‡ªåŠ¨ | æŒ‰èµ„æºè°ƒæ•´ | Watch Cache å¤§å°ï¼ˆå¦‚ pods#1000ï¼‰ |
| `--default-watch-cache-size` | 100 | 500~1000 | é»˜è®¤ Watch Cache å¤§å° |
| `--etcd-compaction-interval` | 5m | 5m | etcd å‹ç¼©é—´éš” |
| `--audit-log-maxage` | 0 | 30 | å®¡è®¡æ—¥å¿—ä¿ç•™å¤©æ•° |
| `--audit-log-maxsize` | 0 | 100 | å®¡è®¡æ—¥å¿—å•æ–‡ä»¶æœ€å¤§ MB |
| `--enable-priority-and-fairness` | true | true | API ä¼˜å…ˆçº§å’Œå…¬å¹³æ€§ï¼ˆAPFï¼‰ |

#### etcd è°ƒä¼˜

| å‚æ•° | é»˜è®¤å€¼ | æ¨èå€¼ | è¯´æ˜ |
|------|--------|--------|------|
| `--quota-backend-bytes` | 2GB | 8GB | å­˜å‚¨é…é¢ï¼ˆæœ€å¤§ 8GBï¼‰ |
| `--snapshot-count` | 10000 | 10000 | è§¦å‘å¿«ç…§çš„æ—¥å¿—æ¡æ•° |
| `--heartbeat-interval` | 100ms | 100ms | Leader å¿ƒè·³é—´éš” |
| `--election-timeout` | 1000ms | 1000ms | é€‰ä¸¾è¶…æ—¶ï¼ˆåº”ä¸ºå¿ƒè·³çš„ 10 å€ï¼‰ |
| `--auto-compaction-mode` | periodic | periodic | è‡ªåŠ¨å‹ç¼©æ¨¡å¼ |
| `--auto-compaction-retention` | 0 | 1h | è‡ªåŠ¨å‹ç¼©ä¿ç•™æ—¶é—´ |
| ç£ç›˜ç±»å‹ | â€” | NVMe SSD | etcd å¯¹ç£ç›˜ IOPS æå…¶æ•æ„Ÿ |
| ç½‘ç»œå»¶è¿Ÿ | â€” | < 10ms | etcd èŠ‚ç‚¹é—´å»¶è¿Ÿåº” < 10ms |

âš ï¸ etcd æ€§èƒ½é»„é‡‘æ³•åˆ™ï¼š**SSD ç£ç›˜ + ä½å»¶è¿Ÿç½‘ç»œ + åˆç†çš„ quota-backend-bytes**ã€‚etcd æ€§èƒ½åŠ£åŒ–æ˜¯å¤§è§„æ¨¡é›†ç¾¤æœ€å¸¸è§çš„ç“¶é¢ˆã€‚

#### kubelet è°ƒä¼˜

| å‚æ•° | é»˜è®¤å€¼ | æ¨èå€¼ | è¯´æ˜ |
|------|--------|--------|------|
| `--max-pods` | 110 | 110~250 | å•èŠ‚ç‚¹æœ€å¤§ Pod æ•° |
| `--kube-api-qps` | 50 | 100 | kubelet è®¿é—® apiserver çš„ QPS |
| `--kube-api-burst` | 100 | 200 | kubelet è®¿é—® apiserver çš„ Burst |
| `--serialize-image-pulls` | true | false | å¹¶è¡Œæ‹‰å–é•œåƒï¼ˆéœ€ containerd æ”¯æŒï¼‰ |
| `--image-gc-high-threshold` | 85% | 85% | é•œåƒ GC é«˜æ°´ä½ |
| `--image-gc-low-threshold` | 80% | 80% | é•œåƒ GC ä½æ°´ä½ |
| `--eviction-hard` | è§ä¸‹æ–¹ | æŒ‰éœ€è°ƒæ•´ | ç¡¬é©±é€é˜ˆå€¼ |
| `--system-reserved` | â€” | cpu=500m,memory=1Gi | ç³»ç»Ÿé¢„ç•™èµ„æº |
| `--kube-reserved` | â€” | cpu=500m,memory=1Gi | K8s ç»„ä»¶é¢„ç•™èµ„æº |

é©±é€é˜ˆå€¼é…ç½®ï¼š
```yaml
# KubeletConfiguration
evictionHard:
  memory.available: "500Mi"
  nodefs.available: "10%"
  imagefs.available: "15%"
  nodefs.inodesFree: "5%"
evictionSoft:
  memory.available: "1Gi"
evictionSoftGracePeriod:
  memory.available: "1m30s"
```

#### kube-scheduler è°ƒä¼˜

| å‚æ•° | é»˜è®¤å€¼ | æ¨èå€¼ | è¯´æ˜ |
|------|--------|--------|------|
| `--percentageOfNodesToScore` | è‡ªåŠ¨ | æŒ‰è§„æ¨¡è°ƒæ•´ | Score é˜¶æ®µè¯„ä¼°çš„èŠ‚ç‚¹æ¯”ä¾‹ |
| `--kube-api-qps` | 50 | 100 | è®¿é—® apiserver çš„ QPS |
| `--kube-api-burst` | 100 | 200 | è®¿é—® apiserver çš„ Burst |
| å¹¶è¡Œåº¦ | 16 | 16~64 | è°ƒåº¦å™¨å¹¶è¡Œå¤„ç†çš„ Pod æ•° |

#### kube-proxy è°ƒä¼˜

| å‚æ•° | é»˜è®¤å€¼ | æ¨èå€¼ | è¯´æ˜ |
|------|--------|--------|------|
| `--proxy-mode` | iptables | ipvs | å¤§è§„æ¨¡é›†ç¾¤ä½¿ç”¨ IPVS |
| `--ipvs-scheduler` | rr | rr/lc | IPVS è´Ÿè½½å‡è¡¡ç®—æ³• |
| `--ipvs-min-sync-period` | 0s | 1s | IPVS è§„åˆ™æœ€å°åŒæ­¥é—´éš” |
| `--conntrack-max-per-core` | 32768 | 65536 | æ¯æ ¸å¿ƒ conntrack è¡¨å¤§å° |

#### é›†ç¾¤çº§è°ƒä¼˜

```yaml
# API Priority and Fairness (APF) â€” é˜²æ­¢å•ä¸ªå®¢æˆ·ç«¯è€—å°½ apiserver èµ„æº
apiVersion: flowcontrol.apiserver.k8s.io/v1
kind: FlowSchema
metadata:
  name: high-priority-system
spec:
  priorityLevelConfiguration:
    name: workload-high
  matchingPrecedence: 100
  rules:
  - subjects:
    - kind: ServiceAccount
      serviceAccount:
        name: critical-controller
        namespace: kube-system
    resourceRules:
    - verbs: ["*"]
      apiGroups: ["*"]
      resources: ["*"]
```

### 5.6 å¯è§‚æµ‹æ€§

#### å…³é”® Prometheus æŒ‡æ ‡

| ç»„ä»¶ | æŒ‡æ ‡ | å«ä¹‰ | å‘Šè­¦é˜ˆå€¼å»ºè®® |
|------|------|------|------------|
| apiserver | `apiserver_request_duration_seconds` | API è¯·æ±‚å»¶è¿Ÿ | P99 > 1s |
| apiserver | `apiserver_request_total` | API è¯·æ±‚æ€»æ•°ï¼ˆæŒ‰çŠ¶æ€ç ï¼‰ | 5xx ç‡ > 1% |
| apiserver | `apiserver_current_inflight_requests` | å½“å‰å¹¶å‘è¯·æ±‚æ•° | > 80% max |
| etcd | `etcd_disk_wal_fsync_duration_seconds` | WAL å†™å…¥å»¶è¿Ÿ | P99 > 10ms |
| etcd | `etcd_server_proposals_failed_total` | å¤±è´¥çš„ Raft ææ¡ˆæ•° | æŒç»­å¢é•¿ |
| etcd | `etcd_mvcc_db_total_size_in_bytes` | æ•°æ®åº“å¤§å° | > 6GB (quota 8GB) |
| kubelet | `kubelet_pod_start_duration_seconds` | Pod å¯åŠ¨å»¶è¿Ÿ | P99 > 30s |
| kubelet | `kubelet_running_pods` | è¿è¡Œä¸­çš„ Pod æ•° | æ¥è¿‘ max-pods |
| scheduler | `scheduler_scheduling_attempt_duration_seconds` | è°ƒåº¦å»¶è¿Ÿ | P99 > 1s |
| scheduler | `scheduler_pending_pods` | å¾…è°ƒåº¦ Pod æ•° | æŒç»­å¢é•¿ |

#### å¥åº·æ£€æŸ¥ç«¯ç‚¹

```bash
# apiserver å¥åº·æ£€æŸ¥
curl -k https://localhost:6443/healthz    # ç»¼åˆå¥åº·çŠ¶æ€
curl -k https://localhost:6443/livez      # å­˜æ´»æ£€æŸ¥
curl -k https://localhost:6443/readyz     # å°±ç»ªæ£€æŸ¥
curl -k https://localhost:6443/readyz?verbose  # è¯¦ç»†å°±ç»ªçŠ¶æ€

# etcd å¥åº·æ£€æŸ¥
etcdctl endpoint health --endpoints=https://127.0.0.1:2379

# kubelet å¥åº·æ£€æŸ¥
curl http://localhost:10248/healthz
```

#### å®¡è®¡æ—¥å¿—é…ç½®

```yaml
# audit-policy.yaml
apiVersion: audit.k8s.io/v1
kind: Policy
rules:
# ä¸è®°å½•å¥åº·æ£€æŸ¥
- level: None
  nonResourceURLs: ["/healthz*", "/livez*", "/readyz*"]

# è®°å½• Secret çš„å…ƒæ•°æ®ï¼ˆä¸è®°å½•å†…å®¹ï¼‰
- level: Metadata
  resources:
  - group: ""
    resources: ["secrets"]

# è®°å½•æ‰€æœ‰å†™æ“ä½œçš„è¯·æ±‚ä½“
- level: Request
  verbs: ["create", "update", "patch", "delete"]
  resources:
  - group: ""
    resources: ["pods", "services", "configmaps"]

# å…¶ä»–è®°å½•å…ƒæ•°æ®
- level: Metadata
  omitStages: ["RequestReceived"]
```

---

## ç¬¬å…­ç« ï¼šå®æˆ˜æŒ‡å—ä¸é—®é¢˜æ’æŸ¥

### 6.1 æœ€ä½³å®è·µ

#### èµ„æºè¯·æ±‚ä¸é™åˆ¶

```yaml
# æ¨èé…ç½®æ¨¡å¼
resources:
  requests:          # è°ƒåº¦ä¾æ®ï¼Œä¿è¯æœ€ä½èµ„æº
    cpu: 100m        # 0.1 æ ¸
    memory: 128Mi
  limits:            # ç¡¬ä¸Šé™ï¼Œè¶…å‡ºåˆ™ OOMKilled/CPU é™æµ
    cpu: 500m        # å»ºè®® limits/requests æ¯”ä¾‹ 2~5 å€
    memory: 256Mi    # memory limits å»ºè®® = requests æˆ–ç•¥é«˜
```

âš ï¸ å…³é”®åŸåˆ™ï¼š
- **å¿…é¡»è®¾ç½® requests**ï¼šå¦åˆ™ Pod ä¼šè¢«è§†ä¸º BestEffortï¼Œèµ„æºç´§å¼ æ—¶æœ€å…ˆè¢«é©±é€
- **memory limits ä¸å®œè¿‡é«˜**ï¼šè¶…å‡º limits ä¼šè¢« OOMKilledï¼Œä½† CPU åªä¼šè¢«é™æµ
- **é¿å… limits = requests**ï¼šè¿™æ˜¯ Guaranteed QoSï¼Œèµ„æºåˆ©ç”¨ç‡ä½ï¼›å»ºè®® Burstable QoS

#### RBAC æƒé™æœ€å°åŒ–

```yaml
# æœ€å°æƒé™ Role ç¤ºä¾‹ï¼šåªå…è®¸è¯»å–ç‰¹å®š namespace çš„ Pod
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: production
  name: pod-reader
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]  # åªè¯»ï¼Œä¸å« create/delete
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  namespace: production
  name: read-pods
subjects:
- kind: ServiceAccount
  name: monitoring-sa
  namespace: production
roleRef:
  kind: Role
  name: pod-reader
  apiGroup: rbac.authorization.k8s.io
```

#### Pod å®‰å…¨æ ‡å‡†

```yaml
# åœ¨ Namespace çº§åˆ«å¯ç”¨ Pod Security Standards
apiVersion: v1
kind: Namespace
metadata:
  name: production
  labels:
    pod-security.kubernetes.io/enforce: restricted    # å¼ºåˆ¶æ‰§è¡Œ
    pod-security.kubernetes.io/audit: restricted      # å®¡è®¡è®°å½•
    pod-security.kubernetes.io/warn: restricted       # è­¦å‘Šæç¤º
```

### 6.2 æ€§èƒ½å‹æµ‹

#### æ¨èå·¥å…·

| å·¥å…· | ç”¨é€” | ç‰¹ç‚¹ |
|------|------|------|
| kube-burner | é›†ç¾¤å‹åŠ›æµ‹è¯• | æ¨¡æ‹Ÿå¤§é‡èµ„æºåˆ›å»º/åˆ é™¤ï¼Œæµ‹é‡ API å»¶è¿Ÿ |
| ClusterLoader2 | K8s å®˜æ–¹å‹æµ‹å·¥å…· | SIG-Scalability ä½¿ç”¨ï¼Œæœ€æƒå¨ |
| k6 | HTTP è´Ÿè½½æµ‹è¯• | æµ‹è¯• Service/Ingress å±‚é¢çš„æ€§èƒ½ |
| kwok | æ¨¡æ‹Ÿå¤§è§„æ¨¡é›†ç¾¤ | æ— éœ€çœŸå®èŠ‚ç‚¹ï¼Œæ¨¡æ‹Ÿæ•°åƒèŠ‚ç‚¹ |

#### å…¸å‹åŸºå‡†å€¼

| æŒ‡æ ‡ | å°è§„æ¨¡ (<100 èŠ‚ç‚¹) | å¤§è§„æ¨¡ (1000+ èŠ‚ç‚¹) |
|------|-------------------|-------------------|
| API è¯·æ±‚å»¶è¿Ÿ (P99) | < 200ms | < 1s |
| Pod å¯åŠ¨å»¶è¿Ÿ (P99) | < 5s | < 15s |
| è°ƒåº¦å»¶è¿Ÿ (P99) | < 100ms | < 500ms |
| Watch äº‹ä»¶å»¶è¿Ÿ | < 100ms | < 500ms |

### 6.3 å¸¸è§æ•…éšœæ¨¡å¼

#### æ•…éšœ 1ï¼šPod ä¸€ç›´ Pending

**ç°è±¡**ï¼šPod çŠ¶æ€æŒç»­ä¸º Pendingï¼Œä¸è¢«è°ƒåº¦åˆ°ä»»ä½•èŠ‚ç‚¹ã€‚

**æ’æŸ¥å‘½ä»¤**ï¼š
```bash
# æŸ¥çœ‹ Pod äº‹ä»¶
kubectl describe pod <pod-name> -n <namespace>

# æŸ¥çœ‹è°ƒåº¦å™¨æ—¥å¿—
kubectl logs -n kube-system -l component=kube-scheduler --tail=100

# æŸ¥çœ‹èŠ‚ç‚¹èµ„æºä½¿ç”¨æƒ…å†µ
kubectl top nodes
kubectl describe nodes | grep -A 5 "Allocated resources"
```

**å¸¸è§æ ¹å› ä¸è§£å†³æ–¹æ¡ˆ**ï¼š

| æ ¹å›  | Events ä¸­çš„æç¤º | è§£å†³æ–¹æ¡ˆ |
|------|----------------|---------|
| èµ„æºä¸è¶³ | `Insufficient cpu/memory` | æ‰©å®¹èŠ‚ç‚¹æˆ–è°ƒæ•´ requests |
| èŠ‚ç‚¹äº²å’Œæ€§ä¸åŒ¹é… | `didn't match Pod's node affinity/selector` | æ£€æŸ¥ nodeSelector/nodeAffinity |
| Taint æœªå®¹å¿ | `had taint {key=value:NoSchedule}` | æ·»åŠ å¯¹åº” toleration |
| PVC æœªç»‘å®š | `persistentvolumeclaim is not bound` | æ£€æŸ¥ PV/StorageClass |
| è°ƒåº¦å™¨æœªè¿è¡Œ | æ— äº‹ä»¶ | æ£€æŸ¥ kube-scheduler çŠ¶æ€ |

**é¢„é˜²æªæ–½**ï¼šé…ç½® Cluster Autoscaler è‡ªåŠ¨æ‰©å®¹ï¼›è®¾ç½® PodDisruptionBudget é˜²æ­¢è¿‡åº¦é©±é€ã€‚

#### æ•…éšœ 2ï¼šPod CrashLoopBackOff

**ç°è±¡**ï¼šPod åå¤é‡å¯ï¼ŒçŠ¶æ€åœ¨ Running å’Œ CrashLoopBackOff ä¹‹é—´åˆ‡æ¢ã€‚

**æ’æŸ¥å‘½ä»¤**ï¼š
```bash
# æŸ¥çœ‹å®¹å™¨æ—¥å¿—ï¼ˆå½“å‰å’Œä¸Šä¸€æ¬¡ï¼‰
kubectl logs <pod-name> -c <container-name>
kubectl logs <pod-name> -c <container-name> --previous

# æŸ¥çœ‹ Pod è¯¦æƒ…
kubectl describe pod <pod-name>

# è¿›å…¥å®¹å™¨è°ƒè¯•ï¼ˆå¦‚æœå®¹å™¨èƒ½å¯åŠ¨ï¼‰
kubectl exec -it <pod-name> -- /bin/sh

# ä½¿ç”¨ ephemeral container è°ƒè¯•ï¼ˆå®¹å™¨æ— æ³•å¯åŠ¨æ—¶ï¼‰
kubectl debug <pod-name> -it --image=busybox
```

**å¸¸è§æ ¹å› **ï¼šåº”ç”¨å¯åŠ¨å¤±è´¥ï¼ˆé…ç½®é”™è¯¯ã€ä¾èµ–æœåŠ¡ä¸å¯ç”¨ï¼‰ã€OOMKilledã€liveness æ¢é’ˆé…ç½®ä¸å½“ã€‚

#### æ•…éšœ 3ï¼šImagePullBackOff

**ç°è±¡**ï¼šPod äº‹ä»¶æ˜¾ç¤º `Failed to pull image`ã€‚

**æ’æŸ¥å‘½ä»¤**ï¼š
```bash
kubectl describe pod <pod-name> | grep -A 10 Events

# éªŒè¯é•œåƒæ˜¯å¦å­˜åœ¨
docker pull <image-name>

# æ£€æŸ¥ imagePullSecrets
kubectl get pod <pod-name> -o jsonpath='{.spec.imagePullSecrets}'
kubectl get secret <secret-name> -o jsonpath='{.data.\.dockerconfigjson}' | base64 -d
```

**å¸¸è§æ ¹å› **ï¼šé•œåƒå/æ ‡ç­¾é”™è¯¯ã€ç§æœ‰ä»“åº“è®¤è¯å¤±è´¥ã€ç½‘ç»œä¸é€šã€ä»“åº“é™æµï¼ˆDocker Hub rate limitï¼‰ã€‚

#### æ•…éšœ 4ï¼šNode NotReady

**ç°è±¡**ï¼š`kubectl get nodes` æ˜¾ç¤ºèŠ‚ç‚¹çŠ¶æ€ä¸º NotReadyã€‚

**æ’æŸ¥å‘½ä»¤**ï¼š
```bash
# æŸ¥çœ‹èŠ‚ç‚¹çŠ¶æ€è¯¦æƒ…
kubectl describe node <node-name> | grep -A 20 Conditions

# æ£€æŸ¥ kubelet çŠ¶æ€
systemctl status kubelet
journalctl -u kubelet --since "10 minutes ago" --no-pager

# æ£€æŸ¥å®¹å™¨è¿è¡Œæ—¶
systemctl status containerd
crictl ps
```

**å¸¸è§æ ¹å› **ï¼škubelet å´©æºƒã€å®¹å™¨è¿è¡Œæ—¶æ•…éšœã€ç£ç›˜ç©ºé—´ä¸è¶³ã€å†…å­˜è€—å°½ã€ç½‘ç»œä¸é€šã€‚

#### æ•…éšœ 5ï¼šService æ— æ³•è®¿é—®åç«¯ Pod

**æ’æŸ¥å‘½ä»¤**ï¼š
```bash
# æ£€æŸ¥ Service å’Œ Endpoints
kubectl get svc <svc-name>
kubectl get endpoints <svc-name>

# æ£€æŸ¥ Pod æ ‡ç­¾æ˜¯å¦åŒ¹é… Service selector
kubectl get pods -l <selector-key>=<selector-value>

# æµ‹è¯• DNS è§£æ
kubectl run test-dns --image=busybox --rm -it -- nslookup <svc-name>

# æ£€æŸ¥ kube-proxy è§„åˆ™
iptables -t nat -L KUBE-SERVICES | grep <svc-cluster-ip>
# æˆ– IPVS æ¨¡å¼
ipvsadm -Ln | grep <svc-cluster-ip>
```

**å¸¸è§æ ¹å› **ï¼šSelector ä¸åŒ¹é…ã€Pod æœªå°±ç»ªï¼ˆreadinessProbe å¤±è´¥ï¼‰ã€NetworkPolicy é˜»æ–­ã€kube-proxy å¼‚å¸¸ã€‚

#### æ•…éšœ 6ï¼šPVC Pending

**æ’æŸ¥å‘½ä»¤**ï¼š
```bash
kubectl describe pvc <pvc-name>
kubectl get sc  # æ£€æŸ¥ StorageClass
kubectl get pv  # æ£€æŸ¥å¯ç”¨ PV
```

**å¸¸è§æ ¹å› **ï¼šæ— åŒ¹é…çš„ PVã€StorageClass ä¸å­˜åœ¨ã€CSI é©±åŠ¨æœªå®‰è£…ã€å­˜å‚¨åç«¯å®¹é‡ä¸è¶³ã€‚

#### æ•…éšœ 7ï¼šDNS è§£æå¤±è´¥

**æ’æŸ¥å‘½ä»¤**ï¼š
```bash
# æ£€æŸ¥ CoreDNS çŠ¶æ€
kubectl get pods -n kube-system -l k8s-app=kube-dns
kubectl logs -n kube-system -l k8s-app=kube-dns

# ä» Pod å†…æµ‹è¯• DNS
kubectl exec -it <pod-name> -- nslookup kubernetes.default
kubectl exec -it <pod-name> -- cat /etc/resolv.conf
```

**å¸¸è§æ ¹å› **ï¼šCoreDNS Pod å¼‚å¸¸ã€resolv.conf é…ç½®é”™è¯¯ã€NetworkPolicy é˜»æ–­ DNS æµé‡ï¼ˆUDP 53ï¼‰ã€‚

#### æ•…éšœ 8ï¼šOOMKilled

**æ’æŸ¥å‘½ä»¤**ï¼š
```bash
kubectl describe pod <pod-name> | grep -A 5 "Last State"
# æŸ¥çœ‹ Reason: OOMKilled

# æŸ¥çœ‹èŠ‚ç‚¹å†…å­˜ä½¿ç”¨
kubectl top pod <pod-name>
kubectl top node <node-name>

# æŸ¥çœ‹ cgroup å†…å­˜é™åˆ¶
kubectl exec <pod-name> -- cat /sys/fs/cgroup/memory/memory.limit_in_bytes
```

**è§£å†³æ–¹æ¡ˆ**ï¼šå¢åŠ  memory limitsã€ä¼˜åŒ–åº”ç”¨å†…å­˜ä½¿ç”¨ã€æ’æŸ¥å†…å­˜æ³„æ¼ã€‚

#### æ•…éšœ 9ï¼šEvicted Pod

**æ’æŸ¥å‘½ä»¤**ï¼š
```bash
# æŸ¥çœ‹è¢«é©±é€çš„ Pod
kubectl get pods --field-selector=status.phase=Failed | grep Evicted

# æŸ¥çœ‹èŠ‚ç‚¹å‹åŠ›çŠ¶å†µ
kubectl describe node <node-name> | grep -A 5 Conditions
# å…³æ³¨ MemoryPressureã€DiskPressureã€PIDPressure
```

**å¸¸è§æ ¹å› **ï¼šèŠ‚ç‚¹å†…å­˜/ç£ç›˜å‹åŠ›è§¦å‘ kubelet é©±é€ã€‚BestEffort QoS çš„ Pod æœ€å…ˆè¢«é©±é€ã€‚

#### æ•…éšœ 10ï¼šRBAC æƒé™ä¸è¶³ï¼ˆ403 Forbiddenï¼‰

**æ’æŸ¥å‘½ä»¤**ï¼š
```bash
# æ£€æŸ¥å½“å‰ç”¨æˆ·/SA çš„æƒé™
kubectl auth can-i create pods --namespace production
kubectl auth can-i --list --namespace production

# æ£€æŸ¥ SA ç»‘å®šçš„ Role
kubectl get rolebindings,clusterrolebindings -o wide | grep <sa-name>
```

#### æ•…éšœ 11ï¼šetcd æ€§èƒ½åŠ£åŒ–å¯¼è‡´ apiserver è¶…æ—¶

**æ’æŸ¥å‘½ä»¤**ï¼š
```bash
# æ£€æŸ¥ etcd æŒ‡æ ‡
etcdctl endpoint status --write-out=table
etcdctl endpoint health

# æ£€æŸ¥ç£ç›˜å»¶è¿Ÿ
etcdctl check perf

# æŸ¥çœ‹ apiserver æ—¥å¿—ä¸­çš„ etcd è¶…æ—¶
kubectl logs -n kube-system kube-apiserver-<node> | grep "etcd"
```

**è§£å†³æ–¹æ¡ˆ**ï¼šè¿ç§»åˆ° SSDã€æ‰§è¡Œ etcd ç¢ç‰‡æ•´ç†ï¼ˆ`etcdctl defrag`ï¼‰ã€å¢åŠ  `--quota-backend-bytes`ã€‚

#### æ•…éšœ 12ï¼šè¯ä¹¦è¿‡æœŸå¯¼è‡´é›†ç¾¤é€šä¿¡ä¸­æ–­

**æ’æŸ¥å‘½ä»¤**ï¼š
```bash
# æ£€æŸ¥è¯ä¹¦è¿‡æœŸæ—¶é—´
kubeadm certs check-expiration

# æŸ¥çœ‹å…·ä½“è¯ä¹¦
openssl x509 -in /etc/kubernetes/pki/apiserver.crt -noout -dates
```

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# ç»­æœŸæ‰€æœ‰è¯ä¹¦
kubeadm certs renew all

# é‡å¯æ§åˆ¶å¹³é¢ç»„ä»¶
systemctl restart kubelet
```

**é¢„é˜²æªæ–½**ï¼šè®¾ç½®è¯ä¹¦è¿‡æœŸå‘Šè­¦ï¼ˆæå‰ 30 å¤©ï¼‰ã€é…ç½®è‡ªåŠ¨ç»­æœŸã€‚

### 6.4 æ•…éšœæ¼”ç»ƒï¼ˆChaos Engineeringï¼‰

#### ä½¿ç”¨ Chaos Mesh çš„åœºæ™¯è®¾è®¡

```yaml
# åœºæ™¯ 1ï¼šPod æ•…éšœæ³¨å…¥ â€” éšæœºæ€æ­» Pod
apiVersion: chaos-mesh.org/v1alpha1
kind: PodChaos
metadata:
  name: pod-kill-test
spec:
  action: pod-kill
  mode: one              # éšæœºé€‰æ‹©ä¸€ä¸ª Pod
  selector:
    namespaces: ["production"]
    labelSelectors:
      app: web
  scheduler:
    cron: "@every 5m"    # æ¯ 5 åˆ†é’Ÿæ€ä¸€æ¬¡

---
# åœºæ™¯ 2ï¼šç½‘ç»œå»¶è¿Ÿæ³¨å…¥
apiVersion: chaos-mesh.org/v1alpha1
kind: NetworkChaos
metadata:
  name: network-delay-test
spec:
  action: delay
  mode: all
  selector:
    namespaces: ["production"]
    labelSelectors:
      app: api-gateway
  delay:
    latency: "200ms"
    jitter: "50ms"
  duration: "5m"

---
# åœºæ™¯ 3ï¼šèŠ‚ç‚¹æ•…éšœæ¨¡æ‹Ÿ
apiVersion: chaos-mesh.org/v1alpha1
kind: PhysicalMachineChaos
metadata:
  name: node-failure-test
spec:
  action: stress-cpu
  address: ["http://10.0.0.5:31767"]
  stress-cpu:
    workers: 4
    load: 90
  duration: "10m"
```

ğŸ¯ æ•…éšœæ¼”ç»ƒæ£€æŸ¥æ¸…å•ï¼š
- Pod è¢«æ€åæ˜¯å¦è‡ªåŠ¨æ¢å¤ï¼Ÿæ¢å¤æ—¶é—´æ˜¯å¦å¯æ¥å—ï¼Ÿ
- ç½‘ç»œå»¶è¿Ÿä¸‹æœåŠ¡æ˜¯å¦æœ‰åˆç†çš„è¶…æ—¶å’Œé‡è¯•ï¼Ÿ
- èŠ‚ç‚¹æ•…éšœå Pod æ˜¯å¦è¢«æ­£ç¡®é©±é€å’Œé‡æ–°è°ƒåº¦ï¼Ÿ
- æ•°æ®åº“ Pod æ•…éšœåæ•°æ®æ˜¯å¦å®Œæ•´ï¼Ÿä¸»ä»åˆ‡æ¢æ˜¯å¦æ­£å¸¸ï¼Ÿ

---

## ç¬¬ä¸ƒç« ï¼šé¢è¯•é¢˜åº“ä¸å­¦ä¹ è·¯å¾„

### 7.1 é«˜é¢‘é¢è¯•é¢˜

#### åŸºç¡€é¢˜ï¼ˆ10é¢˜ï¼‰

**Q1ï¼šPod å’Œå®¹å™¨çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆ K8s ä¸ç›´æ¥ç®¡ç†å®¹å™¨ï¼Ÿ**

Pod æ˜¯ K8s æœ€å°è°ƒåº¦å•å…ƒï¼ŒåŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªå…±äº«ç½‘ç»œå‘½åç©ºé—´å’Œå­˜å‚¨å·çš„å®¹å™¨ã€‚K8s ä¸ç›´æ¥ç®¡ç†å®¹å™¨çš„åŸå› ï¼š
- å¤šä¸ªå®¹å™¨å¯èƒ½éœ€è¦ç´§å¯†åä½œï¼ˆå¦‚ Sidecar æ¨¡å¼ï¼‰ï¼Œå…±äº« localhost å’Œ Volume
- Pod æä¾›äº†ç»Ÿä¸€çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ˆInit Container â†’ Sidecar â†’ ä¸»å®¹å™¨ï¼‰
- Pod æ˜¯è°ƒåº¦çš„åŸå­å•ä½ï¼Œä¿è¯ç›¸å…³å®¹å™¨åœ¨åŒä¸€èŠ‚ç‚¹

**Q2ï¼šService çš„å››ç§ç±»å‹åŠå…¶åŒºåˆ«ï¼Ÿ**

| ç±»å‹ | è®¿é—®èŒƒå›´ | å®ç°æ–¹å¼ |
|------|---------|---------|
| ClusterIP | é›†ç¾¤å†…éƒ¨ | åˆ†é…è™šæ‹Ÿ IPï¼Œé€šè¿‡ kube-proxy è½¬å‘ |
| NodePort | é›†ç¾¤å¤–éƒ¨ï¼ˆé€šè¿‡èŠ‚ç‚¹ç«¯å£ï¼‰ | åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šå¼€æ”¾ 30000-32767 ç«¯å£ |
| LoadBalancer | é›†ç¾¤å¤–éƒ¨ï¼ˆé€šè¿‡äº‘ LBï¼‰ | è°ƒç”¨äº‘å‚å•† API åˆ›å»ºå¤–éƒ¨è´Ÿè½½å‡è¡¡å™¨ |
| ExternalName | DNS åˆ«å | è¿”å› CNAME è®°å½•ï¼Œä¸åšä»£ç† |

**Q3ï¼šDeployment å’Œ StatefulSet çš„åŒºåˆ«ï¼Ÿ**

| ç»´åº¦ | Deployment | StatefulSet |
|------|-----------|------------|
| Pod æ ‡è¯† | éšæœºåï¼ˆå¦‚ nginx-abc123ï¼‰ | æœ‰åºå›ºå®šåï¼ˆå¦‚ mysql-0, mysql-1ï¼‰ |
| å­˜å‚¨ | å…±äº« PVC æˆ–æ— çŠ¶æ€ | æ¯ä¸ª Pod ç‹¬ç«‹ PVCï¼ˆvolumeClaimTemplatesï¼‰ |
| æ‰©ç¼©å®¹ | å¹¶è¡Œåˆ›å»º/åˆ é™¤ | æœ‰åºåˆ›å»ºï¼ˆ0â†’1â†’2ï¼‰ï¼Œé€†åºåˆ é™¤ï¼ˆ2â†’1â†’0ï¼‰ |
| æ›´æ–°ç­–ç•¥ | RollingUpdateï¼ˆå¹¶è¡Œï¼‰ | RollingUpdateï¼ˆé€†åºï¼Œä¸€ä¸ªä¸€ä¸ªæ›´æ–°ï¼‰ |
| é€‚ç”¨åœºæ™¯ | æ— çŠ¶æ€åº”ç”¨ï¼ˆWebã€APIï¼‰ | æœ‰çŠ¶æ€åº”ç”¨ï¼ˆæ•°æ®åº“ã€æ¶ˆæ¯é˜Ÿåˆ—ï¼‰ |

**Q4ï¼šK8s çš„ä¸‰ç§ QoS ç­‰çº§æ˜¯ä»€ä¹ˆï¼Ÿ**

- **Guaranteed**ï¼šæ‰€æœ‰å®¹å™¨çš„ requests = limits â†’ æœ€é«˜ä¼˜å…ˆçº§ï¼Œæœ€åè¢«é©±é€
- **Burstable**ï¼šè‡³å°‘ä¸€ä¸ªå®¹å™¨è®¾ç½®äº† requests ä¸” requests â‰  limits â†’ ä¸­ç­‰ä¼˜å…ˆçº§
- **BestEffort**ï¼šæ²¡æœ‰ä»»ä½•å®¹å™¨è®¾ç½® requests/limits â†’ æœ€ä½ä¼˜å…ˆçº§ï¼Œæœ€å…ˆè¢«é©±é€

**Q5ï¼šä»€ä¹ˆæ˜¯ Init Containerï¼Ÿå®ƒå’Œ Sidecar Container çš„åŒºåˆ«ï¼Ÿ**

Init Container åœ¨ä¸»å®¹å™¨å¯åŠ¨å‰æŒ‰é¡ºåºæ‰§è¡Œï¼Œå…¨éƒ¨æˆåŠŸåä¸»å®¹å™¨æ‰å¯åŠ¨ã€‚ç”¨äºåˆå§‹åŒ–ï¼ˆå¦‚ç­‰å¾…ä¾èµ–æœåŠ¡ã€ä¸‹è½½é…ç½®ï¼‰ã€‚

Sidecar Containerï¼ˆ1.32 GAï¼‰æ˜¯è®¾ç½®äº† `restartPolicy: Always` çš„ Init Containerï¼Œå®ƒåœ¨ Init é˜¶æ®µå¯åŠ¨åæŒç»­è¿è¡Œï¼Œä¸ä¸»å®¹å™¨å…±å­˜ã€‚ç”¨äºæ—¥å¿—æ”¶é›†ã€ä»£ç†ç­‰ã€‚

**Q6ï¼šConfigMap å’Œ Secret çš„åŒºåˆ«ï¼Ÿ**

ä¸¤è€…éƒ½ç”¨äºå­˜å‚¨é…ç½®æ•°æ®ï¼ŒåŒºåˆ«åœ¨äºï¼šSecret çš„æ•°æ®ä»¥ Base64 ç¼–ç å­˜å‚¨ï¼ˆæ³¨æ„ï¼šä¸æ˜¯åŠ å¯†ï¼‰ï¼Œå¯ä»¥é…åˆ KMS åŠ å¯†å­˜å‚¨åœ¨ etcd ä¸­ã€‚Secret é€‚åˆå­˜å‚¨å¯†ç ã€Tokenã€è¯ä¹¦ç­‰æ•æ„Ÿæ•°æ®ã€‚

**Q7ï¼šä»€ä¹ˆæ˜¯ Taint å’Œ Tolerationï¼Ÿ**

Taintï¼ˆæ±¡ç‚¹ï¼‰æ ‡è®°åœ¨ Node ä¸Šï¼Œé˜»æ­¢ Pod è°ƒåº¦åˆ°è¯¥èŠ‚ç‚¹ã€‚Tolerationï¼ˆå®¹å¿ï¼‰æ ‡è®°åœ¨ Pod ä¸Šï¼Œå…è®¸ Pod è°ƒåº¦åˆ°æœ‰å¯¹åº” Taint çš„èŠ‚ç‚¹ã€‚å¸¸ç”¨äºä¸“ç”¨èŠ‚ç‚¹ï¼ˆå¦‚ GPU èŠ‚ç‚¹åªè¿è¡Œ ML ä»»åŠ¡ï¼‰ã€‚

**Q8ï¼šNamespace çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿå®ƒèƒ½å®ç°ç½‘ç»œéš”ç¦»å—ï¼Ÿ**

Namespace æä¾›é€»è¾‘éš”ç¦»ï¼šèµ„æºåç§°åœ¨ Namespace å†…å”¯ä¸€ã€å¯ä»¥è®¾ç½® ResourceQuota å’Œ LimitRangeã€‚ä½† Namespace æœ¬èº«ä¸æä¾›ç½‘ç»œéš”ç¦»ï¼Œéœ€è¦é…åˆ NetworkPolicy å®ç°ã€‚

**Q9ï¼škubectl apply å’Œ kubectl create çš„åŒºåˆ«ï¼Ÿ**

- `create`ï¼šå‘½ä»¤å¼ï¼Œèµ„æºå·²å­˜åœ¨åˆ™æŠ¥é”™
- `apply`ï¼šå£°æ˜å¼ï¼Œèµ„æºä¸å­˜åœ¨åˆ™åˆ›å»ºï¼Œå·²å­˜åœ¨åˆ™æ›´æ–°ï¼ˆä¸‰æ–¹åˆå¹¶ patchï¼‰
- ç”Ÿäº§ç¯å¢ƒæ¨è `apply`ï¼Œæ”¯æŒ GitOps å·¥ä½œæµ

**Q10ï¼šä»€ä¹ˆæ˜¯ PodDisruptionBudgetï¼ˆPDBï¼‰ï¼Ÿ**

PDB å®šä¹‰äº†åœ¨è‡ªæ„¿ä¸­æ–­ï¼ˆå¦‚èŠ‚ç‚¹ç»´æŠ¤ã€æ»šåŠ¨æ›´æ–°ï¼‰æœŸé—´ï¼Œå¿…é¡»ä¿æŒå¯ç”¨çš„æœ€å° Pod æ•°é‡æˆ–æœ€å¤§ä¸å¯ç”¨æ•°é‡ã€‚é˜²æ­¢è¿ç»´æ“ä½œå¯¼è‡´æœåŠ¡å®Œå…¨ä¸å¯ç”¨ã€‚

#### è¿›é˜¶é¢˜ï¼ˆ10é¢˜ï¼‰

**Q11ï¼šInformer æœºåˆ¶çš„å·¥ä½œåŸç†ï¼Ÿ**

Informer é€šè¿‡ List-Watch æœºåˆ¶å®ç°æœ¬åœ°ç¼“å­˜ï¼šé¦–æ¬¡ List è·å–å…¨é‡æ•°æ®å­˜å…¥ Indexerï¼Œä¹‹åé€šè¿‡ Watch æ¥æ”¶å¢é‡äº‹ä»¶æ›´æ–°ç¼“å­˜ã€‚å†…éƒ¨æµæ°´çº¿ï¼šReflector â†’ DeltaFIFO â†’ Indexer + EventHandler â†’ workqueueã€‚è¿™é¿å…äº†æ¯æ¬¡éƒ½æŸ¥è¯¢ apiserverï¼Œå¤§å¹…é™ä½ apiserver è´Ÿè½½ã€‚

**Q12ï¼škube-scheduler çš„è°ƒåº¦æµç¨‹ï¼Ÿ**

è°ƒåº¦æ¡†æ¶åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š
1. è°ƒåº¦å‘¨æœŸï¼šPreFilter â†’ Filterï¼ˆè¿‡æ»¤ä¸åˆæ ¼èŠ‚ç‚¹ï¼‰â†’ PostFilterï¼ˆæŠ¢å ï¼‰â†’ PreScore â†’ Scoreï¼ˆæ‰“åˆ†æ’åºï¼‰â†’ Reserve
2. ç»‘å®šå‘¨æœŸï¼šPermit â†’ PreBind â†’ Bindï¼ˆå†™å…¥ apiserverï¼‰â†’ PostBind

**Q13ï¼šå¦‚ä½•å®ç° Pod çš„é›¶åœæœºæ›´æ–°ï¼Ÿ**

1. é…ç½® readinessProbe ç¡®ä¿æ–° Pod å°±ç»ªåæ‰æ¥æ”¶æµé‡
2. è®¾ç½®åˆç†çš„ `maxSurge` å’Œ `maxUnavailable`
3. ä½¿ç”¨ `preStop` hook ç­‰å¾…è¿æ¥æ’ç©ºï¼š`lifecycle.preStop.exec.command: ["sleep", "15"]`
4. é…ç½® PDB ä¿è¯æœ€å°å¯ç”¨å‰¯æœ¬æ•°

**Q14ï¼šetcd çš„ Raft åè®®å¦‚ä½•ä¿è¯ä¸€è‡´æ€§ï¼Ÿ**

Raft é€šè¿‡ä¸‰ä¸ªå­é—®é¢˜ä¿è¯ä¸€è‡´æ€§ï¼š
1. Leader é€‰ä¸¾ï¼šéšæœºè¶…æ—¶é¿å…æ´»é”ï¼Œè·å¾—å¤šæ•°ç¥¨æˆä¸º Leader
2. æ—¥å¿—å¤åˆ¶ï¼šLeader å°†å†™æ“ä½œå¤åˆ¶åˆ°å¤šæ•° Follower åæ‰æäº¤
3. å®‰å…¨æ€§ï¼šåªæœ‰åŒ…å«æœ€æ–°å·²æäº¤æ—¥å¿—çš„èŠ‚ç‚¹æ‰èƒ½å½“é€‰ Leader

**Q15ï¼šCRD å’Œ Aggregated API Server çš„åŒºåˆ«ï¼Ÿ**

- CRDï¼šè½»é‡çº§æ‰©å±•ï¼Œåªéœ€å®šä¹‰ YAMLï¼Œæ•°æ®å­˜å‚¨åœ¨ etcd ä¸­ï¼Œé€‚åˆå¤§å¤šæ•°åœºæ™¯
- Aggregated API Serverï¼šé‡é‡çº§æ‰©å±•ï¼Œéœ€è¦å¼€å‘ç‹¬ç«‹çš„ API Serverï¼Œå¯ä»¥ä½¿ç”¨è‡ªå®šä¹‰å­˜å‚¨åç«¯ï¼Œé€‚åˆéœ€è¦è‡ªå®šä¹‰å­˜å‚¨æˆ–å¤æ‚é€»è¾‘çš„åœºæ™¯

**Q16ï¼šK8s ç½‘ç»œæ¨¡å‹çš„ä¸‰ä¸ªåŸºæœ¬è¦æ±‚ï¼Ÿ**

1. æ‰€æœ‰ Pod å¯ä»¥ä¸ç»è¿‡ NAT ç›´æ¥ä¸å…¶ä»– Pod é€šä¿¡
2. æ‰€æœ‰ Node å¯ä»¥ä¸ç»è¿‡ NAT ç›´æ¥ä¸æ‰€æœ‰ Pod é€šä¿¡
3. Pod çœ‹åˆ°çš„è‡ªå·±çš„ IP ä¸å…¶ä»– Pod çœ‹åˆ°çš„ä¸€è‡´

**Q17ï¼šä»€ä¹ˆæ˜¯ Admission Webhookï¼ŸMutating å’Œ Validating çš„åŒºåˆ«ï¼Ÿ**

Admission Webhook æ˜¯ apiserver åœ¨æŒä¹…åŒ–å¯¹è±¡å‰è°ƒç”¨çš„å¤–éƒ¨ HTTP å›è°ƒï¼š
- Mutating Webhookï¼šå¯ä»¥ä¿®æ”¹è¯·æ±‚å¯¹è±¡ï¼ˆå¦‚æ³¨å…¥ Sidecarã€æ·»åŠ é»˜è®¤æ ‡ç­¾ï¼‰
- Validating Webhookï¼šåªèƒ½æ¥å—æˆ–æ‹’ç»è¯·æ±‚ï¼ˆå¦‚å¼ºåˆ¶èµ„æºé™åˆ¶ã€å‘½åè§„èŒƒï¼‰
- æ‰§è¡Œé¡ºåºï¼šå…ˆ Mutatingï¼Œå Validating

**Q18ï¼šå¦‚ä½•æ’æŸ¥ Pod ç½‘ç»œä¸é€šçš„é—®é¢˜ï¼Ÿ**

æ’æŸ¥è·¯å¾„ï¼šPod â†’ CNI â†’ Node â†’ kube-proxy â†’ Service â†’ ç›®æ ‡ Pod
1. æ£€æŸ¥ Pod IP æ˜¯å¦åˆ†é…ï¼š`kubectl get pod -o wide`
2. æ£€æŸ¥ CNI æ’ä»¶çŠ¶æ€ï¼š`kubectl get pods -n kube-system | grep calico/flannel`
3. ä» Pod å†… ping å…¶ä»– Pod IP
4. æ£€æŸ¥ NetworkPolicy æ˜¯å¦é˜»æ–­
5. æ£€æŸ¥ kube-proxy å’Œ iptables/IPVS è§„åˆ™

**Q19ï¼šK8s çš„åƒåœ¾å›æ”¶ï¼ˆGCï¼‰æœºåˆ¶ï¼Ÿ**

K8s ä½¿ç”¨ OwnerReference å»ºç«‹å¯¹è±¡é—´çš„æ‰€æœ‰æƒå…³ç³»ã€‚å½“ Owner è¢«åˆ é™¤æ—¶ï¼ŒGC Controller æ ¹æ®åˆ é™¤ç­–ç•¥å¤„ç†ï¼š
- Foregroundï¼šå…ˆåˆ é™¤æ‰€æœ‰ dependentsï¼Œå†åˆ é™¤ owner
- Backgroundï¼šå…ˆåˆ é™¤ ownerï¼ŒGC å¼‚æ­¥åˆ é™¤ dependents
- Orphanï¼šåˆ é™¤ ownerï¼Œä¿ç•™ dependentsï¼ˆè§£é™¤å…³è”ï¼‰

**Q20ï¼šä»€ä¹ˆæ˜¯ API Priority and Fairnessï¼ˆAPFï¼‰ï¼Ÿ**

APF æ˜¯ apiserver çš„æµé‡ç®¡ç†æœºåˆ¶ï¼Œå°†è¯·æ±‚åˆ†ä¸ºä¸åŒä¼˜å…ˆçº§ï¼ˆPriorityLevelï¼‰ï¼Œæ¯ä¸ªä¼˜å…ˆçº§æœ‰ç‹¬ç«‹çš„å¹¶å‘é™åˆ¶å’Œæ’é˜Ÿç­–ç•¥ã€‚é˜²æ­¢å•ä¸ªå®¢æˆ·ç«¯ï¼ˆå¦‚å¤±æ§çš„æ§åˆ¶å™¨ï¼‰è€—å°½ apiserver èµ„æºï¼Œä¿æŠ¤ç³»ç»Ÿå…³é”®è¯·æ±‚ã€‚

#### åŸç†é¢˜ï¼ˆ10é¢˜ï¼‰

**Q21ï¼šapiserver å¤„ç†ä¸€ä¸ªè¯·æ±‚çš„å®Œæ•´é“¾è·¯ï¼Ÿ**

```
å®¢æˆ·ç«¯è¯·æ±‚ â†’ TLS ç»ˆæ­¢ â†’ è®¤è¯(Authentication) â†’ æˆæƒ(Authorization)
â†’ Mutating Admission â†’ Object Schema Validation â†’ Validating Admission
â†’ etcd æŒä¹…åŒ– â†’ è¿”å›å“åº”
```

**Q22ï¼škubelet çš„ PLEG æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿ**

PLEGï¼ˆPod Lifecycle Event Generatorï¼‰æ¯ç§’è½®è¯¢å®¹å™¨è¿è¡Œæ—¶ï¼Œå¯¹æ¯”ä¸Šæ¬¡çŠ¶æ€ç”Ÿæˆ Pod ç”Ÿå‘½å‘¨æœŸäº‹ä»¶ã€‚å®ƒè§£è€¦äº† kubelet ä¸»å¾ªç¯å’Œå®¹å™¨è¿è¡Œæ—¶çš„çŠ¶æ€åŒæ­¥ï¼Œé¿å… kubelet ç›´æ¥ä¾èµ–å®¹å™¨è¿è¡Œæ—¶çš„äº‹ä»¶æœºåˆ¶ã€‚

**Q23ï¼šWatch æ–­è¿åå¦‚ä½•æ¢å¤ï¼Ÿ**

å®¢æˆ·ç«¯è®°å½•æœ€åæ”¶åˆ°çš„ ResourceVersionï¼Œæ–­è¿åä½¿ç”¨è¯¥ç‰ˆæœ¬é‡æ–° Watchã€‚å¦‚æœç‰ˆæœ¬è¿‡æ—§ï¼ˆetcd å·²å‹ç¼©ï¼‰ï¼Œapiserver è¿”å› 410 Goneï¼Œå®¢æˆ·ç«¯éœ€è¦é‡æ–° List è·å–å…¨é‡æ•°æ®ã€‚Watch Bookmark æœºåˆ¶å¸®åŠ©å®¢æˆ·ç«¯ä¿æŒè¾ƒæ–°çš„ ResourceVersionã€‚

**Q24ï¼šK8s å¦‚ä½•å®ç° Service çš„è´Ÿè½½å‡è¡¡ï¼Ÿ**

kube-proxy åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šç»´æŠ¤è½¬å‘è§„åˆ™ï¼š
- iptables æ¨¡å¼ï¼šé€šè¿‡ DNAT è§„åˆ™å’Œ probability å®ç°éšæœºè´Ÿè½½å‡è¡¡
- IPVS æ¨¡å¼ï¼šé€šè¿‡ Linux IPVS å†…æ ¸æ¨¡å—å®ç°å¤šç§ç®—æ³•ï¼ˆrr/lc/sh ç­‰ï¼‰
- ä¸¤ç§æ¨¡å¼éƒ½ä¾èµ– conntrack è¿›è¡Œè¿æ¥è¿½è¸ª

**Q25ï¼šä¸ºä»€ä¹ˆ K8s é€‰æ‹© etcd è€Œä¸æ˜¯ ZooKeeper æˆ– Consulï¼Ÿ**

- etcd ä½¿ç”¨ Raftï¼ˆæ¯” ZooKeeper çš„ ZAB æ›´æ˜“ç†è§£å’Œå®ç°ï¼‰
- etcd æä¾› Watch æœºåˆ¶ï¼ˆK8s çš„æ ¸å¿ƒéœ€æ±‚ï¼‰
- etcd æ˜¯ Go ç¼–å†™ï¼ˆä¸ K8s æŠ€æœ¯æ ˆä¸€è‡´ï¼‰
- etcd çš„ MVCC å­˜å‚¨æ”¯æŒé«˜æ•ˆçš„èŒƒå›´æŸ¥è¯¢å’Œ Watch

**Q26ï¼šK8s çš„ GVK å’Œ GVR æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆéœ€è¦ä¸¤å¥—ï¼Ÿ**

GVKï¼ˆGroup/Version/Kindï¼‰æ ‡è¯†å¯¹è±¡ç±»å‹ï¼Œç”¨äºä»£ç å±‚é¢çš„ç±»å‹ç³»ç»Ÿã€‚GVRï¼ˆGroup/Version/Resourceï¼‰æ ‡è¯† REST è·¯å¾„ï¼Œç”¨äº API å±‚é¢çš„è·¯ç”±ã€‚ä¸¤è€…é€šè¿‡ RESTMapper æ˜ å°„ã€‚åˆ†ç¦»çš„åŸå› æ˜¯ Kind å’Œ Resource ä¸æ€»æ˜¯ä¸€ä¸€å¯¹åº”ï¼ˆå¦‚ Scale å­èµ„æºï¼‰ã€‚

**Q27ï¼šController çš„ Reconcile å‡½æ•°åº”è¯¥éµå¾ªå“ªäº›åŸåˆ™ï¼Ÿ**

1. å¹‚ç­‰æ€§ï¼šå¤šæ¬¡æ‰§è¡Œç»“æœç›¸åŒ
2. Level-Triggeredï¼šåŸºäºå½“å‰çŠ¶æ€è€Œéäº‹ä»¶
3. åªå…³æ³¨è‡ªå·±ç®¡ç†çš„èµ„æº
4. å¤±è´¥æ—¶è¿”å›é”™è¯¯è®©æ¡†æ¶é‡è¯•
5. é¿å…é•¿æ—¶é—´é˜»å¡ï¼ˆä½¿ç”¨ RequeueAfterï¼‰

**Q28ï¼šK8s çš„è¯ä¹¦ä½“ç³»æ˜¯æ€æ ·çš„ï¼Ÿ**

K8s ä½¿ç”¨ PKI ä½“ç³»ï¼Œæ ¸å¿ƒ CA ç­¾å‘æ‰€æœ‰ç»„ä»¶è¯ä¹¦ï¼š
- apiserver æœåŠ¡ç«¯è¯ä¹¦ï¼ˆå®¢æˆ·ç«¯éªŒè¯ apiserver èº«ä»½ï¼‰
- kubelet å®¢æˆ·ç«¯è¯ä¹¦ï¼ˆapiserver éªŒè¯ kubelet èº«ä»½ï¼‰
- etcd æœåŠ¡ç«¯/å®¢æˆ·ç«¯è¯ä¹¦
- front-proxy è¯ä¹¦ï¼ˆAPI èšåˆï¼‰
- SA ç­¾åå¯†é’¥å¯¹ï¼ˆç­¾å‘ ServiceAccount Tokenï¼‰

**Q29ï¼šä»€ä¹ˆæ˜¯ Finalizerï¼Ÿå®ƒçš„å·¥ä½œåŸç†ï¼Ÿ**

Finalizer æ˜¯å¯¹è±¡ metadata ä¸­çš„å­—ç¬¦ä¸²åˆ—è¡¨ã€‚å½“å¯¹è±¡è¢«åˆ é™¤æ—¶ï¼Œå¦‚æœæœ‰ Finalizerï¼Œå¯¹è±¡ä¸ä¼šè¢«çœŸæ­£åˆ é™¤ï¼Œè€Œæ˜¯è®¾ç½® `deletionTimestamp`ã€‚æ§åˆ¶å™¨æ£€æµ‹åˆ°åæ‰§è¡Œæ¸…ç†é€»è¾‘ï¼Œå®Œæˆåç§»é™¤ Finalizerï¼Œå¯¹è±¡æ‰è¢«çœŸæ­£åˆ é™¤ã€‚ç”¨äºç¡®ä¿å¤–éƒ¨èµ„æºï¼ˆå¦‚äº‘èµ„æºï¼‰è¢«æ­£ç¡®æ¸…ç†ã€‚

**Q30ï¼šK8s 1.32 ä¸­ Sidecar Containers GA çš„å®ç°åŸç†ï¼Ÿ**

é€šè¿‡åœ¨ `initContainers` ä¸­è®¾ç½® `restartPolicy: Always` å®ç°ã€‚kubelet åœ¨å¯åŠ¨ Init Containers æ—¶ï¼Œé‡åˆ° `restartPolicy: Always` çš„å®¹å™¨ä¼šå°†å…¶æ ‡è®°ä¸º Sidecarï¼Œå¯åŠ¨åä¸ç­‰å¾…å…¶å®Œæˆå°±ç»§ç»­å¯åŠ¨ä¸‹ä¸€ä¸ª Init Containerã€‚Sidecar åœ¨æ‰€æœ‰ä¸»å®¹å™¨ç»ˆæ­¢åæ‰è¢«ç»ˆæ­¢ã€‚

#### åœºæ™¯é¢˜ï¼ˆ5é¢˜ï¼‰

**Q31ï¼šè®¾è®¡ä¸€ä¸ªæ”¯æŒ 10000 QPS çš„ Web æœåŠ¡åœ¨ K8s ä¸Šçš„éƒ¨ç½²æ–¹æ¡ˆã€‚**

å…³é”®è®¾è®¡ç‚¹ï¼š
- HPA åŸºäº CPU/è‡ªå®šä¹‰æŒ‡æ ‡è‡ªåŠ¨æ‰©ç¼©å®¹
- Pod åäº²å’Œæ€§ç¡®ä¿åˆ†æ•£åœ¨ä¸åŒèŠ‚ç‚¹/AZ
- Ingress Controllerï¼ˆå¦‚ Nginxï¼‰+ å¤–éƒ¨ LB å…¥å£
- åˆç†çš„ requests/limitsï¼ˆå‹æµ‹ç¡®å®šå• Pod æ‰¿è½½èƒ½åŠ›ï¼‰
- PDB ä¿è¯æ»šåŠ¨æ›´æ–°æ—¶æœ€å°å¯ç”¨å‰¯æœ¬
- é¢„çƒ­æœºåˆ¶ï¼ˆstartupProbe + minReadySecondsï¼‰

**Q32ï¼šetcd æ•°æ®æŸåï¼Œå¦‚ä½•æ¢å¤é›†ç¾¤ï¼Ÿ**

1. åœæ­¢æ‰€æœ‰ apiserver
2. ä»æœ€è¿‘çš„ etcd å¿«ç…§æ¢å¤ï¼š`etcdctl snapshot restore`
3. é‡å¯ etcd é›†ç¾¤
4. é‡å¯ apiserver
5. éªŒè¯é›†ç¾¤çŠ¶æ€ï¼š`kubectl get nodes`ã€`kubectl get pods --all-namespaces`
6. æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®ä¸¢å¤±ï¼ˆå¿«ç…§æ—¶é—´ç‚¹ä¹‹åçš„å˜æ›´ä¼šä¸¢å¤±ï¼‰

**Q33ï¼šå¦‚ä½•å®ç°é‡‘ä¸é›€å‘å¸ƒï¼ˆCanary Deploymentï¼‰ï¼Ÿ**

æ–¹æ¡ˆä¸€ï¼šåŸç”Ÿ K8sï¼ˆä¸¤ä¸ª Deployment + Service æƒé‡ï¼‰
æ–¹æ¡ˆäºŒï¼šIstio VirtualService æµé‡åˆ†å‰²ï¼ˆæ¨èï¼Œç²¾ç¡®æ§åˆ¶ç™¾åˆ†æ¯”ï¼‰
æ–¹æ¡ˆä¸‰ï¼šArgo Rolloutsï¼ˆå£°æ˜å¼æ¸è¿›å¼äº¤ä»˜ï¼‰

**Q34ï¼šé›†ç¾¤ä¸­å‡ºç°å¤§é‡ Evicted Podï¼Œå¦‚ä½•æ’æŸ¥å’Œè§£å†³ï¼Ÿ**

1. `kubectl describe node` æ£€æŸ¥èŠ‚ç‚¹ Conditionsï¼ˆMemoryPressure/DiskPressureï¼‰
2. `kubectl top nodes` æŸ¥çœ‹èµ„æºä½¿ç”¨
3. æ£€æŸ¥ kubelet é©±é€é˜ˆå€¼é…ç½®
4. æ¸…ç† Evicted Podï¼š`kubectl delete pods --field-selector=status.phase=Failed`
5. æ ¹å› è§£å†³ï¼šæ‰©å®¹èŠ‚ç‚¹ã€ä¼˜åŒ–åº”ç”¨èµ„æºä½¿ç”¨ã€è°ƒæ•´é©±é€é˜ˆå€¼

**Q35ï¼šå¦‚ä½•å®‰å…¨åœ°å¯¹ K8s é›†ç¾¤è¿›è¡Œç‰ˆæœ¬å‡çº§ï¼Ÿ**

1. é˜…è¯»ç›®æ ‡ç‰ˆæœ¬çš„ CHANGELOGï¼Œå…³æ³¨ Breaking Changes å’ŒåºŸå¼ƒ API
2. åœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯å‡çº§
3. å¤‡ä»½ etcd
4. é€ä¸ªå‡çº§æ§åˆ¶å¹³é¢èŠ‚ç‚¹ï¼ˆå…ˆå‡çº§ apiserverï¼Œå†å‡çº§ controller-manager å’Œ schedulerï¼‰
5. é€ä¸ªå‡çº§å·¥ä½œèŠ‚ç‚¹ï¼ˆcordon â†’ drain â†’ å‡çº§ kubelet â†’ uncordonï¼‰
6. éªŒè¯é›†ç¾¤åŠŸèƒ½å’Œåº”ç”¨çŠ¶æ€

### 7.2 å­¦ä¹ èµ„æº

#### å®˜æ–¹æ–‡æ¡£å¿…è¯»ç« èŠ‚

| ç« èŠ‚ | é“¾æ¥ | é‡è¦ç¨‹åº¦ |
|------|------|---------|
| Concepts | https://kubernetes.io/docs/concepts/ | â­â­â­â­â­ |
| Tasks | https://kubernetes.io/docs/tasks/ | â­â­â­â­ |
| API Reference | https://kubernetes.io/docs/reference/ | â­â­â­ |
| Contribute (è®¾è®¡ææ¡ˆ) | https://github.com/kubernetes/enhancements | â­â­â­â­ |

#### ç»å…¸ä¹¦ç±

| ä¹¦å | ä½œè€… | é€‚åˆäººç¾¤ |
|------|------|---------|
| ã€ŠKubernetes in Actionã€‹ | Marko LukÅ¡a | å…¥é—¨åˆ°è¿›é˜¶ |
| ã€ŠProgramming Kubernetesã€‹ | Michael Hausenblas | Operator å¼€å‘è€… |
| ã€ŠKubernetes Patternsã€‹ | Bilgin Ibryam | æ¶æ„å¸ˆ |
| ã€ŠManaging Kubernetesã€‹ | Brendan Burns | è¿ç»´å·¥ç¨‹å¸ˆ |

#### æ ¸å¿ƒè®ºæ–‡

1. *"Large-scale cluster management at Google with Borg"* â€” EuroSys 2015
2. *"Borg, Omega, and Kubernetes"* â€” ACM Queue 2016
3. *"In Search of an Understandable Consensus Algorithm (Raft)"* â€” USENIX ATC 2014

### 7.3 å®éªŒç¯å¢ƒæ­å»º

#### Kind å¤šèŠ‚ç‚¹é›†ç¾¤

```yaml
# kind-config.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  kubeadmConfigPatches:
  - |
    kind: InitConfiguration
    nodeRegistration:
      kubeletExtraArgs:
        node-labels: "ingress-ready=true"
  extraPortMappings:
  - containerPort: 80
    hostPort: 80
    protocol: TCP
  - containerPort: 443
    hostPort: 443
    protocol: TCP
- role: worker
- role: worker
- role: worker
```

```bash
# åˆ›å»ºé›†ç¾¤
kind create cluster --name k8s-lab --config kind-config.yaml --image kindest/node:v1.32.0

# éªŒè¯
kubectl get nodes
kubectl cluster-info

# å®‰è£… Metrics Serverï¼ˆKind éœ€è¦ç‰¹æ®Šé…ç½®ï¼‰
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
kubectl patch deployment metrics-server -n kube-system --type='json' \
  -p='[{"op":"add","path":"/spec/template/spec/containers/0/args/-","value":"--kubelet-insecure-tls"}]'

# æ¸…ç†
kind delete cluster --name k8s-lab
```

#### kubeadm ç”Ÿäº§çº§é›†ç¾¤æ­å»ºè¦ç‚¹

```bash
# 1. ç³»ç»Ÿå‡†å¤‡ï¼ˆæ‰€æœ‰èŠ‚ç‚¹ï¼‰
swapoff -a
modprobe br_netfilter
cat <<EOF | tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF
sysctl --system

# 2. å®‰è£… containerd + kubeadm/kubelet/kubectlï¼ˆæ‰€æœ‰èŠ‚ç‚¹ï¼‰
# è§å®˜æ–¹æ–‡æ¡£ï¼šhttps://kubernetes.io/docs/setup/production-environment/

# 3. åˆå§‹åŒ–æ§åˆ¶å¹³é¢ï¼ˆç¬¬ä¸€ä¸ª Masterï¼‰
kubeadm init \
  --control-plane-endpoint "lb.example.com:6443" \
  --upload-certs \
  --pod-network-cidr=10.244.0.0/16

# 4. å®‰è£… CNIï¼ˆå¦‚ Calicoï¼‰
kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.27.0/manifests/calico.yaml

# 5. åŠ å…¥å…¶ä»– Master å’Œ Worker èŠ‚ç‚¹
kubeadm join lb.example.com:6443 --token <token> \
  --discovery-token-ca-cert-hash sha256:<hash> \
  --control-plane --certificate-key <key>  # Master èŠ‚ç‚¹åŠ  --control-plane
```

---

## é™„å½•

### é™„å½•Aï¼šæ ¸å¿ƒæœ¯è¯­è¡¨

| æœ¯è¯­ | å…¨ç§° | è¯´æ˜ |
|------|------|------|
| K8s | Kubernetes | K å’Œ s ä¹‹é—´æœ‰ 8 ä¸ªå­—æ¯ |
| Pod | â€” | æœ€å°è°ƒåº¦å•å…ƒ |
| Node | â€” | é›†ç¾¤å·¥ä½œèŠ‚ç‚¹ |
| Namespace | â€” | é€»è¾‘éš”ç¦»åˆ†åŒº |
| Deployment | â€” | æ— çŠ¶æ€åº”ç”¨æ§åˆ¶å™¨ |
| StatefulSet | â€” | æœ‰çŠ¶æ€åº”ç”¨æ§åˆ¶å™¨ |
| DaemonSet | â€” | æ¯èŠ‚ç‚¹ä¸€ä¸ª Pod çš„æ§åˆ¶å™¨ |
| ReplicaSet | â€” | Pod å‰¯æœ¬ç®¡ç†å™¨ï¼ˆDeployment å†…éƒ¨ä½¿ç”¨ï¼‰ |
| Service | â€” | ç¨³å®šçš„ç½‘ç»œè®¿é—®å…¥å£ |
| Ingress | â€” | HTTP/HTTPS è·¯ç”±è§„åˆ™ |
| ConfigMap | â€” | éæ•æ„Ÿé…ç½®å­˜å‚¨ |
| Secret | â€” | æ•æ„Ÿæ•°æ®å­˜å‚¨ |
| PV | PersistentVolume | æŒä¹…åŒ–å­˜å‚¨èµ„æº |
| PVC | PersistentVolumeClaim | å­˜å‚¨èµ„æºç”³è¯· |
| SC | StorageClass | å­˜å‚¨ç±»ï¼ˆåŠ¨æ€ä¾›ç»™ï¼‰ |
| CRD | CustomResourceDefinition | è‡ªå®šä¹‰èµ„æºå®šä¹‰ |
| CR | Custom Resource | è‡ªå®šä¹‰èµ„æºå®ä¾‹ |
| CRI | Container Runtime Interface | å®¹å™¨è¿è¡Œæ—¶æ¥å£ |
| CNI | Container Network Interface | å®¹å™¨ç½‘ç»œæ¥å£ |
| CSI | Container Storage Interface | å®¹å™¨å­˜å‚¨æ¥å£ |
| RBAC | Role-Based Access Control | åŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶ |
| SA | ServiceAccount | æœåŠ¡è´¦æˆ· |
| HPA | Horizontal Pod Autoscaler | æ°´å¹³ Pod è‡ªåŠ¨æ‰©ç¼©å™¨ |
| VPA | Vertical Pod Autoscaler | å‚ç›´ Pod è‡ªåŠ¨æ‰©ç¼©å™¨ |
| PDB | PodDisruptionBudget | Pod ä¸­æ–­é¢„ç®— |
| PSA | Pod Security Admission | Pod å®‰å…¨å‡†å…¥ |
| PSS | Pod Security Standards | Pod å®‰å…¨æ ‡å‡† |
| GVK | Group/Version/Kind | API å¯¹è±¡ç±»å‹æ ‡è¯† |
| GVR | Group/Version/Resource | API èµ„æºè·¯å¾„æ ‡è¯† |
| APF | API Priority and Fairness | API ä¼˜å…ˆçº§å’Œå…¬å¹³æ€§ |
| DRA | Dynamic Resource Allocation | åŠ¨æ€èµ„æºåˆ†é… |
| PLEG | Pod Lifecycle Event Generator | Pod ç”Ÿå‘½å‘¨æœŸäº‹ä»¶ç”Ÿæˆå™¨ |
| KEP | Kubernetes Enhancement Proposal | Kubernetes å¢å¼ºææ¡ˆ |
| SIG | Special Interest Group | ç‰¹åˆ«å…´è¶£å°ç»„ |
| CNCF | Cloud Native Computing Foundation | äº‘åŸç”Ÿè®¡ç®—åŸºé‡‘ä¼š |
| OCI | Open Container Initiative | å¼€æ”¾å®¹å™¨å€¡è®® |
| etcd | â€” | åˆ†å¸ƒå¼é”®å€¼å­˜å‚¨ï¼ˆåç§°æ¥æºäº /etc ç›®å½• + distributedï¼‰ |
| kubeadm | â€” | é›†ç¾¤å¼•å¯¼å·¥å…· |
| kubectl | â€” | K8s å‘½ä»¤è¡Œå®¢æˆ·ç«¯ |
| kubelet | â€” | èŠ‚ç‚¹ä»£ç† |
| kube-proxy | â€” | ç½‘ç»œä»£ç† |
| CoreDNS | â€” | é›†ç¾¤ DNS æœåŠ¡ |
| Helm | â€” | K8s åŒ…ç®¡ç†å™¨ |
| Operator | â€” | CRD + Controller çš„è¿ç»´è‡ªåŠ¨åŒ–æ¨¡å¼ |
| Informer | â€” | client-go çš„æœ¬åœ°ç¼“å­˜æœºåˆ¶ |
| Finalizer | â€” | å¯¹è±¡åˆ é™¤å‰çš„æ¸…ç†é’©å­ |
| Webhook | â€” | HTTP å›è°ƒæœºåˆ¶ï¼ˆAdmission/Conversionï¼‰ |

### é™„å½•Bï¼šå‚è€ƒæ–‡çŒ®

#### å®˜æ–¹èµ„æº

- Kubernetes å®˜æ–¹æ–‡æ¡£ï¼šhttps://kubernetes.io/docs/
- Kubernetes GitHub ä»“åº“ï¼šhttps://github.com/kubernetes/kubernetes
- Kubernetes Enhancement Proposals (KEPs)ï¼šhttps://github.com/kubernetes/enhancements
- Kubernetes API Reference (1.32)ï¼šhttps://kubernetes.io/docs/reference/generated/kubernetes-api/v1.32/
- client-go æ–‡æ¡£ï¼šhttps://pkg.go.dev/k8s.io/client-go

#### è®ºæ–‡

1. Verma, A., et al. "Large-scale cluster management at Google with Borg." *Proceedings of the European Conference on Computer Systems (EuroSys)*, 2015.
2. Burns, B., et al. "Borg, Omega, and Kubernetes." *ACM Queue*, 14(1), 2016.
3. Ongaro, D., Ousterhout, J. "In Search of an Understandable Consensus Algorithm." *USENIX Annual Technical Conference*, 2014.

#### ç¤¾åŒºèµ„æº

- CNCF å¹´åº¦è°ƒæŸ¥æŠ¥å‘Šï¼šhttps://www.cncf.io/reports/
- Kubernetes Blogï¼šhttps://kubernetes.io/blog/
- KubeCon æ¼”è®²è§†é¢‘ï¼šhttps://www.youtube.com/c/CloudNativeComputingFoundation

### é™„å½•Cï¼šKubernetes 1.32 ç‰ˆæœ¬æ›´æ–°è®°å½•

#### GAï¼ˆç¨³å®šï¼‰ç‰¹æ€§

| ç‰¹æ€§ | KEP | è¯´æ˜ |
|------|-----|------|
| Sidecar Containers | KEP-753 | Init Container æ”¯æŒ `restartPolicy: Always` |
| Custom Resource Field Selectors | KEP-4358 | CRD æ”¯æŒå­—æ®µé€‰æ‹©å™¨ |
| Pod Scheduling Readiness | KEP-3521 | Pod å¯å£°æ˜è°ƒåº¦å°±ç»ªæ¡ä»¶ |

#### Beta ç‰¹æ€§

| ç‰¹æ€§ | KEP | è¯´æ˜ |
|------|-----|------|
| DRA: Structured Parameters | KEP-4381 | åŠ¨æ€èµ„æºåˆ†é…ç»“æ„åŒ–å‚æ•° |
| nftables kube-proxy | KEP-3866 | åŸºäº nftables çš„ kube-proxy åç«¯ |
| Recursive Read-only Mounts | KEP-3857 | é€’å½’åªè¯»æŒ‚è½½ |

#### åºŸå¼ƒä¸ç§»é™¤

- æŒç»­æ¸…ç†è¿‡æœŸçš„ Beta API
- æ¨è¿› in-tree å­˜å‚¨æ’ä»¶å‘ CSI è¿ç§»

> å®Œæ•´ CHANGELOG è§ï¼šhttps://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.32.md

---

> æœ¬æ–‡æ¡£æœ€åæ›´æ–°æ—¶é—´ï¼š2025-01-15
> åŸºäº Kubernetes 1.32 "Penelope" ç‰ˆæœ¬
> æ–‡æ¡£ç‰ˆæœ¬ï¼šv1.0

